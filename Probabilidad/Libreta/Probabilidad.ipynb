{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de contenido 💜<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Matemáticas-para-Data-Science:-Probabilidad\" data-toc-modified-id=\"Matemáticas-para-Data-Science:-Probabilidad-1\">Matemáticas para Data Science: Probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Incertidumbre-y-probabilidad\" data-toc-modified-id=\"Incertidumbre-y-probabilidad-1.1\">Incertidumbre y probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Axiomas-de-la-probabilidad\" data-toc-modified-id=\"Axiomas-de-la-probabilidad-1.1.1\">Axiomas de la probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Axioma-1.\" data-toc-modified-id=\"Axioma-1.-1.1.1.1\">Axioma 1.</a></span></li><li><span><a href=\"#Axioma-2.\" data-toc-modified-id=\"Axioma-2.-1.1.1.2\">Axioma 2.</a></span></li><li><span><a href=\"#Axioma-3.\" data-toc-modified-id=\"Axioma-3.-1.1.1.3\">Axioma 3.</a></span></li></ul></li><li><span><a href=\"#Propiedades-que-se-deducen-de-los-axiomas\" data-toc-modified-id=\"Propiedades-que-se-deducen-de-los-axiomas-1.1.2\">Propiedades que se deducen de los axiomas</a></span></li><li><span><a href=\"#Probabilidad-en-Machine-Learning\" data-toc-modified-id=\"Probabilidad-en-Machine-Learning-1.1.3\">Probabilidad en Machine Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fuentes-de-incertidumbre\" data-toc-modified-id=\"Fuentes-de-incertidumbre-1.1.3.1\">Fuentes de incertidumbre</a></span></li></ul></li></ul></li><li><span><a href=\"#Fundamentos-de-probabilidad\" data-toc-modified-id=\"Fundamentos-de-probabilidad-1.2\">Fundamentos de probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tipos-de-probabilidad\" data-toc-modified-id=\"Tipos-de-probabilidad-1.2.1\">Tipos de probabilidad</a></span></li><li><span><a href=\"#Ejemplos-de-cálculo-de-probabilidad\" data-toc-modified-id=\"Ejemplos-de-cálculo-de-probabilidad-1.2.2\">Ejemplos de cálculo de probabilidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Correlaciones-de-eventos\" data-toc-modified-id=\"Correlaciones-de-eventos-1.2.2.1\">Correlaciones de eventos</a></span></li><li><span><a href=\"#Ejercicio-#1\" data-toc-modified-id=\"Ejercicio-#1-1.2.2.2\">Ejercicio #1</a></span></li><li><span><a href=\"#Paradoja-¿niño-o-niña?\" data-toc-modified-id=\"Paradoja-¿niño-o-niña?-1.2.2.3\">Paradoja ¿niño o niña?</a></span></li><li><span><a href=\"#El-problema-de-Monthy-Hall\" data-toc-modified-id=\"El-problema-de-Monthy-Hall-1.2.2.4\">El problema de Monthy Hall</a></span></li></ul></li></ul></li><li><span><a href=\"#Distribuciones-de-probabilidad\" data-toc-modified-id=\"Distribuciones-de-probabilidad-1.3\">Distribuciones de probabilidad</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matemáticas para Data Science: Probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incertidumbre y probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axiomas de la probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado un conjunto de sucesos elementales $\\Omega$, sobre el que se ha definido una $\\sigma$-álgebra $\\sigma$  (familia $\\Sigma$ no vacía de subconjuntos de un conjunto $X$, cerrada bajo complementos, uniones e intersecciones contables) de conjuntos de $\\Omega$ y una función $P$ que asigna valores reales a los miembros de $\\sigma$, a los que denominamos \"sucesos\", se dice que $P$ es una probabilidad sobre $(\\Omega, \\sigma)$ si se cumplen los siguientes 3 axiomas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Axioma 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad de un evento $S$ no puede ser negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$0 \\leq P(S)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Axioma 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad de un evento seguro, $\\Omega$, es igual a 1, denotado simbólicamente como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\Omega) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Axioma 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $E_1, E_2, ...$ son eventos **mutuamente excluyentes** (su intersección es el conjunto vacío), entonces:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(E_1 \\cup E_2 \\cup ...) = \\sum{P(E_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según este axioma se puede calcular la probabilidad de un suceso compuesto de varias alternativas mutuamente excluyentes sumando las probabilidades de sus componentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En términos más formales, una probabilidad es una medida sobre una $\\sigma$-álgebra (sigma-álgebra) de subconjuntos del espacio muestral, siendo los subconjuntos miembros de la $\\sigma$-álgebra los sucesos y definida de tal manera que la medida del total sea 1. Tal medida, gracias a su definición matemática, verifica igualmente los 3 axiomas de Kolmogórov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la terna formada por el **espacio muestral, la $\\sigma$-álgebra y la función de probabilidad** se la denomina **espacio probabilístico** , esto es, un \"espacio de sucesos\" en el que se ha definido los posibles sucesos a considerar (la $ \\sigma$-álgebra) y la probabilidad de cada suceso (la función de probabilidad)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propiedades que se deducen de los axiomas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los axiomas anteriores podemos obtener las siguiente proposiciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $P(\\phi)= 0$ donde el conjunto vacío ($\\phi$) representa en probabilidad el **suceso imposible**.\n",
    "\n",
    "2. Para cualquier evento, $P(E) \\leq 1$.\n",
    "\n",
    "3. $P(A^c) = 1 - P(A)$, donde $A^c$ representa el conjunto complemento de $A$ (todos los elementos que no están en $A$).\n",
    "\n",
    "4. Si $E \\subseteq F$ entonces, $P(E) \\leq P(F)$. Si $E$ es un subconjunto de $F$, la probabilidad de $E$ es menor que la probabilidad de $F$.\n",
    "\n",
    "5. $P(E \\cup F) = P(E) + P(F) - P(E \\cap F)$. Sumamos las probabilidades individuales y restamos la parte en que interseccionan para no contarla 2 veces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad en Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuentes de incertidumbre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Datos**: Para obtener los datos partimos de una obtención o una medición de datos, por lo que esta recolección de datos siempre estará sujeta a ciertos márgenes de error que mantendrán nuestros datos desde un inicio con cierta \"imperfección\" o incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Atributos del modelo**: También llamados **predictores** son un subconjunto o reducción de todas las variables que intervienen en un problema en específico para facilitar la resolución del problema. Es decir, al estudiar un problema complejo usualmente estudiamos ciertas variables que resultan relevantes para nosotros o que creemos que están estrechamente relacionadas con el fenómeno de estudio, pero en realidad puede que estemos dejando muchas variables de lado, las cuales pueden hacer pequeñas contribuciones al problema real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Arquitectura del modelo**: Nuestro modelo al final de cuentas siempre será una versión simplificada de la realidad, de forma que podamos \"aproximar\" el comportamiento que estamos interesados en estudiar. Así que es de esperarse que se \"pierda\" algo de información o exactitud cuando comparemos nuestros resultados arrojados por el modelo vs el fenómeno real. Nuestro trabajo es tratar de aproximarnos lo más posible y minimizar esos errores con modelos más completos y complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, al trabajar con modelos de clasificación trabajamos con probabilidades para deducir a que grupo pertenece cierto elemento de entrada. Aunque nunca tendremos una certeza del 100% si que podremos calcular las probabilidades individuales de que pertenezca a cada uno de los grupos para tomar decisiones más certeras ya que nuestro modelo nos arrojará la opción que nos arroje las probabilidades más altas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un ejemplo de la arquitectura general de un modelo de clasificación supervisada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/sxCngb6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero tenemos nuestra **fase de entrenamiento** donde comenzamos con nuestros datos etiquetados, de forma que tenemos ya ubicados ciertos atributos o features para después pasar por un extractor de atributos de forma que ubica las variables más importantes para que el modelo realice sus predicciones. Una vez pasa por el extractor pasamos de tener un input de cierto tipo a tener únicamente atributos o variables con las que vamos a trabajar. Posteriormente entra en juego nuestro algoritmos de Machine Learning, que variarán dependiendo de la tarea a resolver y que técnicas va a utilizar, pero al final va a arrojarnos un modelo matemático de clasificación que se adaptará según nuestro data set de entrenamiento.\n",
    "\n",
    "Después, en nuestra parte de **predicción** una vez que ya tenemos nuestro modelo de clasificación le pasamos **nuevos datos** con los que va a tratar de hacer predicciones a partir de lo que aprendió de los datos de entrenamiento. Para esto ingresamos nuestros datos, que ya no están necesariamente etiquetados; pasan por el extractor de atributos y a partir de los features que reconoce como más importantes trata de realizar predicciones. De forma que al final del proceso obtenemos una etiqueta que nos índica a que clase pertenece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede que en la mayoría de etapas de nuestro modelo tengamos que trabajar con probabilidades para realizar nuestra predicciones aunque no siempre tiene que ser así, esto dependerá siempre del diseño que elijamos para nuestro algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/6Fy93Tm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que seleccionamos el **diseño** de nuestro modelo procedemos a definir la etapa de entrenamiento, es decir, como va a realizar el proceso de la asignación de los valores de nuestros inputs para ciertos outputs. Usualmente se suele utilizar la estimación por **máxima verosimilitud** o **MLE** por sus siglas en inglés; la cual es una técnica que se usa para ajustar nuestro modelo y estimar sus parámetros, de forma que a partir de esa técnica nuestro modelo aprenderá a asignar probabilidades a cada una de nuestras posibles ocurrencias de nuestros datos. \n",
    "\n",
    "Después pasamos por una **etapa de calibración**, donde lo que calibramos no son nuestros parámetros en sí (de eso ya se encarga el entrenamiento), si no que ahora tratamos de minimizar los errores dados por variables externas al proceso de optimización, es decir, errores que vienen dados por **hiper-parámetros** (parámetros fuera de nuestro esquema de optimización).\n",
    "\n",
    "Finalmente pasamos por un **proceso de interpretación** de la predicción realizada, por que a pesar de que al final lo que estamos obteniendo solo son números o probabilidades, muchas veces viene como resultado de un proceso sumamente complejo y nos puede resultar muy difícil o confuso el interpretar los resultados. Por ejemplo, si estamos recibiendo probabilidades como valores de salida, muchas veces tenemos que reinterpretar esos datos también de forma probabilística para llegar a una conclusión clara."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamentos de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Conjunta (joint)\n",
    "* Marginal\n",
    "* Condicional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a considerar un ejemplo de un lanzamiento de 2 dados para ver las diferentes perspectivas de cada tipo de probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso del lanzamiento de 1 dado tenemos 6 posibles opciones, pero al lanzar 2 dados vamos a tener 36 posibles combinaciones. \n",
    "\n",
    "Podemos imaginarlo como si por cada posible resultado en el dado A tendremos 6 posibles resultados del dado B, por lo que tendremos $6 \\cdot 6$ combinaciones (como si recorrieramos los 6 posibles eventos de B en cada evento de A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/TeWn9rQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, pensemos **¿Cómo calcularíamos la probabilidad de que ambos dados caigan en número par**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como los lanzamientos de los dados son eventos independientes, es decir, obtenemos un resultado en el dado A sin que afecte al dado B. Entonces podemos calcular cual es la probabilidad de que un solo dado caiga en número par, que es una probabilidad de $P(\\text{par}) = \\frac{3}{6}$ y ahora, para cada unos de los 3 posibles casos donde es par en nuestro dado A tendremos otros 3 posibles casos de obtener un número par en nuestro dado B, por lo que lo podemos expresar como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{par}, \\text{par})= \\frac{3}{6} \\cdot \\frac{3}{6} = \\frac{1}{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/XX2tf24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver a la probabilidad anterior como la probabilidad de la **unión de 2 sucesos independientes**. Cuando calculamos probabilidades de 2 o más eventos que ocurren o son estudiados en el mismo experimento se le llama **probabilidad conjunta**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora consideremos la siguiente pregunta, **¿Cuál es la probabilidad de que A caiga par, dado que cayó B en par**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso estamos condicionando el calculo de una probabilidad a que previamente ocurrió otro evento que nos interesa, es decir, en lugar de evaluar las probabilidades sobre todo nuestro espacio muestral $S$, estamos evaluando nuestras probabilidades en un \"sub-espacio muestral\" que solo abarca los eventos en los que ocurrió nuestro evento en B. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma que nuestro espacio muestral pasa de 36 posibilidades a 18 (6 posibles eventos de A y 3 eventos de B donde son pares). Y ahora calculamos nuestra probabilidad de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A=\\text{par}|B=\\text{par}) = \\frac{9}{18} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/xsCliKI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos relacionar estos 2 resultados aparentemente distintos de la siguiente forma. Recordemos que ya calculamos la probabilidad de que ambos resultados sean par y la probabilidad de que un dado sea par dado que el otro también es par.\n",
    "\n",
    "Ahora vamos a preguntarnos. **¿Cuál es la probabilidad de que B sea par?** De nuevo es una probabilidad independiente de lo que ocurre en A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(B) = \\frac{18}{36} = \\frac{1}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que si nos damos cuenta, la probabilidad de dicho evento es la suma de nuestras columnas amarillas de la imagen de arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y pongamos atención en que pasa al multiplicar nuestra $P(B) \\cdot P(A|B)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(B) \\cdot P(A|B) = \\frac{18}{36} \\cdot \\frac{9}{18} = \\frac{9}{36} = \\frac{1}{4} = P(\\text{par}, \\text{par})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "es decir, al multiplicar la probabilidad de nuestro evento B por la probabilidad de nuestro evento A dado B, obtenemos la **probabilidad conjunta**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hecho, esto anterior no es un caso particular sino que se le conoce como la **regla del producto** que dice lo siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A,B) = P(A|B)P(B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o escrita de una forma en la que no la vamos a encontrar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(A|B) = \\frac{P(A \\cap B)}{P(B)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hablemos sobre la **probabilidad marginal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con probabilidad marginal nos referimos a cuando obtenemos una probabilidad \"sencilla\" a partir de una probabilidad conjunta. Es decir, la probabilidad de un evento simple que es independiente al resto de eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y se expresa de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p_x(x) = \\sum_{y}{P(x,y)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad marginal de $x$ es la suma de todas las probabilidades conjuntas sobre los demás estados que no consideran a $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos definir cíclicamente a la probabilidad marginal a partir de la conjunta y la condicional o a la condicional en términos de la conjunta y la marginal, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos de cálculo de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlaciones de eventos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados los siguientes 3 eventos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A = {el resultado de lanzar un dado es 4}\n",
    "* B = {el resultado de lanzar un dado es par}\n",
    "* C = {el resultado de lanzar un dado es impar}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos **cual es la probabilidad de que ocurra A**:\n",
    "\n",
    "$$P(A) = \\frac{1}{6}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la **probabilidad de A dado que ocurrió B**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|B) = \\frac{1}{3} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entre 3 ya que el evento B reduce el espacio a 3 eventos posibles donde es par, mientras que el evento A solo forma parte de 1 solo de esos eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, calculemos la **probabilidad de A dado C**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C reduce nuestro espacio a los casos donde sale {1, 3, 5}, pero A es el evento {4}. Por lo que tenemos eventos excluyentes y se interseccionan en el vacío"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos decir que A y C están negativamente coorelacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|C) = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una probabilidad igual a 0 dice que los eventos son **excluyentes**, pero NO nos está diciendo que sean **independientes**. De hecho, como vimos en el caso anterior, son altamente dependientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{excluyente} \\not= \\text{independiente}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para el siguiente ejemplo consideremos un juego de ruleta de casino que puede tomar 8 valores y donde tenemos a los siguientes 2 jugadores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/2c2ZYR7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, los eventos donde ganar el jugador 1 y donde gana el jugador 2 son **mutuamente excluyentes**, es decir, si gana uno el otro pierde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos preguntarnos, ¿Cuál es la probabilidad de que gane el jugador 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(W_1) = \\frac{4}{8} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o, ¿Cuál es la probabilidad de que gane 1 sabiendo que ganó 2 (dado que ocurrieron eventos de el conjunto B)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(W_1 | B) = \\frac{0}{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para ponerlo un poquito más interesante el jugador 2 cambia su conjunto B por el conjunto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$C = {4,5,6,7}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y repetimos la misma pregunta, ¿Cuál es la probabilidad de que gane 1 dado que ocurrieron eventos del conjunto C?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que C reduce nuestro espacio muestral a 4 posibles eventos {4,5,6,7} y de esos eventos A solo contiene a {4}, por lo que podemos deducirlo rápidamente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(W_1|C)= \\frac{1}{4}= 25\\%$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debido a que, sabiendo que el jugador 2 ganó podemos encontrar una menor posibilidad de que el jugador 1 haya ganado decimos que estos eventos están **negativamente relacionados**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el jugador 1 mantiene su conjunto de eventos $\\{1,2,3,4\\}$ y el jugador 2 cambia su conjunto a $\\{2,3,6,7\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es la probabilidad de que gane el jugador 1 sabiendo que ganó el jugador 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|B) = \\frac{2}{4} = 50\\%$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paradoja ¿niño o niña?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos las siguientes frases:\n",
    "\n",
    "* Una mujer tiene 2 bebés donde el mayor es un varón.\n",
    "* Una mujer tiene 2 bebés donde uno de ellos es varón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de que parece el mismo enunciado o que se refiere a lo mismo, contiene una pequeña diferencia gramatical que nos brinda información adicional. De forma que al realizar el calculo de las probabilidades tendremos una diferencia al realizar el conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a empezar con la siguiente pregunta, **¿Cuál es la probabilidad de que esta mujer tenga 2 hijos varones?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un inicio, sin tener en cuenta factores externos, tenemos un 50% de probabilidad de que nazca un niño y 50% de que nazca una niña en cada nacimiento. Por lo que podemos expresar al nacimiento de 2 niños de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{v,v})= \\frac{1}{2} \\cdot \\frac{1}{2}= \\frac{1}{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, volviendo a nuestro ejemplo donde una sola mujer tiene 2 bebés podemos tener el siguiente espacio muestral:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/vDU7yiI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando consideramos el **primer enunciado**, es decir, cuando **el mayor es varón**, reducimos nuestro espacio muestral al siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/TvrTPAj.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que la probabilidad de que el siguiente también sea varón es de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{v,v}) = P(\\text{v}|M_\\text{varon})= \\frac{1}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver que pasa en el **segundo enunciado**, donde **uno de ellos** es varón. En ese caso nuestro espacio se restringe al siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/8b6OCsY.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que nuestra probabilidad de que uno de ellos sea varón es de:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(v,v) = \\frac{1}{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El problema de Monthy Hall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema salió de un show de TV donde se tenía a un participante que tenia en frente 3 puertas y una de ellas contenía un premio. Entonces, el participante tenía que elegir una puerta cualquiera tratando de atinarle a la puerta correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/YZ5DLIy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que inicialmente tenía una probabilidad de $\\frac{1}{3}$ de atinarle a la puerta correcta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dinámica del programa consistía en que primero el participante seleccionaba una puerta y antes de que supiera si el premio estaba ahí o no, llegaba el presentador y abría otra puerta donde no estaba el premio, de forma que el participante se quedaba con 2 opciones, podía mantener su elección o hacer un cambio hacía la puerta restante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitivamente podríamos caer en el pensamiento de decir, \"tengo 2 puertas y en 1 de ellas está el premio, por lo que realice o no el cambio de puerta sigo teniendo la misma probabilidad del 50% de atinarle a la correcta\".\n",
    "\n",
    "Y justo aquí es donde está la paradoja por qué resulta que no funciona así. Veamos por qué"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En realidad, la confusión viene al tratar el problema como si pasaramos a tener un nuevo espacio muestral donde ahora solo tenemos 2 puertas y regresamos a un $50\\%$ de probabilidad de atinarle. La realidad es que seguimos teniendo nuestro espacio de 3 puertas, pero ahora con información extra. Vamos a ver los casos posibles que tenemos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/Amyh17E.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a verlo desde otra perspectiva, ¿cuál es la probabilidad de que nosotros hayamos elegido una puerta incorrecta? Esta probabilidad sería de $\\frac{2}{3} \\approx 0.66$. Entonces, es mucho más probable que nosotros hayamos elegido una puerta incorrecta, ¿no?\n",
    "\n",
    "Así que, como también sabemos, el presentador siempre abrirá una puerta que también es la incorrecta por lo que en 2 de 3 posibles casos vamos a dar con la puerta correcta al hacer el cambio, es decir, escogemos una incorrecta y el presentador abre la incorrecta y por lo tanto, al hacer el cambio damos con el premio. Por el otro lado, solo hay 1 caso de 3 en donde al hacer el cambio pasamos de la puerta correcta a la incorrecta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned}\n",
    "P(\\text{win}|\\text{stay}) = \\frac{1}{3} \\\\\n",
    "P(\\text{win}|\\text{switch}) = \\frac{2}{3}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluimos que tenemos más probabilidad de ganar si hacemos el cambio de puerta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a incorporar un poco de cálculo en Probabilidad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de contenido 💜",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.273px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
