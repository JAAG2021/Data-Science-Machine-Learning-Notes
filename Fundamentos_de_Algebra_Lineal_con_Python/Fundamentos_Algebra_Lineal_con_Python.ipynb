{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de contenidos 💜<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Fundamentos-de-Álgebra-lineal-con-Python\" data-toc-modified-id=\"Fundamentos-de-Álgebra-lineal-con-Python-0\">Fundamentos de Álgebra lineal con Python</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conceptos-básicos\" data-toc-modified-id=\"Conceptos-básicos-0.1\">Conceptos básicos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Escalar\" data-toc-modified-id=\"Escalar-0.1.1\">Escalar</a></span></li><li><span><a href=\"#Vector\" data-toc-modified-id=\"Vector-0.1.2\">Vector</a></span></li><li><span><a href=\"#Matriz\" data-toc-modified-id=\"Matriz-0.1.3\">Matriz</a></span></li><li><span><a href=\"#Tensor\" data-toc-modified-id=\"Tensor-0.1.4\">Tensor</a></span></li></ul></li><li><span><a href=\"#Operaciones-básicas\" data-toc-modified-id=\"Operaciones-básicas-0.2\">Operaciones básicas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dimensión-de-un-escalar,-vector,-matriz-o-tensor\" data-toc-modified-id=\"Dimensión-de-un-escalar,-vector,-matriz-o-tensor-0.2.1\">Dimensión de un escalar, vector, matriz o tensor</a></span></li><li><span><a href=\"#Transposición\" data-toc-modified-id=\"Transposición-0.2.2\">Transposición</a></span></li><li><span><a href=\"#Suma-de-matrices\" data-toc-modified-id=\"Suma-de-matrices-0.2.3\">Suma de matrices</a></span></li><li><span><a href=\"#Suma-de-matrices-y-vectores-con-dimensiones-distintas-(broadcasting)\" data-toc-modified-id=\"Suma-de-matrices-y-vectores-con-dimensiones-distintas-(broadcasting)-0.2.4\">Suma de matrices y vectores con dimensiones distintas (broadcasting)</a></span></li></ul></li><li><span><a href=\"#Operaciones-con-matrices\" data-toc-modified-id=\"Operaciones-con-matrices-0.3\">Operaciones con matrices</a></span><ul class=\"toc-item\"><li><span><a href=\"#Producto-interno-de-matrices-y--vectores\" data-toc-modified-id=\"Producto-interno-de-matrices-y--vectores-0.3.1\">Producto interno de matrices y  vectores</a></span></li><li><span><a href=\"#Producto-interno-entre-2-matrices\" data-toc-modified-id=\"Producto-interno-entre-2-matrices-0.3.2\">Producto interno entre 2 matrices</a></span></li><li><span><a href=\"#Propiedades-de-las-matrices\" data-toc-modified-id=\"Propiedades-de-las-matrices-0.3.3\">Propiedades de las matrices</a></span><ul class=\"toc-item\"><li><span><a href=\"#Asociativa\" data-toc-modified-id=\"Asociativa-0.3.3.1\">Asociativa</a></span></li><li><span><a href=\"#Distributiva:\" data-toc-modified-id=\"Distributiva:-0.3.3.2\">Distributiva:</a></span></li><li><span><a href=\"#Conmutativa:\" data-toc-modified-id=\"Conmutativa:-0.3.3.3\">Conmutativa:</a></span></li></ul></li><li><span><a href=\"#Conmutatividad-en-producto-interno-de-vectores\" data-toc-modified-id=\"Conmutatividad-en-producto-interno-de-vectores-0.3.4\">Conmutatividad en producto interno de vectores</a></span></li><li><span><a href=\"#Transposición-del-producto-de-matrices\" data-toc-modified-id=\"Transposición-del-producto-de-matrices-0.3.5\">Transposición del producto de matrices</a></span></li><li><span><a href=\"#Cómo-comprobar-la-solución-de-un-sistema-de-ecuaciones-lineales\" data-toc-modified-id=\"Cómo-comprobar-la-solución-de-un-sistema-de-ecuaciones-lineales-0.3.6\">Cómo comprobar la solución de un sistema de ecuaciones lineales</a></span><ul class=\"toc-item\"><li><span><a href=\"#Combinación-lineal\" data-toc-modified-id=\"Combinación-lineal-0.3.6.1\">Combinación lineal</a></span></li><li><span><a href=\"#Ecuación-lineal\" data-toc-modified-id=\"Ecuación-lineal-0.3.6.2\">Ecuación lineal</a></span></li><li><span><a href=\"#Sistema-de-ecuaciones-lineales\" data-toc-modified-id=\"Sistema-de-ecuaciones-lineales-0.3.6.3\">Sistema de ecuaciones lineales</a></span></li></ul></li><li><span><a href=\"#Tipos-especiales-de-matrices:-Identidad,-Inversa-y-Singular\" data-toc-modified-id=\"Tipos-especiales-de-matrices:-Identidad,-Inversa-y-Singular-0.3.7\">Tipos especiales de matrices: Identidad, Inversa y Singular</a></span><ul class=\"toc-item\"><li><span><a href=\"#Matriz-Identidad\" data-toc-modified-id=\"Matriz-Identidad-0.3.7.1\">Matriz Identidad</a></span></li><li><span><a href=\"#Matriz-Inversa\" data-toc-modified-id=\"Matriz-Inversa-0.3.7.2\">Matriz Inversa</a></span></li><li><span><a href=\"#Matriz-Singular\" data-toc-modified-id=\"Matriz-Singular-0.3.7.3\">Matriz Singular</a></span></li></ul></li><li><span><a href=\"#Utilizando-la-Inversa-de-una-matriz-para-resolver-un-sistema-de-ecuaciones\" data-toc-modified-id=\"Utilizando-la-Inversa-de-una-matriz-para-resolver-un-sistema-de-ecuaciones-0.3.8\">Utilizando la Inversa de una matriz para resolver un sistema de ecuaciones</a></span></li></ul></li><li><span><a href=\"#Sistemas-de-ecuaciones-lineales\" data-toc-modified-id=\"Sistemas-de-ecuaciones-lineales-0.4\">Sistemas de ecuaciones lineales</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ejemplos-de-sistemas-sin-solución,-con-una-solución-y-con-infinitas-soluciones\" data-toc-modified-id=\"Ejemplos-de-sistemas-sin-solución,-con-una-solución-y-con-infinitas-soluciones-0.4.1\">Ejemplos de sistemas sin solución, con una solución y con infinitas soluciones</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sistema-Incompatible-(sin-soluciones)\" data-toc-modified-id=\"Sistema-Incompatible-(sin-soluciones)-0.4.1.1\">Sistema Incompatible (sin soluciones)</a></span></li><li><span><a href=\"#Sistema-Compatible\" data-toc-modified-id=\"Sistema-Compatible-0.4.1.2\">Sistema Compatible</a></span></li></ul></li><li><span><a href=\"#Graficar-vectores\" data-toc-modified-id=\"Graficar-vectores-0.4.2\">Graficar vectores</a></span></li><li><span><a href=\"#¿Qué-es-una-combinación-lineal?\" data-toc-modified-id=\"¿Qué-es-una-combinación-lineal?-0.4.3\">¿Qué es una combinación lineal?</a></span></li><li><span><a href=\"#¿Qué-es-un-espacio-y-un-subespacio?\" data-toc-modified-id=\"¿Qué-es-un-espacio-y-un-subespacio?-0.4.4\">¿Qué es un espacio y un subespacio?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Condiciones-necesarias-y-suficientes-para-definir-un-subespacio\" data-toc-modified-id=\"Condiciones-necesarias-y-suficientes-para-definir-un-subespacio-0.4.4.1\">Condiciones necesarias y suficientes para definir un subespacio</a></span></li><li><span><a href=\"#Conjunto-generador\" data-toc-modified-id=\"Conjunto-generador-0.4.4.2\">Conjunto generador</a></span></li></ul></li><li><span><a href=\"#Vectores-linealmente-Independientes\" data-toc-modified-id=\"Vectores-linealmente-Independientes-0.4.5\">Vectores linealmente Independientes</a></span></li><li><span><a href=\"#Validar-que-una-matriz-tenga-inversa\" data-toc-modified-id=\"Validar-que-una-matriz-tenga-inversa-0.4.6\">Validar que una matriz tenga inversa</a></span></li></ul></li><li><span><a href=\"#Norma\" data-toc-modified-id=\"Norma-0.5\">Norma</a></span><ul class=\"toc-item\"><li><span><a href=\"#¿Qué-es-una-norma-y-para-qué-se-usa?-Desigualdad-triangular\" data-toc-modified-id=\"¿Qué-es-una-norma-y-para-qué-se-usa?-Desigualdad-triangular-0.5.1\">¿Qué es una norma y para qué se usa? Desigualdad triangular</a></span><ul class=\"toc-item\"><li><span><a href=\"#Propiedades\" data-toc-modified-id=\"Propiedades-0.5.1.1\">Propiedades</a></span></li></ul></li><li><span><a href=\"#Tipos-de-normas:-norma-0,-norma-1,-norma-2,-norma-infinito-y-norma-L2-al-cuadrado\" data-toc-modified-id=\"Tipos-de-normas:-norma-0,-norma-1,-norma-2,-norma-infinito-y-norma-L2-al-cuadrado-0.5.2\">Tipos de normas: norma 0, norma 1, norma 2, norma infinito y norma L2 al cuadrado</a></span><ul class=\"toc-item\"><li><span><a href=\"#L0\" data-toc-modified-id=\"L0-0.5.2.1\">L0</a></span></li><li><span><a href=\"#L1\" data-toc-modified-id=\"L1-0.5.2.2\">L1</a></span></li><li><span><a href=\"#L2\" data-toc-modified-id=\"L2-0.5.2.3\">L2</a></span></li><li><span><a href=\"#$L2^2$\" data-toc-modified-id=\"$L2^2$-0.5.2.4\">$L2^2$</a></span></li><li><span><a href=\"#$L-\\infty$\" data-toc-modified-id=\"$L-\\infty$-0.5.2.5\">$L \\infty$</a></span></li></ul></li><li><span><a href=\"#El-producto-interno-como-función-de-una-norma-y-su-visualización\" data-toc-modified-id=\"El-producto-interno-como-función-de-una-norma-y-su-visualización-0.5.3\">El producto interno como función de una norma y su visualización</a></span></li><li><span><a href=\"#VIDEO:-Similaridad-coseno\" data-toc-modified-id=\"VIDEO:-Similaridad-coseno-0.5.4\">VIDEO: Similaridad coseno</a></span></li></ul></li><li><span><a href=\"#Matrices-y-vectores-especiales\" data-toc-modified-id=\"Matrices-y-vectores-especiales-0.6\">Matrices y vectores especiales</a></span><ul class=\"toc-item\"><li><span><a href=\"#La-matriz-diagonal\" data-toc-modified-id=\"La-matriz-diagonal-0.6.1\">La matriz diagonal</a></span></li><li><span><a href=\"#Matriz-simétrica\" data-toc-modified-id=\"Matriz-simétrica-0.6.2\">Matriz simétrica</a></span></li><li><span><a href=\"#Vectores-ortogonales,-matrices-ortogonales-y-sus-propiedades\" data-toc-modified-id=\"Vectores-ortogonales,-matrices-ortogonales-y-sus-propiedades-0.6.3\">Vectores ortogonales, matrices ortogonales y sus propiedades</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vectores-Ortogonales\" data-toc-modified-id=\"Vectores-Ortogonales-0.6.3.1\">Vectores Ortogonales</a></span></li><li><span><a href=\"#Vectores-Ortonormales\" data-toc-modified-id=\"Vectores-Ortonormales-0.6.3.2\">Vectores Ortonormales</a></span></li></ul></li><li><span><a href=\"#Matrices-ortogonales-y-sus-propiedades\" data-toc-modified-id=\"Matrices-ortogonales-y-sus-propiedades-0.6.4\">Matrices ortogonales y sus propiedades</a></span><ul class=\"toc-item\"><li><span><a href=\"#Matriz-de-rotación\" data-toc-modified-id=\"Matriz-de-rotación-0.6.4.1\">Matriz de rotación</a></span></li></ul></li></ul></li><li><span><a href=\"#El-determinante-y-la-traza\" data-toc-modified-id=\"El-determinante-y-la-traza-0.7\">El determinante y la traza</a></span><ul class=\"toc-item\"><li><span><a href=\"#Determinante\" data-toc-modified-id=\"Determinante-0.7.1\">Determinante</a></span></li><li><span><a href=\"#Traza\" data-toc-modified-id=\"Traza-0.7.2\">Traza</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ArqM3v4Prsa"
   },
   "source": [
    "# Fundamentos de Álgebra lineal con Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rZTAWNHbHd7"
   },
   "source": [
    "## Conceptos básicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQ_RxEzUbwme"
   },
   "source": [
    "### Escalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h45LCAh7dMQu"
   },
   "source": [
    "Se denomina **escalar** a los números reales, constantes o complejos que sirven para describir un fenómeno físico (o de otro tipo) con magnitud, pero sin la característica *vectorial* de la dirección. Más formalmente, **es un tensor de orden cero**.\n",
    "\n",
    "En términos matemáticos, se llama **escalar** a los elementos de un *cuerpo* (en algunos casos también a los elementos de un anillo), generalmente números, y en particular se usa con vectores en álgebra lineal y en cualquier rama que use *módulos* o *espacios vectoriales*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqjY2wLWdzLq"
   },
   "source": [
    "Al trabajar en Python con escalares tenemos de muchos tipos, por ejemplo, **enteros**, **flotantes**, **complejos**, **string** o **null/non-type**, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrVjCsXmdl4e",
    "outputId": "afec4022-0097-47c0-9dde-280bab804233"
   },
   "outputs": [],
   "source": [
    "escalar_int = 5\n",
    "print(escalar_int)\n",
    "print(type(escalar_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlUH_6VddxA6",
    "outputId": "cc718110-5c8e-4e4c-8003-4796aaf683da"
   },
   "outputs": [],
   "source": [
    "escalar_float = 3.1416\n",
    "print(escalar_float)\n",
    "print(type(escalar_float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VCmLRW32eK0I",
    "outputId": "e80ff0cc-5687-49ad-e498-1bfea385356b"
   },
   "outputs": [],
   "source": [
    "escalar_bool = True\n",
    "print(escalar_bool)\n",
    "print(type(escalar_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgItgc5oeQQj",
    "outputId": "8734922e-0a12-457e-8625-1d021519cd8e"
   },
   "outputs": [],
   "source": [
    "import cmath\n",
    "escalar_complex = complex(5, 3)\n",
    "print(escalar_complex)\n",
    "print(type(escalar_complex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hG8ogn0gf8RR"
   },
   "source": [
    "### Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWlRQDoIf9s5"
   },
   "source": [
    "Es un énte matemático como la *recta* o el *plano*. Se puede representar mediante un segmento de recta, orientado dentro del *espacio euclidiano tridimensional*. Ek vectir tiene 3 elementos:\n",
    "\n",
    "* Módulo (cuánto mide)\n",
    "* Dirección (ángulo respecto a algún eje)\n",
    "* Sentido (hacía donde \"apunta\" la cabeza de la flecha)\n",
    "\n",
    "En matemáticas se define al vector como **un elemento de un espacio vectorial**. Esta noción es más abstracta y para muchos espacios vectoriales no es posible representar sus vectores mediante el módulo y la dirección. En particular los espacios de dimensión infinita sin producto escalar no son representables de ese modo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SO4g1bLJg8VL"
   },
   "source": [
    "Se llama **vector** de dimensión $n$ a una **tupla** de números reales (que se llaman componentes del vector). El conjunto de todos los vectores de dimensión se representa cómo $\\mathbb{R}^n$ (formado mediante el producto cartesiano).\n",
    "\n",
    "Así, un vector $v$ perteneciente a un espacio $\\mathbb{R}$ se representa como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJ82nmPZhbfs"
   },
   "source": [
    "$$ v = (a_1, a_2, a_3, ... ,a_n),\\text{donde } v \\in \\mathbb{R}^n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdLKEbAchcN-"
   },
   "source": [
    "Podemos ver al vector como un *conjunto de números*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HyhFwYb7fC1S",
    "outputId": "be90253b-77c0-4bf1-def5-7f9c55aca051"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Vector Columna\n",
    "column_vector = np.array([[1],[2],[3]])\n",
    "print(column_vector)\n",
    "print(type(column_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBt4D69YiYom",
    "outputId": "81210bae-810a-49bd-ffae-ed014aaaca3b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Vector Fila\n",
    "row_vector = np.array([1,2,3])\n",
    "print(row_vector)\n",
    "print(type(row_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfbmZeMriw9Y"
   },
   "source": [
    "### Matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqPnyoNFiz9l"
   },
   "source": [
    "En matemáticas, una **matriz** es un *arreglo bidimensional de números*. Dado que puede definirse tanto la suma como el producto de matrices, en mayor generalidad se dice que son **elementos de un anillo**. Una matriz se representa por medio de una letra mayúscula $(A,B, \\dots)$ y sus elementos con la misma letra en minúscula $(a,b,\\dots)$, con un doble subíndice, donde el primero indica la fila y el segundo la columna a la que pertenece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mf3MUk29izWv"
   },
   "source": [
    "$$A = \n",
    "\\begin{pmatrix}\n",
    "a_{11} & a_{12} & \\dots & a_{1n} \\\\\n",
    "a_{21} & a_{22} & \\dots & a_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{m1} & a_{m2} & \\dots & a_{mn} \\\\\n",
    "\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SKfZQOTlC26"
   },
   "source": [
    "Siempre que 2 matrices tengan el mismo número de filas y de columnas, pueden sumarse o restarse elemento por elemento.\n",
    "\n",
    "Las matrices sirven para representar las coeficientes de los sistemas de ecuaciones lineales o para representar transformaciones lineales dadas una base.\n",
    "\n",
    "Pueden sumarse, multiplicarse y descomponerse de varias formas, lo que también las hace un concepto clave en el campo del álgebra lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cFzlOqHxnYAJ",
    "outputId": "ef04994c-f343-45de-d58e-44e8a463fccf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "matrix = np.array([\n",
    "                   [0, 1, 2 ,3],\n",
    "                   [3, 2, 1, 0],\n",
    "                   [1, 2, 3, 4],\n",
    "                   [3, 2, 1, 0]\n",
    "])\n",
    "\n",
    "print(matrix)\n",
    "print(type(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36dImWdwldTy"
   },
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTp1OnhAlevF"
   },
   "source": [
    "Un **tensor** es cierta clase de entidad  algebraica de varios componentes que generalizan los conceptos de escalar, vector y matriz **de manera que sea independiente de cualquier sistema de coordenadas**. Se suele utilizar el convenio se **suma de Einstein**.\n",
    "\n",
    "Una vez elegida la base vectorial, los componentes de un tensor en una base vendrán dadas por una **multi-matriz**. El orden del tensor será el número de índices necesarios para especificar sin ambigüedad un componente de un tensor: \n",
    "\n",
    "* Un **escalar** será considerado como un tensor de orden 0.\n",
    "* Un **vecor** será considerado como un tensor de orden 1.\n",
    "* Y dada una *base vectorial*, los tensores de segundo orden pueden ser representados por una **matriz**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25xyl56dpa4i"
   },
   "source": [
    "![](https://miro.medium.com/max/891/0*jGB1CGQ9HdeUwlgB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rD5S95zIoKNi"
   },
   "source": [
    "Podemos ver al tensor como varias matrices acomodadas en \"capas\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdLDQGUjnz0_",
    "outputId": "5384d5c4-902b-4c06-bea6-c6011a625679"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tensor = np.array([\n",
    "                   [ [11,22,33],  [44,55,66],   [77,88,99]    ],\n",
    "                   [ [99,368,777],[666,555,444],[333,222,111] ],\n",
    "                   [ [13,297,306],[546,58,642], [27,328,943]  ]\n",
    "])\n",
    "print(tensor)\n",
    "print(type(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "723Uwk3ooZP5"
   },
   "source": [
    "Vamos a visualizar nuestro tensor, **suponiendo** que los datos que tenemos son los que representan a una imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "n3AMZePloe2B",
    "outputId": "df32b415-d74f-43f4-f641-7dbdbc5f8dca"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(tensor, interpolation='nearest')\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ki-gAhkqesVr"
   },
   "source": [
    "Podemos decir que en lo que se diferencian nuestros elementos como los escalares, vectores, matrices y tensores es en los *grados de libertad que tenemos para interactuar con ellos*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGEjSb1TjMJM"
   },
   "source": [
    "![](https://i.imgur.com/vDwWVp9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXVt09Mqp1Ib"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Xy8Pndop2uu"
   },
   "source": [
    "## Operaciones básicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fu4-yX6FHnc5"
   },
   "source": [
    "### Dimensión de un escalar, vector, matriz o tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0vHD_5-HucJ"
   },
   "source": [
    "En álgebra lineal es importante tener en consideración las dimensiones que tienen nuestras matrices, vectores y tensores. Ya que algunas veces, de ello dependerá si las operaciones entre ellos están definidas o no. Por ejemplo, en el caso de una multiplicación de una matriz por un vector (producto interno), tenemos que coincidir en la dimensión de nuestro vector con la cantidad de filas que tiene nuestra matriz.\n",
    "\n",
    "De forma que se cumple que, si tenemos una matriz de $m\\times n$ por un vector columna $n\\times 1$, entonces obtendremos de resultado un vector fila de $m \\times 1$ (más adelante veremos este tema con calma)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-Azhm4RKwBq"
   },
   "source": [
    "$$\\begin{align*}\n",
    "  A\\cdot {x}=\n",
    "  \\left[\n",
    "    \\begin{array}{cccc}\n",
    "      a_{11} & a_{12} & \\ldots & a_{1n}\\\\\n",
    "      a_{21} & a_{22} & \\ldots & a_{2n}\\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "      a_{m1} & a_{m2} & \\ldots & a_{mn}\n",
    "    \\end{array}\n",
    "  \\right]\n",
    "  \\left[\n",
    "    \\begin{array}{c}\n",
    "      x_1\\\\\n",
    "      x_2\\\\\n",
    "      \\vdots\\\\\n",
    "      x_n\n",
    "    \\end{array}\n",
    "  \\right]\n",
    "  =\n",
    "  \\left[\n",
    "    \\begin{array}{c}\n",
    "      a_{11}x_1+a_{12}x_2 + \\cdots + a_{1n} x_n\\\\\n",
    "      a_{21}x_1+a_{22}x_2 + \\cdots + a_{2n} x_n\\\\\n",
    "      \\vdots\\\\\n",
    "      a_{m1}x_1+a_{m2}x_2 + \\cdots + a_{mn} x_n\\\\\n",
    "    \\end{array}\n",
    "  \\right].\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbZ4iC2ILFct"
   },
   "source": [
    "Entonces, es importante conocer las dimensiones de nuestros `arrays`, y para ello tenemos el método `.shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBfkqNKjIuKl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "scalar = 5.679\n",
    "row_vector = np.array([1,2,3])\n",
    "column_vector = np.array([[1],\n",
    "                          [2],\n",
    "                          [3]])\n",
    "matrix = np.array([[1,2],\n",
    "                   [2,3]])\n",
    "tensor = np.array([\n",
    "                   [ [11,22,33],  [44,55,66],   [77,88,99]    ],\n",
    "                   [ [99,368,777],[666,555,444],[333,222,111] ],\n",
    "                   [ [13,297,306],[546,58,642], [27,328,943]  ]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDVx4q6jLUE6"
   },
   "source": [
    "El siguiente error ocurre por que el escalar es considerado un tensor de dimensión 0, es decir, no tiene dimensión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "8tM8_UGcJ0Oq",
    "outputId": "817a0c76-dba3-4816-9456-cc374c671947"
   },
   "outputs": [],
   "source": [
    "scalar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dshxNlKMgo9"
   },
   "source": [
    "Vamos a ver la dimensión del resto de elementos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y5DsXlQSLOl-",
    "outputId": "a78e1ebe-cf80-4e9f-b04e-1e2c987ac5ec"
   },
   "outputs": [],
   "source": [
    "row_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpy6QJfgMNdq",
    "outputId": "57e6b9a7-ce87-43ce-ba0a-650a942d9de0"
   },
   "outputs": [],
   "source": [
    "column_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NjZmzppjMSP-",
    "outputId": "93d1a960-f43d-4981-aca0-c7d69fcac52f"
   },
   "outputs": [],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxfg2p28MVA5",
    "outputId": "2f70871b-f009-4dcc-b572-e97b90ac0909"
   },
   "outputs": [],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3OX9nzwMWBo"
   },
   "source": [
    "¿Qué pasa si utilizamos `len()` en lugar de `shape`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZE-wGxQEM4yb",
    "outputId": "b5748e84-30fb-4c83-c2cf-cdd28262522d"
   },
   "outputs": [],
   "source": [
    "len(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fgna_htNAKZ"
   },
   "source": [
    "Solo nos devuelve la longitud de la primera parte del arreglo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZGEjq4FNFHU"
   },
   "source": [
    "¿ Y qué pasaría si utilizamos `.size`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlzRdrcbNMT7",
    "outputId": "2765f8e6-0ff5-40bf-dce5-64a1dbf435fe"
   },
   "outputs": [],
   "source": [
    "tensor.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVsyNisWNOql"
   },
   "source": [
    "Nos devuelve la multiplicación de las dimensiones (total de elementos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbid7WSKNTcz"
   },
   "source": [
    "La representación `(3,3,3)` de un tensor la podemos interpretar como 3 filas, 3 columnas y 3 matrices de 3x3 \"superpuestas\" unas de otras.\n",
    "\n",
    "Por ejemplo, si en una matriz 3x3 podemos representar una imagen; entonces, en un tensor de 3x3x3 podemos representar un video de 3 fotogramas. De esta forma podríamos pensar en un tensor como **la evolución de una matriz en el tiempo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ae0T_tkOIN5"
   },
   "source": [
    "![](https://i.postimg.cc/25f2FS5P/Capture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsTXWM8COtHC"
   },
   "source": [
    "### Transposición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando hablamos de la transposición de una matriz, nos referimos al proceso de \"voltear\" una matriz, es decir, intercambiar filas por columnas. En realidad es una operación muy sencilla de hacer, pero con un montón de aplicaciones importantes.\n",
    "\n",
    "Por ejemplo, si tenemos una matriz de $3 \\times 2$ y la transponemos, obtendremos una matriz $2 \\times 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer un proceso similar con los vectores. Por ejemplo, si tenemos un vector fila y hacemos la transposición, entonces obtendremos un vector columna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar la transposición, estamos haciendo una especie de \"espejo\" alrededor de la diagonal, por lo que **los elementos de la diagonal se mantienen iguales**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.postimg.cc/GtrCWCzN/Capture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "scalar = 5.679\n",
    "row_vector = np.array([1,2,3])\n",
    "column_vector = np.array([[1],\n",
    "                          [2],\n",
    "                          [3]])\n",
    "matrix = np.array([[1,2,4],\n",
    "                   [2,3,4],\n",
    "                   [6,5,8]])\n",
    "tensor = np.array([\n",
    "                   [ [11,22,33],  [44,55,66],   [77,88,99]    ],\n",
    "                   [ [99,368,777],[666,555,444],[333,222,111] ],\n",
    "                   [ [13,297,306],[546,58,642],   [27,328,943]],\n",
    "                   [ [56,67,89],  [111,231,333],  [77,88,99]  ]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar una transposición utilizamos el atributo `.T` de los `narray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_row_vec = row_vector.T\n",
    "print(f'Vector original:\\n{row_vector}\\nVector Transpuesto:\\n{T_row_vec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que en el caso del vector fila lo mantendrá igual, al menos de que realicemos operaciones con el."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_col_vec = column_vector.T\n",
    "print(f'Vector original:\\n{column_vector}\\nVector Transpuesto:\\n{T_col_vec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en el caso del vector columna si vemos como lo pasa a un vector fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix = matrix.T\n",
    "print(f'Matriz original:\\n{matrix}\\nMatriz Transpuesta:\\n{T_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver como nuestras filas de la matriz original pasan a ser las nuevas columnas y viceversa con las columnas originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_tensor = tensor.T\n",
    "print(f'Tensor original:\\n{tensor}\\n\\nTensor Transpuesto:\\n{T_tensor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que el Tensor es una generalización del mismo objeto matemático que la matriz, en este caso vamos a ir tomando elemento por elemento de la primera columna para formar la nueva fila y así hasta recorrerlas todas.\n",
    "\n",
    "En este caso en particular vemos como pasamos de tener \"4 matrices de 3x3 concatenadas\", a tener \"3 matrices de 4x3 concatenadas\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si aplicamos 2 veces la transposición de una matriz, obtendremos la misma matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$(A^{T})^T = A$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix = matrix.T\n",
    "T_T_matrix = T_matrix.T\n",
    "print(f'Matriz original:\\n{matrix}\\nMatriz doblemente Transpuesta:\\n{T_T_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es de mucha ayuda en la resolución de ecuaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suma de matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suma de matrices está definida cuando los objetos tienen las mismas dimensiones, y para sumar (o restar) 2 matrices basta con sumar cada uno de los elementos con el mismo subíndice. De la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align*}\n",
    "A + B =\n",
    "  \\left[\n",
    "    \\begin{array}{cccc}\n",
    "      a_{11} & a_{12} & \\ldots & a_{1n}\\\\\n",
    "      a_{21} & a_{22} & \\ldots & a_{2n}\\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "      a_{m1} & a_{m2} & \\ldots & a_{mn}\n",
    "    \\end{array}\n",
    "  \\right]\n",
    "  +\n",
    "    \\left[\n",
    "    \\begin{array}{cccc}\n",
    "      b_{11} & b_{12} & \\ldots & b_{1n}\\\\\n",
    "      b_{21} & b_{22} & \\ldots & b_{2n}\\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "      b_{m1} & b_{m2} & \\ldots & b_{mn}\n",
    "    \\end{array}\n",
    "  \\right]\n",
    "  =\n",
    "  \\left[\n",
    "    \\begin{array}{cccc}\n",
    "      a_{11} + b_{11}& a_{12}+ b_{12} & \\ldots & a_{1n} + b_{1n}\\\\\n",
    "      a_{21} + b_{21}& a_{22}+ b_{22} & \\ldots & a_{2n} + b_{2n}\\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "      a_{m1}+b_{m1} & a_{m2}+ b_{m2} & \\ldots & a_{mn} + b_{mn}\n",
    "    \\end{array}\n",
    "  \\right]\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.postimg.cc/x1Qz6JKy/Capture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3],\n",
    "              [2,3,4],\n",
    "              [3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[3,2,1],\n",
    "              [3,1,4],\n",
    "              [6,7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = A + B\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = A - B\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de sumar un escalar a nuestra matriz, entonces sumaríamos el escalar a cada elemento de la matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 10 + A\n",
    "print(f'Escalar:{10}\\nA:\\n{A}\\n\\nEscalar + A:\\n{E}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasa exactamente lo mismo en el caso de la multiplicación (si ambas matrices son de las mismas dimensiones):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = A * B\n",
    "print(f'A:\\n{A}\\nB:\\n{B}\\nA*B:\\n{F}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suma de matrices y vectores con dimensiones distintas (broadcasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El término *broadcasting* describe como *NumPy* trata a los arrays con diferentes dimensiones durante operaciones aritméticas. Sujeto a varias restricciones, se le aplica *broadcast* al array más pequeño a través del array más grande, de forma que terminen con dimensiones compatibles. \n",
    "\n",
    "El *broadcasting* nos provee de un medio para vectorizar operaciones con arrays, de forma que el bucle se produce en C en lugar de en Python. Esto lo hace sin hacer copias innecesarias de datos y usualmente, conduce a implementaciones eficientes de algoritmos. Sin embargo, existen casos en donde el *broadcasting* es una mala idea por qué podría conducir a ineficientes usos de memoria que podrían alentar el cómputo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "scalar = 5.679\n",
    "vector = np.array([3,4,5])\n",
    "matrix = np.array([[1,2],\n",
    "                   [3,4],\n",
    "                   [5,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que cuando tratamos de sumar elementos de diferentes dimensiones no tenemos como tal una operación definida como en el caso siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = vector + matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esto ocurre por qué tenemos una matriz $3\\times 2$ tratando de sumarse con un vector fila $3\\times 1$. En este caso no coinciden las dimensiones.\n",
    "\n",
    "¿Qué pasaría si utilizamos la transposición de la matriz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_matrix = matrix.T\n",
    "T_A = vector + T_matrix\n",
    "print(T_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma no tenemos error ya que nuestra matriz pasa a ser una matriz $2\\times 3$ que sí se puede sumar con un vector $3 \\times 1$.\n",
    "\n",
    "Notemos como podemos realizar las operaciones cuando los números o dimensiones de en medio coinciden, en este casi el 3 con el : $2\\times 3 \\rightarrow 3 \\times 1$. De está forma lo que estamos haciendo es \"duplicar\" el vector fila, de manera que se sume en cada fila de la matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/2114/1*lY8Ve6Uz_bqVI5NPh5RPZA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justo a esto es a lo que le llamamos **broadcasting**, estamos \"extendiendo\" la dimensión de menor tamaño para completar la de menor tamaño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internamente, Python hace **broadcasting** al sumar un escalar con una matriz, ya que está \"extendiendo\" dicho escalar para poder sumar cada elemento de la matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma que la suma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = matrix + 50\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "internamente es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C_Py = matrix + np.array([[50],[50],[50]])\n",
    "print(C_Py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones con matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producto interno de matrices y  vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $V$ un espacio vectorial *sobre el cuerpo* $\\mathbb{R}$ *de los reales*. El **producto interno** o **producto escalar** definido sobre $V$ es una aplicación entre el conjunto de todos los pares de vectores $(u,v)$ y $\\mathbb{R}$, cuyo resultado es un número real denotado por $\\langle u, v \\rangle$, que satisface las siguientes propiedades para todo $u,v,w \\in V$ y todo escalar $\\alpha \\in \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tag{1} \\langle u,v \\rangle = \\langle v,u \\rangle$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tag{2} \\alpha \\langle u,v \\rangle = \\langle (\\alpha u),v \\rangle = \\langle u ,(\\alpha v) \\rangle$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tag{3} \\langle u+v , w \\rangle = \\langle u,w \\rangle +  \\langle v,w \\rangle $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tag{4} \\langle u , u \\rangle \\geq 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$\\tag{4.1}\\langle u , u \\rangle = 0 \\text{ si y sólo si } u= 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar la multiplicación de un vector por una matriz debemos de asegurarnos que sus dimensiones coincidan de la siguiente forma:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$(n\\times m)(m\\times l)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde:\n",
    "    \n",
    "* $n$ es el número de filas de la matriz.\n",
    "* $m$ es el número de columnas de la matriz y debe coincidir con el número de filas del vector.\n",
    "* $l$ es el número de columnas del vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a escribir los elementos con los que vamos a estar trabajando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_vector = np.array([-4,5,8])\n",
    "\n",
    "column_vector = np.array([[-6],\n",
    "                          [-2],\n",
    "                          [ 5]])\n",
    "matrix = np.array([[-3,5,-6],\n",
    "                   [7,10,-1]])\n",
    "\n",
    "matrix2 = np.array([[-2,10],\n",
    "                    [-1,-4],\n",
    "                    [7,9],])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver la diferencia entre el **producto de un vector y una matriz** (según lo interpreta Python), con el **producto interno** de los mismos. El producto interno se aplica utilizando `.dot()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero veamos **como hace Python para interpretar** el caso del **producto de un vector y una matriz**, así sin más:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = matrix * row_vector\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/J1NHDXY.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nosotros indicamos la multiplicación del vector por la matriz con el operador `*`, entonces Python realizará el calculo de arriba; el cual nos recordara al *broadcasting* del que hablamos anteriormente. Podemos imaginar este proceso como si estuviera \"replicando\" el vector fila, de manera que multiplique componente por componente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product =  row_vector * matrix \n",
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en este caso, no tiene problema en multiplicar primero la matriz o el vector de esta forma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por el otro lado, si quisieramos aplicar el mismo producto con `*` y un **vector columna**, no encontraría compatibilidad con las dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = matrix * column_vector\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, hablemos sobre el **producto interior** o **producto punto** entre matriz y vector. Para realizar esto tendremos que asegurarnos de que se cumpla la condición de arriba: $(n\\times m)(m \\times l)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos con el producto de nuestro vector columna por nuestra matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_col = matrix.dot(column_vector)\n",
    "print(dot_product_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso tenemos una matriz de $(2\\times 3)$ y un vector columna de $(3\\times 1)$, por lo que las dimensiones coinciden y podemos realizar correctamente el producto de vector y matriz, el cual se realiza de la siguiente manera:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/Wo6XcCM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué pasaría si tratamos de realizar el producto del *vector por la matriz*, es decir, el orden inverso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_col2 = column_vector.dot(matrix)\n",
    "print(dot_product_col2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos arroja un error, ya que las dimensiones no coinciden ya que tendriamos el caso $(3\\times 1)(2 \\times 3)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso del **vector fila** ocurre un caso similar, ya que si tratamos de hacer el producto de nuestra matriz por el **vector fila**, tendríamos incompatibilidad con el caso $(2\\times 3)(1 \\times 3)$.\n",
    "\n",
    "En este caso **Python sí lo puede realizar**, ya que utilizar un método como el *broadcasting*, **pero antes de revisarlo veamos como sería el caso con las dimensiones correctas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_row = row_vector.dot(matrix2)\n",
    "print(f'Vector: {row_vector}\\nMatriz:\\n {matrix2}\\nProduct: {dot_product_row}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notemos que estamos multiplicando vector por matriz, no matriz por vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/pfOTMol.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora sí, volvamos al caso donde tenemos diferentes dimensiones, pero Python encuentra el modo de hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Matriz:\\n{matrix}\\nVector:{row_vector}\\nShape:(2x3)(1x3)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_dot_product = matrix.dot(row_vector)\n",
    "print(strange_dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un inicio, las dimensiones no coincide. Así que Python opta por aplicar nuevamente el *broadcasting*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.postimg.cc/CKLw1SgV/Capture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producto interno entre 2 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1 ,2 ,3],\n",
    "              [4 ,5 ,6],\n",
    "              [7 ,8 ,9],\n",
    "              [10,11,12]])\n",
    "\n",
    "B = np.array([[2,3],\n",
    "              [5,7],\n",
    "              [11,13]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(f'Shape A: {A.shape}\\nShape B: {B.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver si están definidos los productos $A \\cdot B$ y $B \\cdot A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A \\cdot B$ sí está definida, ya que coinciden los 3's y nos quedamos con un arreglo de $(4 \\times 2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_dot_B = A.dot(B)\n",
    "print(f'A dot B:\\n{A_dot_B}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La operación que se realizó fue la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/rQMLX0c.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_dot_A = B.dot(A)\n",
    "print(f'A dot B:\\n{B_dot_A}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en el caso de $B \\cdot A$ no está definida por la incompatibilidad de las dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propiedades de las matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asociativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A \\times (B \\times C) = (A \\times B) \\times C$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributiva:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A \\times (B+C) = (A \\times B) + (A \\times C)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conmutativa:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$B \\times C = C \\times B$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a corroborar con código cuales de estas propiedades se cumplen para el producto interno de matrices y de vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[2,3],[5,7],[11,13]])\n",
    "B = np.array([[1,3],[2,1]])\n",
    "C = np.array([[3,1],[4,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asociativa\n",
    "A_BC = A.dot(B.dot(C))\n",
    "AB_C = (A.dot(B)).dot(C)\n",
    "print(f'A(BC):\\n{A_BC}\\n(AB)C:\\n{AB_C}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cumple la ASOCIATIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributiva\n",
    "A_Bpc = A.dot(B+C)\n",
    "AB_AC = A.dot(B)+ A.dot(C)\n",
    "print(f'A*(B+C):\\n{A_Bpc}\\n(AB)+(AC):\\n{AB_AC}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cumple la DISTRIBUTIVA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conmutativa\n",
    "B_C = B.dot(C)\n",
    "C_B = C.dot(B)\n",
    "print(f'B*C:\\n{B_C}\\nC*B:\\n{C_B}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO se cumple la CONMUTATIVA en la mayoría de los casos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conmutatividad en producto interno de vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([[2],[7]])\n",
    "v2 = np.array([[3],[5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a las dimensiones de nuestros vectores, tendremos que hacerlas coincidir con una transposición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1T_dot_v2 = v1.T.dot(v2)\n",
    "print(v1T_dot_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2T_dot_v1 = v2.T.dot(v1)\n",
    "print(v2T_dot_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resto de propiedades también se cumplen para el caso de los vectores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposición del producto de matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una propiedad que nos indica lo siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{pmatrix}\n",
    "A \\cdot B\n",
    "\\end{pmatrix}^t = B^t \\cdot A^t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y recordemos una propiedad que vimos anteriormente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${{(A \\cdot B)}^{t}}^t = A \\cdot B $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde indicamos la transposición de la matriz con la letra $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a corroborar esa propiedad en código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2,3], [5,7], [11,13]])\n",
    "B = np.array([[1,3], [2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'A:\\n{A}\\nB:\\n{B}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Matrices shapes \\nA:{A.shape}\\nB:{B.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpuestas\n",
    "A_t = A.T\n",
    "B_t = B.T\n",
    "print(f'A transpuesta:\\n{A_t}\\nB transpuesta:\\n{B_t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB_t = (A.dot(B)).T\n",
    "print(f'(AB) transpuesta:\\n{AB_t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bt_At = (B.T).dot(A.T)\n",
    "print(f'B transpuesta por A transpuesta:\\n{Bt_At}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AB_t == Bt_At)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómo comprobar la solución de un sistema de ecuaciones lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos algunas nociones básicas del álgebra lineal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinación lineal\n",
    "\n",
    "Es el vector que se obtiene al sumar una series de vectores multiplicados por escalares.\n",
    "\n",
    "Sean $v_1,v_2,...,v_n$ vectores en un espacio vectorial $V$. Entonces, cualquier vector de la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\alpha_{1}v_{1}+\\alpha_{2}v_{2}+\\dots +\\alpha_{n}v_{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $\\alpha_{i} v_{i}$ son escalares, se denomina **combinación lineal** de $v_1,v_2, v_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea la combinación lineal de las variables $x_1, x_2, ..., x_n$ dada por la expresión:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a_1x_1+a_2x_2+ \\dots + a_nx_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los números reales $a_1,\\dots,a_n \\in \\mathbb{R}$, se denominan **coeficientes de la combinación**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ecuación lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una **ecuación lineal** en las incógnitas o variables $x_1, \\dots, x_n$ es una expresión de la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a_1x_1+a_2x_2+ \\dots + a_nx_n = b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $b \\in \\mathbb{R}$, se denomina **término constante**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una $n-$tupla $(s_1, \\dots, s_n)$es una **solución** de la ecuación lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a_1x_1+a_2x_2+ \\dots + a_nx_n = b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "si, al sustituir las variables $x_1, x_2, \\dots, x_n$ por los números $s_1,\\dots,s_n$ se obtiene una identidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sistema de ecuaciones lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **sistema de $m$ ecuaciones lineales** y $n$ **incógnitas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "a_{11}x_1+a_{12}x_2+ &\\dots& + a_{1n}x_n = b_{1}  \\\\\n",
    "a_{21}x_1+a_{22}x_2+ &\\dots& + a_{2n}x_n = b_{2}  \\\\\n",
    "               &\\vdots& \\\\\n",
    "a_{m1}x_1+a_{m2}x_2+ &\\dots& + a_{mn}x_n = b_{m}  \\\\\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tiene **solución** $(s_1, \\dots, s_n)$ si dicha $n-$tupla es una solución **de todas** las ecuaciones del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solución de un sistema lineal no existe necesariamente, y si lo hace, no es necesariamente única."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si un sistema de ecuaciones tiene solución o soluciones, se denomina **sistema compatible**; en caso contrario, diremos que es un **sistema incompatible**. Y al conjunto de todas las soluciones de un sistema de ecuaciones lineales dado se denomina **conjunto de soluciones**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos el siguiente sistema de ecuaciones:\n",
    "\n",
    "$$\\begin{cases} \n",
    "y = 3x + 5 \\\\\n",
    "y = 2x + 3\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que para graficar una función, tendremos que evaluarla a lo largo de diferentes puntos. Por lo que queremos obtener pequeños intervalos en donde vamos a obtener nuestra función evaluada, para hacerlo hagamos un arreglo como el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-5, 5) # Intervalo de -5 a 5 de 1 en 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a escribir las ecuaciones que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = 3*x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = 2*x + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a graficar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure() #Crea figura\n",
    "plt.axvline(x=0, color = 'black') # Eje X\n",
    "plt.axhline(y=0, color=  'black') # Eje Y\n",
    "plt.grid() # Cuadricula\n",
    "plt.plot(x, y_1) \n",
    "plt.plot(x, y_2)\n",
    "plt.ylim(-5, 5)\n",
    "plt.xlim(-5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar que las rectas se tocan en un punto, es decir, comparten un valor posible de $x$ que nos dá el mismo valor en $y$. Esto nos dice que existe una solución del sistema, ya que es solución de ambas ecuaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, podemos proceder a realizar el despeje:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned}\n",
    "2x + 3 &= 3x+5 \\\\\n",
    "x &= -2\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned}\n",
    "2x + 3    &= y \\\\\n",
    "2(-2) + 3 &= y \\\\\n",
    "-1        &= y\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(-2,-1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pero aquí no estamos lidiando con álgebra \"común\", así que vamos a ver como podríamos representar este sistema de forma *matricial*. Para hacerlo, vamos a \"pasar\" todas las variables de un lado de la igualdad y las constantes del otro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "y = 3x + 5 \\\\\n",
    "y = 2x + 3\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "-3x + y = 5 \\\\\n",
    "-2x + y = 3\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a \"extraer\" los coeficientes de nuestro sistema, de manera que tengamos una matriz (con los coeficientes) y un vector (con las variables). De forma que el sistema, se describa mediante el **producto interno** de una matriz y un vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "-3 & 1\\\\\n",
    "-2 & 1\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "5 \\\\\n",
    "3 \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así que, ahora escribamos nuestro sistema en forma matricial a código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-3, 1],\n",
    "              [-2, 1]])\n",
    "res_vec = np.array([[5],\n",
    "                    [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos a comprobar la solución que obtuvimos arriba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_1 = np.array([[-2],[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = A.dot(sol_1)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quisieramos encontrar la solución utilizando Python, haríamos lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linalg.solve(A, res_vec)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usamos el método `.solve()` y le pasamos la matrix coeficiente y despues los valores independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[-3, 1],\n",
    "              [-2, 1]])\n",
    "\n",
    "res_vec = np.array([[5],\n",
    "                    [3]])\n",
    "\n",
    "x = np.linalg.solve(A, res_vec)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos especiales de matrices: Identidad, Inversa y Singular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz Identidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **matriz identidad** es una matriz que cumple la propiedad de ser el elemento neutro del producto de matrices. Esto quiere decir que el producto de cualquier matriz por la matriz identidad (mientras esté definido) no tiene ningún efecto y nos devuelve la matriz original. La columna $i-$ésima de una matriz identidad es el **vector unitario** $e_i$ de una base vectorial inmersa en un espacio Euclídeo de dimensión $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En NumPy basta con escribir la instrucción `.eye()` e indicarle las dimensiones que queremos que tenga nuestra matriz identidad o los cuántos elementos tendrá la diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = np.eye(2)\n",
    "print(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = np.eye(4)\n",
    "print(identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notemos que todos los elementos están definidos como `floats`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a verificar cuál es el efecto de esta matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = np.eye(3)\n",
    "\n",
    "vector = np.array([[1],\n",
    "                   [2],\n",
    "                   [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = identity.dot(vector)\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = np.eye(4)\n",
    "\n",
    "matrix = np.array([[1,2,3,4],\n",
    "                   [5,6,7,8],\n",
    "                   [9,10,11,12],\n",
    "                   [13,14,15,16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product2 = identity.dot(matrix)\n",
    "print(product2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decimos que la **matriz identidad** no transforma el espacio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz Inversa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **matriz inversa** es la transformación lineal de una matriz mediante la multiplicación del inverso del determinante de la matriz por la matriz adjunta transpuesta. Es decir, es la multiplicación del *inverso del determinante* por la matriz adjunta traspuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y se cumple que el producto de una matriz por su inversa, es igual a la matriz identidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A \\cdot A^{-1} =  A^{-1} \\cdot A =I $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz inversa se puede calcular por el **método de Gauss** o por el **método de determinantes**. Para hacerlo en Python tenemos la instrucción `.linalg.inv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,0,1],[0,1,1],[-1,1,1]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inverse = np.linalg.inv(A)\n",
    "print(A_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifiquemos que obtendríamos la matriz identidad al realizar el producto interno de estas matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ident = A.dot(A_inverse)\n",
    "print(ident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ident2 = A_inverse.dot(A)\n",
    "print(ident2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz Singular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que no siempre existe esta matriz inversa. **Cuando la matriz NO tiene inversa, la llamamos singular**. La definimos de la siguiente forma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **matriz singular** es la *matriz cuadrada* de orden $N$, cuyo **determinante es nulo** $(=0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente matriz sería un caso de matriz singular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singular = np.array([[1,1],[1,1]])\n",
    "print(singular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(singular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que nos arroja el error `LinAlgError: Singular matrix`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTA: No podríamos intentar esto con matrices que no sean cuadradas $(m \\times m)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando la Inversa de una matriz para resolver un sistema de ecuaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos el siguiente sistema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "3x + y = 1 \\\\\n",
    "2x + y = 1\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y en forma matricial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "3 & 1\\\\\n",
    "2 & 1\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1 \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos pedirle a NumPy que nos muestre los resultados que están muy proximos a 0, como si fueran 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3,1],\n",
    "              [2,1]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1],\n",
    "              [1]])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que tendríamos que hacer para \"despejar\" a $A$  sería encontrar la inversa de la misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv = np.linalg.inv(A)\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a calcular nuestro $x$ (el vector de variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = A_inv.dot(b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamor a verificarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_dot_x = A.dot(x)\n",
    "print(A_dot_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y como vemos, sí obtenemos el vector `[1 1]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hecho, podríamos utilizar la misma matriz inversa de $A$ para encontrar otro sistema con la misma matriz de coeficientes, pero que esté igualada a otra matriz $b$ diferente.\n",
    "\n",
    "Por ejemplo, probemos con el sistema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "3x + y = 3 \\\\\n",
    "2x + y = 7\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "3 & 1\\\\\n",
    "2 & 1\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "3 \\\\\n",
    "7 \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilizando la misma inversa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_2 = A_inv.dot(np.array([[3],[7]]))\n",
    "print(sol_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos a verificar si es una solución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.dot(sol_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, calculando la inversa podemos calcular la solución de otro sistema de ecuaciones igualado a matrices $b$ distintas. Esto es lo que habitualmente hacemos al resolver un **sistema de ecuaciones homógeneo** y después, calculamos una **solución particular**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistemas de ecuaciones lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos de sistemas sin solución, con una solución y con infinitas soluciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un sistema es:\n",
    "\n",
    "\n",
    "* **COMPATIBLE** si tiene alguna tupla solución (colección finita y ordenada de elementos, $(a_1,\\dots,a_n)$ en un cuerpo $k$)\n",
    "\n",
    "    * **COMPATIBLE DETERMINADO** si tiene una *única* tupla solución.\n",
    "\n",
    "    * **COMPATIBLE INDETERMINADO** si tiene *más de una* tupla solución\n",
    "\n",
    "* **INCOMPATIBLE** si no tiene ninguna tupla o vector solución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Queremos los graficos de forma interctiva debajo de cada celda\n",
    "%matplotlib notebook \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sistema Incompatible (sin soluciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos el siguiente sistema de ecuaciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "y = 3x  + 5 \\\\\n",
    "y = -1x + 3 \\\\\n",
    "y = 2x  + 1\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear el rango de valores de $x$ para evaluar las ecuaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribimos las ecuaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = 3*x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = -x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3 = 2*x + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para cada una generemos la figura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.axvline(x = 0, color= 'black')\n",
    "plt.axhline(y = 0, color= 'black')\n",
    "plt.plot(x, y_1)\n",
    "plt.plot(x, y_2)\n",
    "plt.plot(x, y_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la imagen podemos observar que las ecuaciones se intersectan en distintos puntos, pero **no existe un punto donde se toquen las 3 al mismo tiempo**, por lo que podríamos deducir que dicho sistema de ecuaciones no tiene solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sistema Compatible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora consideremos el siguiente sistema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{cases} \n",
    "y = \\frac{x + 5}{2}\\\\\n",
    "y = \\frac{-1x + 7}{2} \\\\\n",
    "y = \\frac{2x + 7}{3}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = ( x + 5) / 2\n",
    "y_2 = (-x + 7) / 2\n",
    "y_3 = (2*x + 7) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.axvline(x = 0, color= 'black')\n",
    "plt.axhline(y = 0, color= 'black')\n",
    "plt.plot(x, y_1)\n",
    "plt.plot(x, y_2)\n",
    "plt.plot(x, y_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que las 3 rectas se intersectan en un punto. Por lo que el sistema *sí tiene solución* y además, *es única*. Por lo que es un sistema **compatible determinado**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://slideplayer.es/slide/5478638/17/images/5/Sistema+compatible+determinado+Sistema+compatible+indeterminado.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear una función que nos va a ayudar a visualizar vectores para trabajar en el resto de contenidos. Escribiremos el código aquí y también lo guardaremos en otro archivo en local para hacer la llamada a la función desde otro notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([2,5])\n",
    "v2 = np.array([3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_vectores(vectors, color, alpha=1):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.grid()\n",
    "    \n",
    "    # Ejes\n",
    "    plt.axvline(x=0, color='black')\n",
    "    plt.axhline(y=0, color='black')\n",
    "    \n",
    "    for i in range(len(vectors)):\n",
    "        # Recorremos cada vector y los concatenamos\n",
    "        # (Para poner la cola del vector - origen)\n",
    "        x = np.concatenate([[0,0], vectors[i]])\n",
    "        \n",
    "        # Graficamos\n",
    "        plt.quiver([x[0]],\n",
    "                   [x[1]],\n",
    "                   [x[2]],\n",
    "                   [x[3]],\n",
    "                   angles = 'xy',\n",
    "                   scale_units='xy',\n",
    "                   scale= 1,\n",
    "                   color= color[i],\n",
    "                   alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graficar_vectores([v1, v2], ['blue','red'], alpha=1)\n",
    "\n",
    "plt.xlim(-1, 5)\n",
    "plt.ylim(-1,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a estar utilizando constantemente esta función, pero recordemos que cada que reiniciemos el notebook se borrará de la memoria y tendremos que buscar la celda y ejecutar de nuevo. Para evitar esto, la guardaremos en un nuevo notebook y simplemente \"mandaremos a ejecutar\" dicho notebook cada que queramos utilizar la función."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos el comando `%run\"\"` con la ruta relativa de nuestro archivo dentro de las comillas, el cual que contiene la función que queremos utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar que esto funciona, reinicie el notebook e intente ejecutar la instrucción:\n",
    "\n",
    "```Python\n",
    "graficar_vectores([v1, v2], ['blue','red'], alpha=1)\n",
    "\n",
    "plt.xlim(-1, 5)\n",
    "plt.ylim(-1,6)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y aparecerá que no está definida dicha función, así que después ejecute la linea con la instrucción `%run\"\"` y ahora sí se podrá ejecutar el graficado ya que ha sido llamado desde el otro notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué es una combinación lineal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más arriba en la sección de sistemas de ecuaciones definimos que era una combinación lineal. A grandes rasgos y de una forma muy \"hablada\", podemos decir que es multiplicar vectores por escalares y sumar dichos productos entre si, de forma que obtendríamos un nuevo vector. Así podríamos describir el nuevo vector como **una combinación lineal** de los vectores anteriores que los conforman."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ a_1 v_1  + \\dots +  a_n v_n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamemos a la función de graficar vectores\n",
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definamos los vectores\n",
    "v1 = np.array([2,5])\n",
    "v2 = np.array([3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribimos una combinación lineal de esos vectores\n",
    "v1v2 = 2*v1 + 3*v2\n",
    "print(v1v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_vectores([v1,v2,v1v2], color = ['red','blue','purple'], alpha = 1)\n",
    "plt.xlim(-1,13.5)\n",
    "plt.ylim(-1,16.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aún cuesta algo de trabajo interpretar la combinación, así que vamos a graficar los vectores rojo y azul multiplicandolos por los escalares correspondientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_vectores([2*v1,3*v2,v1v2], color = ['red','blue','purple'], alpha = 1)\n",
    "plt.xlim(-1,13.5)\n",
    "plt.ylim(-1,16.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es mucho más claro, podemos visualizar al vector resultante como si colocaramos la cola del vector azul en la punta del vector rojo, de manera que obtendríamos nuestro paralelogramo.\n",
    "\n",
    "Vamos a modificar un poco la función de graficado para que nos dibuje el paralelogramo. Lo hice de forma que primero recibe el vector resultante y luego los 2 vectores que conforman la combinación lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_vectores_punta_cola(vectors, color, alpha=1):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.grid()\n",
    "    \n",
    "    # Ejes\n",
    "    plt.axvline(x=0, color='black')\n",
    "    plt.axhline(y=0, color='black')\n",
    "    \n",
    "    for i in range(len(vectors)):\n",
    "        # Este código en especial solo serviría para combinar 2 vectores\n",
    "        if i == 1:\n",
    "            x = np.concatenate([[0,0], vectors[i]])\n",
    "        elif i == 2: \n",
    "            x = np.concatenate([ vectors[i-1] , vectors[i] ])\n",
    "        else:\n",
    "            x = np.concatenate([[0,0], vectors[i]])\n",
    "        \n",
    "        # Graficamos\n",
    "        plt.quiver([x[0]],\n",
    "                   [x[1]],\n",
    "                   [x[2]],\n",
    "                   [x[3]],\n",
    "                   angles = 'xy',\n",
    "                   scale_units='xy',\n",
    "                   scale= 1,\n",
    "                   color= color[i],\n",
    "                   alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_vectores_punta_cola([v1v2, 2*v1,3*v2], color = ['purple','red','blue'], alpha = 1)\n",
    "plt.xlim(-1,13.5)\n",
    "plt.ylim(-1,16.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, definamos una función para graficar un subconjunto de las posibles combinaciones lineales que podríamos tener al multiplicar nuestros vectores por un cierto rango de escalares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        plt.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b,\n",
    "                   marker= '.', color='pink')\n",
    "        \n",
    "plt.grid()\n",
    "plt.xlim(-100,100)\n",
    "plt.ylim(-100,100)\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.axhline(y=0, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que estamos viendo son solo unas pocas de las posibles combinaciones lineales posibles de 2 vectores. Si siguieramos expandiendo esto, describiríamos a todo el espacio $\\mathbb{R}^2$. \n",
    "\n",
    "Así que con ciertos vectores \"base\" podríamos describir todo el espacio a partir de combinaciones lineales de estos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué es un espacio y un subespacio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **espacio vectorial** es un conjunto *no vacío* de $V$ objetos llamados **vectores**, en el que se han definido dos operaciones: la suma y el producto escalar sujetas a diez axiomas que se dan a continuación. Los axiomas deben ser válidos para todos los vectores $u$, $v$, y $w$ en $V$ y todos los escalares $\\alpha$ y $\\beta$ reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $u + v \\in V$\n",
    "* $u + v = v + u$\n",
    "* $(u + v) + w = u+(v + w)$\n",
    "* Existe un vector nulo $0v \\in V$ tal que, $v + 0v = v$\n",
    "* Para cada $v$ en $V$, existe un opuesto $(-v) \\in V$ tal que, $v + (-v) = 0v$\n",
    "* $\\alpha v \\in V$ \n",
    "* $\\alpha(u+v) = \\alpha u + \\alpha v $\n",
    "* $(\\alpha + \\beta) v = \\alpha v + \\beta v$\n",
    "* $\\alpha(\\beta v) = (\\alpha \\beta) v$\n",
    "* $1v = v$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso nos estamos refiriendo a un **espacio vectorial real**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los espacios $\\mathbb{R}^n$, con $n \\ge 1$, son los ejemplos principales de espacios vectoriales. La intuición geométrica para $\\mathbb{R}^3$ nos ayudará a entender y visualizar muchos conceptos de esta unidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los vectores de $\\mathbb{R}^n$ son $n-$tuplas de números reales, osea:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbb{R}^n = \\{ (x_1,x_2, \\dots, x_n), \\text{ con } x_i \\in \\mathbb{R} \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En $\\mathbb{R}^n$, la suma de vectores y el producto por un escalar se definen como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sean $u=(u_1,u_2, \\dots, u_n)$ y $v=(v_1,v_2, \\dots, v_n)$  $\\in \\mathbb{R}^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ u + v = (u_1  + v_1 , u_2 + v_2 , \\dots , u_n + v_n) \\in \\mathbb{R}^n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\alpha v = (\\alpha v_1, \\alpha v_2, \\dots, \\alpha v_n) \\in \\mathbb{R}^n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $V$ un espacio vectorial y $W$ un subconjunto no vacío de $V$.\n",
    "\n",
    "$W$ es un **subespacio** de $V$ si $W$ es en sí mismo un espacio vectorial con las mismas operaciones (suma de vectores y producto escalar) definidas en $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condiciones necesarias y suficientes para definir un subespacio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $W$ un subconjunto de un espacio vectorial $V$, $\\left( {W \\subseteq V} \\right)$. $W$ es un **subespacio** de $V$ si y sólo si se cumplen las siguientes condiciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $0V$ está en $W$.\n",
    "* Si $u$ y $v$ están en $W$, entonces, $u+v$ están en $W$.\n",
    "* Si $u$ está en $W$ Y $k$ es un escalar, $ku$ está en $W$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La condición #1 nos asegura que $W$ **no es vacío**. Mientras que las propiedades a,b y c corresponden a los axiomas 4,1 y 6.\n",
    "\n",
    "Aún faltaría comprobar que cada vector de $W$ tiene su opuesto en $W$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear 2 vectores \"base\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,1])\n",
    "v2 = np.array([-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamemos a la función de graficar vectores\n",
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_vectores([v1,v2], color=['red','blue'], alpha=1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a ver que otros vectores nos generarían como espacio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        plt.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b,\n",
    "                   marker= '.', color='purple')\n",
    "        \n",
    "plt.grid()\n",
    "plt.xlim(-25,25)\n",
    "plt.ylim(-25,25)\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.axhline(y=0, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así que, a partir de combinaciones lineales de $v1=(1,1)$ y $v2=(-1,-1)$ sólo podríamos obtener nuevos vectores que sigan la trayectoria de la recta de arriba. Así que NO podemos utilizarlos como nuestros vectores \"base\" para construir  todo $\\mathbb{R}^2$. De hecho, si nos fijamos podemos notar que $v2$ puede producirse como una combinación lineal de $v1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hecho, para conformar un espacio tendremos que tener una base de vectores **linealmente independientes** (más adelante explicaremos que es eso). En este caso, para formar a $\\mathbb{R}^2$ tendríamos que utilizar los vectores $v1=(1,0)$ y $v2=(0,1)$. Vamos a corroborarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,0])\n",
    "v2 = np.array([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\"\n",
    "graficar_vectores([v1,v2], color=['red','blue'], alpha=1)\n",
    "plt.xlim(-0.5,1.5)\n",
    "plt.ylim(-0.5,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        plt.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b,\n",
    "                   marker= '.', color='purple')\n",
    "        \n",
    "plt.grid()\n",
    "plt.xlim(-20,20)\n",
    "plt.ylim(-20,20)\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.axhline(y=0, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y podemos ver que ahora sí estamos generando todo el espacio $\\mathbb{R^2}$ (recordemos que solo hicimos la iteración de -10 a 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podríamos construir el espacio con los siguientes vectores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,0])\n",
    "v2 = np.array([2,-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\"\n",
    "graficar_vectores([v1,v2], color=['red','blue'], alpha=1)\n",
    "plt.xlim(-0.5,4)\n",
    "plt.ylim(-5,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        plt.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b,\n",
    "                   marker= '.', color='purple')\n",
    "        \n",
    "plt.grid()\n",
    "plt.xlim(-25,25)\n",
    "plt.ylim(-25,25)\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.axhline(y=0, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a visualizar como el espacio $\\mathbb{R}^2$ es un **subespacio** de $\\mathbb{R}^3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,0,0])\n",
    "v2 = np.array([0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        ax.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b, v1[2]*a + v2[2]*b,\n",
    "                   marker= '.', color='purple')\n",
    "\n",
    "ax.set_xlabel('Eje X')\n",
    "ax.set_ylabel('Eje Y')\n",
    "ax.set_zlabel('Eje Z')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el espacio $\\mathbb{R}^2$ solo conforma una \"capa\" dentro de $\\mathbb{R}^3$, y como todos los elementos de $\\mathbb{R}^2$ están contenidos en $\\mathbb{R}^3$, decimos que $\\mathbb{R}^2$ es un **subespacio de** $\\mathbb{R}^3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En álgebra lineal le llamamos **hiperplano** es un espacio de *menor dimensión* al espacio en el cuál estamos trabajando. Por ejemplo, si estamos trabajando en $\\mathbb{R}^3$ entonces, $\\mathbb{R}^2$ es un **hiperplano**.\n",
    "\n",
    "Si estamos en un espacio de 3 dimensiones, el hiperplano sería una \"capa\" u \"hoja\" como la que vemos arriba, en el caso de estar trabajando en 2 dimensiones tendríamos como hiperplano a una recta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjunto generador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $\\{ v_1,v_2,\\dots, v_n \\}$ un conjunto de vectores de un espacio vectorial $V$.\n",
    "\n",
    "Si **todo vector** de $V$ se puede expresar como combinación lineal de  $ v_1,v_2,\\dots, v_n $, entonces se dice que $\\{ v_1,v_2,\\dots, v_n \\}$ es un **conjunto generador de V**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectores linealmente Independientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decimos que 2 o más vectores son **linealmente independientes** si ninguno de ellos puede ser escrito como una **combinación lineal** de los restantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O por el otro lado, un conjunto de vectores ${v_1, v_2, \\dots , v_n}$ de un espacio vectorial $V$ es **linealmente dependiente** si y sólo si al menos unos de los vectores puede expresarse como una combinación lineal de los demás."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la combinación de los $n$ vectores es igual al vector cero, entonces cada uno de los coeficientes de la combinación lineal es cero:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a_1 \\vec{v_1} + a_2 \\vec{v_2} + \\dots + a_n \\vec{v_n} = \\vec{0} \\implies a_1 = a_2 = \\dots = a_n = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los vectores linealmente independientes tienen distinta dirección y sus componentes no son proporcionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retomemos nuestro ejemplos anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,1])\n",
    "v2 = np.array([-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\"\n",
    "graficar_vectores([v1,v2], color=['red','blue'], alpha=1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        plt.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b,\n",
    "                   marker= '.', color='purple')\n",
    "        \n",
    "plt.grid()\n",
    "plt.xlim(-25,25)\n",
    "plt.ylim(-25,25)\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.axhline(y=0, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recordemos que obtuvimos ese espacio ya que, $v2$ *se puede expresar como una combinación lineal de* $v1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, veamos el caso donde generamos a $\\mathbb{R}^2$ utilizando nuestros 2 vectores linealmente independientes $(1,0)$ y $(0,1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([0,1])\n",
    "v2 = np.array([1,0])\n",
    "\n",
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\"\n",
    "graficar_vectores([v1,v2], color=['red','blue'], alpha=1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        plt.scatter(v1[0]*a + v2[0]*b, v1[1]*a + v2[1]*b,\n",
    "                   marker= '.', color='purple')\n",
    "        \n",
    "plt.grid()\n",
    "plt.xlim(-20,20)\n",
    "plt.ylim(-20,20)\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.axhline(y=0, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo generaríamos a $\\mathbb{R}^3$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los vectores $v1=(1,0,0)$, $v2=(0,1,0)$ y $v3=(0,0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,0,0])\n",
    "v2 = np.array([0,1,0])\n",
    "v3 = np.array([0,0,1])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for a in range(-10,10):\n",
    "    for b in range(-10,10):\n",
    "        for c in range(-10,10):\n",
    "            ax.scatter(v1[0]*a + v2[0]*b + v3[0]*c, v1[1]*a + v2[1]*b + v3[1]*c, v1[2]*a + v2[2]*b + v3[2]*c,\n",
    "                       marker= '.', color='purple')\n",
    "\n",
    "ax.set_xlabel('Eje X')\n",
    "ax.set_ylabel('Eje Y')\n",
    "ax.set_zlabel('Eje Z')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validar que una matriz tenga inversa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que un sistema de ecuaciones tenga solución necesitamos que la matriz $A$ (que representa al sistema) sea cuadrada  y que todos sus vectores sean linealmente independientes.\n",
    "\n",
    "Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0,1,0,0],\n",
    "              [0,0,1,0],\n",
    "              [0,1,1,0],\n",
    "              [1,0,0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta matriz puede darnos la finta de que es cuadrada y contiene vectores linealmente independientes, pero poniendo un poco de atención notaremos que el 3er vector corresponde a una combinación lineal de los primeros 2 vectores. Por lo que al \"recrear\" nuestra matriz utilizando únicamente vectores linealmente independientes, tendremos una matriz de $3 \\times 4$ la cual no es cuadrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos interpretar esto como si tuvieramos un sistema de ecuaciones donde tenemos la misma ecuación multiplicada por un factor $k$, donde aparentaría ser una nueva ecuación, pero NO nos está dando ninguna información extra para resolver el sistema. Por ello nos interesamos en crear la matriz únicamente con vectores linearmente independientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos descomponer nuestra matriz utilizando los autovalores y autovectores que ya hemos visto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas, V = np.linalg.eig(A.T)\n",
    "print(f'lambda:\\n {lambdas}\\nEigen Vector:\\n {V}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que tenemos 4 valores lambda o **eigenvalues**. Y uno de ellos es 0, para el 3er indice. Esto será importante más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La operación que realizamos en la instrucción de arriba fue la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/hq6xg8j.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una forma de saber si hay una solución única para un sistema de ecuaciones o ver si nuestra matriz tiene inversa es asegurandonos de que cero no sea un valor propio de la matriz, ya que de ser así la matriz sería singular (no tiene inversa). Y como vimos en la salida de la linea anterior, tenemos un 0 en nuestro 3er indice de la lista de lambdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime el indice correspondiente a la columna de la matriz donde obtuvimos un eigenvalue igual a cero\n",
    "print(A[lambdas == 0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí encontramos que tenemos un valor `lambda == 0` ya que el vector `[0 1 1 0]` se puede escribir como la suma de los vectores `[0 1 0 0]` y `[0 0 1 0]`.\n",
    "\n",
    "Al final esto es una convención, podríamos describir al vector 2 como una combinación lineal del 1 o el 3. En realidad siempre que tengamos 3 vectores y 1 de ellos puede ser descrito mediante los otros dos, podemos elegir la \"base\" que queramos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué pasaría si intentaramos calcular la inversa de esta matriz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LinAlgError: Singular matrix`: tenemos una matriz singular. De hecho si vemos nuestra matriz como *columnas* podemos ver que la columna 1 y 4 son iguales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando en nuestra matriz tenemos vectores que pueden describirse mediante combinaciones lineales de los otros, ya se en las filas o en las columnas, obtendremos un determinante = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué es una norma y para qué se usa? Desigualdad triangular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La definición general de la norma se basa en generalizar a espacios vectoriales abstractos el concepto de módulo de un vector de un espacio euclídeo. En un espacio no euclídeo, la noción de camino más corto entre dos puntos no es más identificable que con el de la línea recta; por lo cual, se recurre a las propiedades operacionales de la norma euclídea.\n",
    "\n",
    "En un espacio euclídeo los vectores son representados como segmentos orientados entre puntos del espacio. Dado un vector de un espacio vectorial euclídeo, la norma de un vector es definida como la **distancia** (en línea recta) **entre dos puntos A y B** que delimitan al vector. Coincidiendo en un espacio euclídeo la norma de un vector con el módulo del vector $\\vec{AB}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso general de un espacio euclídeo de $n$ dimensiones se tiene qué:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$||{AB}|| = \\sqrt{(b_1 - a_1)^2 + (b_2 - a_2)^2 + \\dots + (b_n - a_n)^2 }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esto se sigue que, fijada una base ortonormal $B$ en la cual un vector $v$ se da a partir de sus componentes en esta base, $VB=(v_1,v_2,\\dots, v_n)$, la norma de dicho vector vendrá dada por:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ ||v||= \\sqrt{v_1^2+ v_2^2+ \\dots + v_n^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Propiedades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La norma de un vector siempre tiene que ser $||v|| \\geq 0$.\n",
    "* $||v|| = 0 \\Longleftrightarrow v = 0$.\n",
    "* Dados 2 vectores $u$ y $v$, al sumar $u+v =s$ y calcular la norma de $||s||$ obtendremos que: $||s|| \\leq ||u|| + ||v||$.\n",
    "* $||av|| = abs(a) * ||v||$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La 3er propiedad es conocida como **desigualdad triangular**. Y nos da la noción de que el camino más corto siempre es una linea recta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver como calcular la norma en Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#Paleta de colores\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([2,7])\n",
    "v2 = np.array([3,5])\n",
    "v1_plus_v2 = v1 + v2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\"\n",
    "graficar_vectores([v1,v2, v1_plus_v2], color=['red','blue', 'purple'], alpha=1)\n",
    "plt.xlim(-1,6)\n",
    "plt.ylim(-1,13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular la norma, utilizamos la función `linalg.norm()` de NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_v1   = round(np.linalg.norm(v1),3)\n",
    "norm_v2   = round(np.linalg.norm(v2),3)\n",
    "norm_v1v2 = np.linalg.norm(v1_plus_v2)\n",
    "print(f'||v1||: {norm_v1}\\n||v2||: {norm_v2}\\n||v1+v2||: {norm_v1v2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_v1v2 <= norm_v1 + norm_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que se respeta la desigualdad triangular. El único caso donde tenemos $||v+u|| = ||v||+||u||$ es cuando los 3 vectores están uno sobre el otro (sobre la misma linea recta), es decir, cuando son colineales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a graficar la suma de nuestros vectores, de forma que quede la punta de $v_1$ con la cola de $v_2$ y luego el vector resultante desde la cola de $v_1$ a la punta de $v_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([0,0,2,7])\n",
    "v2 = np.array([0,0,3,5])\n",
    "\n",
    "v1_aux = np.array([v1[2], v1[3], v2[2], v2[3]])\n",
    "v1v2 = np.array([0,0,5,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.quiver([v1[0], v1_aux[0], v1v2[0]], \n",
    "           [v1[1], v1_aux[1], v1v2[1]],\n",
    "           [v1[2], v1_aux[2], v1v2[2]],\n",
    "           [v1[3], v1_aux[3], v1v2[3]],\n",
    "           angles = 'xy',\n",
    "           scale_units = 'xy',\n",
    "           scale = 1,\n",
    "           color = sns.color_palette())\n",
    "plt.grid()\n",
    "plt.axhline(y=0, color='black')\n",
    "plt.axvline(x=0, color='black')\n",
    "plt.xlim(-1,6)\n",
    "plt.ylim(-1,13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de normas: norma 0, norma 1, norma 2, norma infinito y norma L2 al cuadrado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos distintos tipos de normas que solemos utilizar en Machine Learning, por ejemplo, para medir los errores. Entre las más comunes tenemos los siguientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partiendo de que tenemos un vector $v=(v_1, v_2, \\dots, v_n)$:\n",
    "\n",
    "* $L0$: Número de elementos de $v$ diferentes de 0, $\\# v_i \\not = 0$\n",
    "* $L1$: La suma de los valores absolutos de las elementos de $v$, $\\sum_{i}{abs(v_i)}$\n",
    "* $L2$: Distancia euclídeana, $||v||= \\sqrt{v_1^2+ v_2^2+ \\dots + v_n^2} $\n",
    "* $L2^2$: Distancia euclídea al cuadrado,  $||v||^2= v_1^2+ v_2^2+ \\dots + v_n^2$ \n",
    "    * Por ejemplo, al hacer producto interno de un vector por si mismo, $v \\cdot v^t$. Esto nos podría brindar ventajas computacionales.\n",
    "* $L \\infty$: El valor máximo de nuestros valores absolutos de los elementos de $v$, $\\text{max}_i (abs(v_i))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver como podríamos calcularlas con Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([1,2,0,5,6,0])\n",
    "print(vector)\n",
    "print(np.linalg.norm(vector, ord = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([1,2,3,4,5])\n",
    "print(vector)\n",
    "print(np.linalg.norm(vector, ord = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La instrucción .norm tiene por defecto la norma L2\n",
    "l2 = np.linalg.norm(vector)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([3,4])\n",
    "print(vector)\n",
    "print(np.linalg.norm(vector, ord = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $L2^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_2 = (np.linalg.norm(vector, ord = 2)**2)\n",
    "print(l2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que también se puede representar como el producto interno del vector por sí mismo transpuesto para que las dimensiones coincidan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_dot = vector.dot(vector.T)\n",
    "print(l2_dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $L \\infty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([1,2,3,4,-500])\n",
    "print(np.linalg.norm(vector, ord=np.inf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las normas se utilizan para determinar el módulo de regularización en la construcción de modelos de Machine Learning. La regularización se utiliza para \"castigar\" la complejidad de un modelo y evitar *overfitting*, laS más utilizadas son $L2$ por su simplicidad y $L1$ para esparcidad de los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más info en: [Regularización para lograr la simplicidad: Regularización L₂](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization) (Se quitará la versión en español el 31 de Julio). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/FmyrdWw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El producto interno como función de una norma y su visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anteriormente vimos que podemos ver a la norma $L2$ como el producto interno del vector por si mismo, transpuesto; ahora, vamos a explorar la idea de expresar el producto interno de 2 vectores como **la norma de cada vector por el ángulo que están formando entre ellos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, teniendo los vectores $v_1$ y $v_2$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ v_1^t  \\cdot v_2 = norm(v_1) norm(v_2) \\cos(\\alpha) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([0,0,0,3])\n",
    "v2 = np.array([0,0,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.axvline(x=0, color='gray')\n",
    "plt.axhline(y=0, color = 'gray')\n",
    "plt.xlim(-2,4)\n",
    "plt.ylim(-2,4)\n",
    "\n",
    "plt.quiver([v1[0], v2[0]],\n",
    "           [v1[1], v2[1]],\n",
    "           [v1[2], v2[2]],\n",
    "           [v1[3], v2[3]],\n",
    "           angles = 'xy',\n",
    "           scale_units= 'xy',\n",
    "           scale = 1,\n",
    "           color = sns.color_palette()\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tener un triangulo rectángulo y a la vez tener un ángulo de 90 grados partido a la mitad por el vector amarillo, sabemos que el ángulo que forman los vectores es de 45°."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos la igualdad que mencionamos arriba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([0,3])\n",
    "v2 = np.array([3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( (v1.T).dot(v2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar `math` o `numpy` para darle los valores de coseno y del ángulo.\n",
    "\n",
    "Para el caso de `math` tenemos `math.cos` para la función coseno y `math.pi` para indicarle el valor de pi y lo dividimos entre 4, ya que, $\\pi / 2 = 90°$ y queremos la mitad  de eso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print( np.linalg.norm(v1)*np.linalg.norm(v2)*math.cos(math.pi / 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de `NumPy` tenemos `np.cos` para la función coseno y `np.deg2rad()` para indicarle en radianes un valor que suministramos en grados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.linalg.norm(v1)*np.linalg.norm(v2)*np.cos( np.deg2rad(45) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que sí se puede describir un producto interno entre 2 vectores como el producto de sus normas por el coseno del ángulo que forman. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No olvidemos agregar el ángulo en **radianes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eso se vuelve importante en Machine Learning ya qué el coseno se utiliza para medir el **accuracy** del modelo, midiendo la similitud entre las etiquetas y los valores que el modelo ha predicho.\n",
    "\n",
    "Teniendo la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\cos{x} = \\frac{v_1v_2}{norm(v_1)norm(v_2)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto lo podemos imaginar como si tuvieramos 2 vectores, 1 de ellos representa el **vector de predicciones** y el otro, representa el **vector de etiquetas** (valores reales) y lo que queremos en un modelo es conseguir que el ángulo entre esos 2 vectores sea el mínimo posible, sin entrar en un sobre-ajuste; así conseguiríamos buenas predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[VIDEO: ¿Qué tan parecidos son dos textos?| Similaridad coseno](https://www.youtube.com/watch?v=z0b7TAVtHrw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIDEO: Similaridad coseno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo las siguientes palabras:\n",
    "\n",
    "1. Tigre Tigre Perro\n",
    "2. Tigre Oso Perro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En dos vectores:\n",
    "\n",
    "$v_1 = [2,0,1]$ \n",
    "\n",
    "$v_2 = [1,1,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "v1 = np.array([2,0,1])\n",
    "v2 = np.array([1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, representandolos de la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                   | 1           | 2             |\n",
    "|-------------------|-------------|---------------|\n",
    "| Tigre             | 2           | 1             | \n",
    "| Oso               | 0           | 1             | \n",
    "| Perro             | 1           | 1             | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la similaridad, como ya lo mencionamos antes, estará dada por:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{sim}(A,B) = \\cos{\\theta} = \\frac{A \\cdot B}{||A|| ||B||}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/WpfDNBt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/5l0TUjp.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El producto punto sería el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_dot_v2 = (v1.T).dot(v2)\n",
    "print(v1_dot_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a obtener las normas de los vectores, utilizaremos $L2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_v1 = np.linalg.norm(v1, ord = 2)\n",
    "print(norm_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_v2 = np.linalg.norm(v2, ord = 2)\n",
    "print(norm_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando el valor del $\\cos{\\theta}$ a partir de eso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_theta = v1_dot_v2 / (norm_v1 * norm_v2)\n",
    "print(cos_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer esto directamente utilizando ScikitLearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([[2,0,1]])\n",
    "v2 = np.array([[1,1,1]])\n",
    "print(cosine_similarity(v1, v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices y vectores especiales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La matriz diagonal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **matriz diagonal** es una matriz cuadrada en la que todos los elementos que no son de la diagonal principal, son cero. Los elementos de la diagonal principal pueden ser nulos o no.\n",
    "\n",
    "Son matrices de la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "a & 0 & 0 & 0 \\\\ \n",
    "0 & b & 0 & 0 \\\\ \n",
    "0 & 0 & c & 0 \\\\ \n",
    "0 & 0 & 0 & d \\\\ \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las razones por las que las matrices diagonales son tan importantes en álgebra lineal es por la facilidad con la que permiten realizar cálculos. Por eso son tan utilizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Suma y resta de matrices diagonales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suma de dos matrices diagonales es muy sencilla, simplemente hay que sumar (o restar) los números de las diagonales:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ diag(a_1,\\dots,a_n) \\pm diag(b_1,\\dots,b_n) = diag(a_1 \\pm b_1 ,\\dots,a_n \\pm b_n) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & 3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & 3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "2 & 0 & 0 & 0 \\\\ \n",
    "0 & 4 & 0 & 0 \\\\ \n",
    "0 & 0 & 6 & 0 \\\\ \n",
    "0 & 0 & 0 & 8 \\\\ \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiplicación de matrices diagonales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ diag(a_1,\\dots,a_n) \\cdot diag(b_1,\\dots,b_n) = diag(a_1 \\cdot b_1 ,\\dots,a_n \\cdot b_n) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver una multiplicación de 2 matrices de 2 diagonales, tan solo tenemos que multiplicar los elementos de las diagonales entre sí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "-1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & 3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & -3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-1 & 0 & 0 & 0 \\\\ \n",
    "0 & 4 & 0 & 0 \\\\ \n",
    "0 & 0 & -9 & 0 \\\\ \n",
    "0 & 0 & 0 & 16 \\\\ \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de la **potencia** ocurre los mismo, elevamos cada elemento de la matriz al exponente al que tenemos la matriz entera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Determinante de una matriz diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El determinante de una matriz diagonal es el producto de los elementos de la diagonal principal, ya que el resto de elementos tendrá un 0 que \"cancele\" esa parte del determinante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A = diag(a_1, \\dots, a_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$det(A)= \\prod_{i=1}^{n}{a_i} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inversa de una matriz diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una matriz diagonal se puede invertir, **si y sólo si, todos los elementos de la diagonal principal son diferentes de 0**. En dicho caso decimos que la matriz diagonal es una matriz regular (sí se puede invertir)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrarla, basta con escribir el recíproco de cada uno de los elementos de la matriz:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A =\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & 3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{pmatrix}\n",
    "\\longrightarrow\n",
    "A^{-1}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\frac{1}{1} & 0 & 0 & 0 \\\\ \n",
    "0 &\\frac{1}{2} & 0 & 0 \\\\ \n",
    "0 & 0 & \\frac{1}{3} & 0 \\\\ \n",
    "0 & 0 & 0 & \\frac{1}{4} \\\\ \n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eigenvalues de una matriz diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores propios de una matriz diagonal son los elementos de su diagonal principal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A =\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & 3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{pmatrix}\n",
    "\\longrightarrow\n",
    "\\lambda_1 =1 ; \n",
    "\\lambda_2 =2 ;\n",
    "\\lambda_3 =3 ;\n",
    "\\lambda_4 =4 ;\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar la instrucción `np.diag()` para crear una matriz diagonal y únicamente indicarle los valores de la diagonal principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_elements = np.array([1,2,3,4,5])\n",
    "diag_matrix = np.diag(diag_elements)\n",
    "print(diag_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tener una matriz diagonal y **multiplicarla por un vector** realmente no estamos obteniendo una combinación lineal como tal, ya qué la primer componente del vector se multiplica con el primer elemento de la diagonal principal, el segundo con el segundo y así."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A =\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 \\\\ \n",
    "0 & 2 & 0 & 0 \\\\ \n",
    "0 & 0 & 3 & 0 \\\\ \n",
    "0 & 0 & 0 & 4 \\\\ \n",
    "\\end{pmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\ \n",
    "x_2 \\\\ \n",
    "x_3 \\\\ \n",
    "x_4 \\\\ \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 * x_1 \\\\ \n",
    "2* x_2 \\\\ \n",
    "3* x_3 \\\\ \n",
    "4* x_4 \\\\ \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decimos que lo que está haciendo es una **ponderación de los elementos del vector**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo la matriz diagonal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.diag([2,3,4,5])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y un vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([[1,1,1,1]])\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos el producto, con el vector traspuesto por el tema de las dimensiones :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_v1 = A.dot(v1.T)\n",
    "print(A_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un nuevo vector que \"amplifica\" los valores de la diagonal principal en proporción a los valores del vector, en este caso 1; así que se mantuvo igual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver el caso en donde queremos calcular la **inversa de la matriz**, lo cuál es muy fácil. Si queremos encontrar una matriz tal que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A A^{-1} = I$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, tendremos que conseguir que las diagonales se vuelvan 1. Y sabemos que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a \\cdot \\frac{1}{a} = \\frac{a}{a} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que bastaría con multiplicar cada elemento de la diagonal principal por sus recíprocos. Es decir, por otra matriz que en su diagonal principal contenga los recíprocos de la matriz original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo la matriz diagonal $A$ de arriba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.diag([2,3,4,5])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y su matriz diagonal inversa, añadiendo los recíprocos de la diagonal principal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv = np.diag([1/2, 1/3, 1/4, 1/5])\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y multiplicamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = A.dot(A_inv)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "como esperabamos, obtuvimos la matriz identidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El hecho de poder calcular la inversa de una forma tan fácil, y por lo tanto, poder resolver ciertas operaciones más fácilmente; nos ayuda a reducir mucho el coste computacional de ciertos problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz simétrica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una matriz es simétrica si es **una matriz cuadrada**, que además tiene la característica de ser igual a su transpuesta. Una matriz de $n\\times m$ elementos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\begin{pmatrix}\n",
    "a_{11} & a_{12} & a_{13} & \\dots & a_{1m} \\\\ \n",
    "a_{21} & a_{22} & a_{23} & \\dots & a_{2m} \\\\ \n",
    "a_{31} & a_{32} & a_{33} & \\dots & a_{2m} \\\\ \n",
    "\\vdots & \\vdots & \\vdots & \\ddots& \\vdots  \\\\\n",
    "a_{n1} & a_{n2} & a_{n3} & \\dots & a_{nm} \\\\ \n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "es simétrica, su es una matriz cuadrada $(m=n)$ y además, $a_{ij} = a_{ji}$ para todo $i$, $j$ con $i$, $j$ $=1,2,3,4,\\dots,n$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A = A^T \\implies \\text{ es simétrica}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\begin{pmatrix}\n",
    "-8 & 1 & 3 \\\\ \n",
    " 1 & 7 & 4 \\\\ \n",
    " 3 & 4 &9 \\\\ \n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "podemos visualizarlo como si fuera un \"espejo\" a través de la diagonal principal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Propiedades de las matrices simétricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. La suma de dos matrices simétricas es una matriz simétrica.\n",
    "2. El producto de dos matrices simétricas NO siempre es simétrico.\n",
    "3. Si $A$ es una matriz simétrica $p\\times p$, y $B$ una matriz $p \\times q$, entonces $B^{T}AB$ es simétrica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los teoremas básicos que concierne a este tipo de matrices es el **teorema  espectral de dimensión finita**, que dice que toda matriz simétrica cuyos elementos sean *reales*, es *diagonalizable*. En particular, es diagonalizable mediante una **matriz ortogonal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un ejemplo con Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simetrica = np.array([[1,2,3],\n",
    "                      [2,1,7],\n",
    "                      [3,7,11]])\n",
    "print(simetrica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simetrica_T = simetrica.T\n",
    "print(simetrica_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "podemos ver que obtenemos la misma matriz al transponerla.\n",
    "\n",
    "Ahora, vamos a verificar la siguiente propiedad:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ (AB)^t = B^t A^t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pero si son simétricas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ (AB)^t = B A$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y esto último también tiene implicaciones importantes al agilizar nuestros cómputos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectores ortogonales, matrices ortogonales y sus propiedades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectores Ortogonales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hay que aclarar que, **NO existen vectores que sean ortogonales por sí mismos**, ya que estos requieren estar \"en compañía\"  o en referencia de otro vector para poder definirlos como ortogonales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos vectores son **ortogonales** si su **producto interno es cero**. En general, el término de **ortogonalidad** es una generalización de la noción que nos da el concepto de **perpendicularidad**. En el caso de un espacio euclídeo decimos que **ortogonal** y **perpendicular** significan lo mismo; sin embargo, en espacios de dimensión finita y en geometrías no euclídeas, el concepto de ortogonalidad generaliza al de perpendicularidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente imagen tendríamos el caso de 3 **planos ortogonales**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2c/3D_coordinate_system.svg/350px-3D_coordinate_system.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que existe una relación entre el producto interno de 2 vectores y el ángulo que forman entre sí; más específicamente, con el coseno del ángulo que forman. Y como estamos hablando de vectores **perpendiculares**, es decir, con un ángulo de $\\pi / 2$ radianes o 90°, tendríamos el caso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\cos{\\pi / 2} = \\cos{90°} = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualicemos este caso con Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0,0,2, 2])\n",
    "y = np.array([0,0,2,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.quiver([x[0],y[0]],\n",
    "           [x[1],y[1]],\n",
    "           [x[2],y[2]],\n",
    "           [x[3],y[3]],\n",
    "           angles = 'xy',\n",
    "           scale_units = 'xy',\n",
    "           scale = 1,\n",
    "           color = sns.color_palette()\n",
    "          )\n",
    "\n",
    "plt.grid()\n",
    "plt.axhline(y=0, color='gray')\n",
    "plt.axvline(x=0, color='gray')\n",
    "\n",
    "plt.xlim(-2,4)\n",
    "plt.ylim(-3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualmente podemos intuir que tenemos 2 vectores perpendiculares entre sí, pero eso es gracias a que tenemos la escala correcta. Así que mejor, vamos a calcular el ángulo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabiendo que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x \\cdot y = ||x|| ||y|| \\cos{\\theta} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "despejemos theta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\cos{\\theta} = \\frac{x \\cdot y}{||x|| ||y||} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\theta =  \\arccos{\\frac{x \\cdot y}{||x|| ||y||}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([2, 2])\n",
    "y = np.array([2,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.arccos( (x.dot(y.T) ) / (  np.linalg.norm(x)*np.linalg.norm(y) ) )\n",
    "print(f'{theta} rads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_deg = np.degrees(theta)\n",
    "print(f'{theta_deg} Deg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectores Ortonormales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por el otro lado, tenemos a los vectores **ortonormales**. Estos son vectores que también tienen un **producto interno igual a 0** y *además*, son **vectores unitarios**, es decir, su norma es igual a 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.centroestudioscervantinos.es/wp-content/uploads/2021/01/vectores-ortogonales-y-ortonomales-lifeder.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomemos los vectores anteriores que ya son **ortogonales**, pero aún NO son **ortonormales**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([2, 2])\n",
    "y = np.array([2,-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculemos la norma de cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.norm(x))\n",
    "print(np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no tienen norma $=1$, por lo que no son **ortonormales**. \n",
    "\n",
    "Vamos a tomar los siguientes vectores de ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0,0,1, 0])\n",
    "y = np.array([0,0,0, -1])\n",
    "\n",
    "plt.quiver([x[0],y[0]],\n",
    "           [x[1],y[1]],\n",
    "           [x[2],y[2]],\n",
    "           [x[3],y[3]],\n",
    "           angles = 'xy',\n",
    "           scale_units = 'xy',\n",
    "           scale = 1,\n",
    "           color = sns.color_palette()\n",
    "          )\n",
    "\n",
    "plt.grid()\n",
    "plt.axhline(y=0, color='gray')\n",
    "plt.axvline(x=0, color='gray')\n",
    "\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a corroborar que son **ortogonales** aplicando el producto interno, esperando obtener cero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.dot(y.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tenemos 2 vectores **ortogonales**, ahora vamos a verificar que tengan norma $=1$ para verificar que sean **ortonormales**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.norm(x))\n",
    "print(np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, tenemos 2 vectores que son **ortonormales** ya que forman un ángulo de 90° y tienen una norma igual a 1.\n",
    "\n",
    "Este es un concepto importante al momento de construir un espacio vectorial y definir sus operaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices ortogonales y sus propiedades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una matriz es **ortogonal** cuando todas sus filas son **mutuamente ortonormales** y también sus columnas son **mutuamente ortonormales**. Es decir, si pensamos a las filas y columnas como vectores, estos vectores serían mutuamente ortonormales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra definición sería la siguiente:\n",
    "\n",
    "Una matriz $A$ es **ortogonal** si multiplicada por su transpuesta $A^T$ da como resultado la matriz identidad $I$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A A^{T} =  A^{T}A = I $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como consecuencia de lo anterior, tenemos que la transpuesta de una matriz ortogonal es igual a su **matriz inversa**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A^T = A^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.array([[1,0,0],\n",
    "                   [0,1,0],\n",
    "                   [0,0,1],\n",
    "                  ])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos la norma de los vectores, aunque sea fácil de ver que tienen norma $=1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(matrix[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(matrix[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(matrix[:, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comprobar que sus columnas son mutuamente ortonormales, es decir, son **ortonorgonales** de **norma = 1**. En este caso podemos ver que son de norma 1, pues es el $1$ es el único valor que tienen en sus componentes, y podríamos hacer un producto interno para saber que son ortogonales.\n",
    "\n",
    "Comencemos haciendo el producto de las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(matrix[:, 0].dot(matrix[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(matrix[:, 0].dot(matrix[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(matrix[:, 1].dot(matrix[:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "también si queremos podemos hacer el de las filas, aunque ya lo tenemos claro con haber realizado las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(matrix[0, :].dot(matrix[1,:]))\n",
    "print(matrix[0, :].dot(matrix[2,:]))\n",
    "print(matrix[1, :].dot(matrix[2,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hemos visto que si la visualizamos como vectores columna o fila, obtendremos vectores mutuamente ortonormales. Ahora vamos a comprobar las propiedades que vimos arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "Identity = matrix.dot(matrix.T)\n",
    "print(Identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "M_T = matrix.T\n",
    "print(M_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "M_inverse = np.linalg.inv(matrix)\n",
    "print(M_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(M_T == M_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que sí se cumplen. Así que, esta es una matriz ortogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de las matrices no tenemos como tal una matriz **ortonormal** ya que no tendría caso definirla de esa forma ya que contamos con vectores mutuamente ortonormales y no habría forma de encontrar una distinción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a introducir rápidamente el concepto de **matrices de rotación**. Las cuales nos ayudarán a generar matrices ortogonales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de rotación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En álgebra lineal, una **matriz de rotación** es la matriz que representa una rotación en el espacio euclídeo. Por ejemplo, la matriz:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R(\\theta)=\n",
    "\\begin{bmatrix}\n",
    "\\cos{\\theta} & -\\sin{\\theta} \\\\\n",
    "\\sin{\\theta} &  \\cos{\\theta}\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "que representa una rotación de $\\theta$ grados del plano **en sentido antihorario**. En tres dimensiones, las matrices de rotación representan rotaciones de manera concisa y se usan frecuentemente en geometría, física e informática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver como podríamos utilizar una matriz de rotación de ese estilo para generar matrices ortogonales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86231887  0.50636564]\n",
      " [-0.50636564  0.86231887]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[np.cos(100), -np.sin(100)],\n",
    "              [np.sin(100),  np.cos(100)],\n",
    "             ])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos si tiene vectores de norma = 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "print( np.linalg.norm(A[0,:]) )\n",
    "print( np.linalg.norm(A[1,:]) )\n",
    "print( np.linalg.norm(A[:,0]) )\n",
    "print( np.linalg.norm(A[:,1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un valor muy muy cercano a 1, esto se debe a que existen ciertos problemas para representar nuestros números computacionalmente.\n",
    "\n",
    "\n",
    "Ahora, vamos a confirmar que son **mutuamente ortogonales**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(A[0,:].dot(A[1,:]))\n",
    "print(A[:,0].dot(A[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así ya hemos confirmado que está conformada por vectores **ortonormales**. Vamos a verificar las propiedades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86231887 -0.50636564]\n",
      " [ 0.50636564  0.86231887]]\n"
     ]
    }
   ],
   "source": [
    "A_T = A.T\n",
    "print(A_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86231887 -0.50636564]\n",
      " [ 0.50636564  0.86231887]]\n"
     ]
    }
   ],
   "source": [
    "A_inv = np.linalg.inv(A)\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -7.93771519e-18]\n",
      " [-7.93771519e-18  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(A_T.dot(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 7.93771519e-18]\n",
      " [7.93771519e-18 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(A.dot(A_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que obtenemos la misma matriz, aunque no tenemos como tal ceros fuera de la diagonal principal, pero **sí tenemos números muy muy cercanos a 0**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver algunos de los errores a los que podríamos llegar si no tenemos cuidado con esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86231887 -0.50636564]\n",
      " [ 0.50636564  0.86231887]]\n"
     ]
    }
   ],
   "source": [
    "A_inv = np.linalg.inv(A)\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86231887 -0.50636564]\n",
      " [ 0.50636564  0.86231887]]\n"
     ]
    }
   ],
   "source": [
    "print(A_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí todo normal, estamos repitiendo los pasos anteriores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Que pasaría si dividieramos entre el producto de nuestra traspuesta y de la matriz original? Tendríamos una operación que no estaría definida (o infinito). Sin embargo, utilizando el resultado anterior obtenemos lo siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -1.25980837e+17]\n",
      " [-1.25980837e+17  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(1/ A_T.dot(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos obteniendo valores muy muy grandes en nuestros elementos fuera de la diagonal principal. Esto de debe a que realizó los cómputos con los valores `-7.93771519e-18` los cuales al hacer el recíproco nos da un número que es muy muy grande, de forma que estaría amplificando estos elementos de la matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El determinante y la traza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El determinante se define como una [forma multilineal alternada](https://es.wikipedia.org/wiki/Forma_multilineal) sobre un espacio vectorial. Esta definición indica una serie de propiedades matemáticas y generaliza el concepto de determinante de una matriz haciéndolo aplicable en distintos campos. El concepto de *determinante* fue introducido para estudiar el número de soluciones de los sistemas de ecuaciones lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El determinante de una matriz siempre es un número real y únicamente lo podremos calcular para matrices cuadradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de matrices, el terminante de una matriz nos indica si estamos ante un **sistema singular** o **no singular** de ecuaciones lineales. Por ello, si el resultado del determinante es cero, estaremos ante una matriz singular, y si el resultado es $\\not = 0$ entonces estamos ante una matriz no singular.\n",
    "\n",
    "Este nos habla sobre la **transformación que ejerce una matriz sobre el espacio que está transformando**. Si es negativo, nos da el \"espejo\" de nuestro espacio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre algunos de sus usos tenemos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nos permite estudiar la posición relativa de rectas y planos.\n",
    "\n",
    "* Podemos obtener la ecuación implícita de un plano.\n",
    "\n",
    "* Son un instrumento para calcular áreas de figuras en el plano.\n",
    "\n",
    "* Nos ayudan a calcular el rango de una matriz con parámetros.\n",
    "\n",
    "* Son útiles para calcular el volumen de los paralepípedos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que podemos construir nuestro espacio a partir de una *base* de *vectores* que nos permitan construir el resto a partir de operaciones de suma o multiplicación (combinaciones lineales).\n",
    "\n",
    "¿Qué pasaría si tuvieramos bases de vectores en la misma dirección, pero con diferentes magnitudes? En ese caso, podrían cambiar algunas de nuestra funciones al reescribir nuestras matrices en funciones de esos nuevos vectores. Para esto utilizamos la **traza** que nos permite trabajar **independientemente del sistema de referencia** en el que estemos trabajando, de forma que siempre nos devuelve los mismos valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/LoqexDt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En álgebra lineal, la **traza** es una matriz $A$ de tamaño $n \\times m$, denotada por $tr(A)$, se define como la suma de los elementos de la diagonal principal de $A$, es decir:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$tr(A) = \\sum_{i = 1}^{n}{a_{ii}} = a_{11}+ a_{22} + \\dots + a_{nn}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $a_{ii}$ representa el elemento que está en la $i-$ésima fila y en la $i-$ésima columna de la matriz $A$. Para cualquier otra matriz, la traza es la **suma de sus valores propios**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido al especial comportamiento de la traza de una matriz al cambiar de base, puede definirse una unívocamente  la traza de una aplicación lineal, **independientemente de cual sea la base elegida**, Si un espacio vectorial de dimensión finita está dotado de un producto escalar y se tiene una base ortonormal, entonces la traza de un *endomorfismo* de dicho espacio viene dada por:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ tr f := \\sum_{k}\\langle f(e_{k}), e_{k}\\rangle $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede comprobarse que si $A_{f}$ es la matriz de dicha aplicación respecto a dicha base, la cantidad anterior **es igual** a la traza de la matriz $A$. Y de hecho, si $B_{f}$ es la matriz de la misma aplicación respecto a cualquier otra base ortonormal se tiene:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ tr f = tr A_{f} = tr B_{f} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.array([[1,2,3],\n",
    "                   [4,5,6],\n",
    "                   [7,8,9],\n",
    "                  ])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener la traza de nuestra matriz haremos lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "traza =  np.trace(matrix)\n",
    "print(traza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Funciones_Auxiliares/Graficar_Vectores.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir nuevos vectores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([0,1])\n",
    "v2 = np.array([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.25, 1.25)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graficar_vectores([v1,v2], ['purple','blue'], 1)\n",
    "plt.xlim(-0.25,1.25)\n",
    "plt.ylim(-0.25,1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué pasaría si aplicamos una matriz a estos 2 vectores? Recordemos que con estos vectores podemos generar a todo $\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2,0],\n",
    "              [0,2]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que este tipo de matrices \"amplifican\" las coordenadas de nuestros vectores. En este caso los estaría duplicando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2]\n",
      "[2 0]\n"
     ]
    }
   ],
   "source": [
    "A_v1 = A.dot(v1)\n",
    "A_v2 = A.dot(v2)\n",
    "print(A_v1)\n",
    "print(A_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.25, 2.25)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graficar_vectores([A_v1,A_v2], ['red','green'], 1)\n",
    "plt.xlim(-0.25,2.25)\n",
    "plt.ylim(-0.25,2.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que seguimos teniendo 2 vectores ortogonales, pero ya no son de norma igual a 1, sino que ahora miden 2.\n",
    "\n",
    "Imaginemos esto como si tuvieramos 2 cuadrados a partir de las longitudes de nuestros vectores, de forma que ahora contamos con 2 cuadrados proporcionales de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/HdMOokZ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a calcular el determinante de A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "det_A = np.linalg.det(A)\n",
    "print(det_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos decir que, *el cuadrado unitario* formado por 2 vectores *ortonormales*, aumento 4 veces su área."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "area_T = abs( (A_v1[0] - A_v2[0])  * abs( A_v1[1] - A_v2[1]) ) # lado * Lado\n",
    "print(area_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver que ocurriría en caso de tener un **determinante negativo**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2  0]\n",
      " [ 0  2]]\n"
     ]
    }
   ],
   "source": [
    "B = A * [-1, 1]\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.0\n"
     ]
    }
   ],
   "source": [
    "det_B = np.linalg.det(B)\n",
    "print(det_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver que es lo que les haría esta matriz a nuestros vectores anteriores, vamos a escribirlos de nuevo y vamos a graficarlos todos juntos para que sea más visual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([0,1])\n",
    "v2 = np.array([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_B = B.dot(v1)\n",
    "v2_B = B.dot(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 2.0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUr0lEQVR4nO3df7DV9X3n8ecbroAmUQhQQ4CAuEBip83WUNQkU+/kV40NardJ17T1Rzcp7W6dTXfS2THrbNpmdqa1O5M/UmwcJnHUNmPT7a8AYqw/OGabDQpaBIXyQ9eVX6kRBMNKjVze+8f5gDfX++Nwz/ee7znu8zFz5n6/3/O55/Piw+W+7vmec79EZiJJ0qS6A0iSuoOFIEkCLARJUmEhSJIAC0GSVFgIkiSggkKIiPkRsSEitkfE0xHxuWHGRER8JSL2RMTWiLi43XklSdXqq+AxTgCfz8wnIuJtwOMR8UBmbh805uPA4nK7BPhq+ShJ6hJtP0PIzIOZ+UTZ/iGwA5g7ZNjVwN3ZtBGYHhFz2p1bklSdKp4hnBYRC4GfAR4dctdcYO+g/X3l2MEhn78SWAkwbdq0973rXe+qMt6EOHnyJJMmdf9LMeaszt69e8lM/PqsTi/k7IWMALt27XoxM2eP53MrK4SIeCvw18DvZObL43mMzFwNrAZYunRp7ty5s6p4E6bRaNDf3193jDGZszr9Cxdy5Nxz2bJ1a91RxtQL6wm9kbMXMgJExP8Z7+dWUncRcRbNMvhGZv7NMEP2A/MH7c8rx6Tec+gQnDhRdwqpclW8yyiArwM7MvPLIwxbA1xf3m10KXA0Mw+OMFbqXgcOwLFjFoLelKo4ZfQB4DpgW0RsKcf+C/AugMy8HVgPXAnsAV4Bfr2CeaXOu/fe5seBgWY5vPOd9eaRKtR2IWTmPwAxxpgEfrvduaTarV37+va998Jv/EZ9WaSKdf9L5lK3OH4cHnzw9f116+rLIk0AC0Fq1UMPNUvhlAce+PF9qcdZCFKrBp8ugmYZPPxwPVmkCWAhSK3IHP4U0dCSkHqYhSC14h//sfmuoqHWrWuWhfQmYCFIrTj1TGDevNePzZsH+/fDli21RJKqZiFIrTh5Eh57DG655fVj3/0u/PmfQw9cYkVqRaUXt5PetP7gD5ofH3/89WOTJ8Ov/mo9eaQJ4DMESRJgIUiSCgtBkgRYCJKkwkKQJAEWgiSpsBAkSYCFIEkqLARJEmAhSJIKC0GSBFgIkqTCQpAkARaCJKmwECRJgIUgSSosBEkSYCFIkgoLQZIEVFQIEXFHRLwQEU+NcH9/RByNiC3l9sUq5pUkVaevose5E1gF3D3KmP+ZmZ+oaD5JUsUqeYaQmd8BDlfxWJKkenTyNYTLIuLJiLgvIn6yg/NKklpQ1SmjsTwBLMjMYxFxJfB3wOKhgyJiJbASYPbs2TQajQ7FG79jx46Zs0Jdn3PmTI4sWsTA1Kk0tm+H3bvrTjSqrl/Pohdy9kLGtmVmJTdgIfBUi2OfA2aNNmbJkiXZCzZs2FB3hJaYsyJf/WpeDvneRYsy9+2rO82Yun49i17I2QsZMzOBzTnO7+MdOWUUEe+IiCjby2meqjrUibklSa2p5JRRRNwD9AOzImIf8HvAWQCZeTvwSeDfR8QJ4DhwbWkySVKXqKQQMvPTY9y/iubbUiVJXcrfVJYkARaCJKmwECRJgIUgSSosBEkSYCFIkgoLQZIEWAiSpMJCkCQBFoIkqbAQJEmAhSBJKiwESRJgIUiSCgtBkgRYCJKkwkKQJAEWgiSpsBAkSYCFIEkqLARJEmAhSJIKC0GSBFgIkqTCQpAkARaCJKmwECRJgIUgSSoqKYSIuCMiXoiIp0a4PyLiKxGxJyK2RsTFVcwrSapOVc8Q7gSuGOX+jwOLy20l8NWK5pUkVaSSQsjM7wCHRxlyNXB3Nm0EpkfEnCrmliRVo69D88wF9g7a31eOHRw8KCJW0nwGwezZs2k0Gh2KN37Hjh0zZ4W6PufMmRxetJic2kdj+3bYvbvuRKPq+vUseiFnL2RsV6cKoSWZuRpYDbB06dLs7++vN1ALGo0G5qxO1+e8/XYGnn2JyYtm0H/RRTB3bt2JRtX161n0Qs5eyNiuTr3LaD8wf9D+vHJM6ikDA8lxzuakb9DTm1CnvqrXANeXdxtdChzNzINjfZLUbfY+8xonmcRJgoHXTtYdR6pUJaeMIuIeoB+YFRH7gN8DzgLIzNuB9cCVwB7gFeDXq5hX6rSdW18tW8HeTd9n4cL5o46XekklhZCZnx7j/gR+u4q5pDrt2vbq6e2dDz7Pwk/9bI1ppGp5IlRq0Ys7X+TwCwOn93c/uHeU0VLvsRCkFu1au+vH9g89e5RDuw7VlEaqnoUgtWhoIQDsXLuzhiTSxLAQpBYcP3yc57/7/BuOD1cSUq+yEKQW7Pn2HnIg33D8+X94nuMvHa8hkVQ9C0Fqwa51u3j3Ne/mZy8/+/Sxn//9S5m1dBZ7vr2nxmRSdbrq0hVSt/rQf/sQMxbNYPOvfPn0sYt+4QIu+a8f4+jzR2tMJlXHZwhSC2YsmjHs8ZgUTF84vbNhpAliIUiSAAtBklRYCJIkwEKQJBUWgiQJsBAkSYWFIEkCLARJUmEhSJIAC0GSVFgIkiTAQpAkFRaCJAmwECRJhYUgSQIsBElSYSFIkgALQZJUWAiSJKCiQoiIKyJiZ0TsiYibh7n/xoj4QURsKbfPVjGvJKk6fe0+QERMBm4DPgrsAzZFxJrM3D5k6Dcz86Z255MkTYwqniEsB/Zk5rOZ+SPgL4CrK3hcSVIHtf0MAZgL7B20vw+4ZJhxvxQRPwfsAv5TZu4dOiAiVgIrAWbPnk2j0agg3sQ6duyYOSvU7Tlf+ehcznn0HCZNncTmF/43kxoH6o40qm5fz1N6IWcvZGxXFYXQirXAPZn5akT8JnAX8KGhgzJzNbAaYOnSpdnf39+heOPXaDQwZ3W6Pefm1V/mlWdf4ZxF57DsJy7g3GVL6o40qm5fz1N6IWcvZGxXFaeM9gPzB+3PK8dOy8xDmflq2f0a8L4K5pUkVaiKQtgELI6ICyJiCnAtsGbwgIiYM2j3KmBHBfNKkirU9imjzDwRETcB9wOTgTsy8+mI+BKwOTPXAP8xIq4CTgCHgRvbnVeSVK1KXkPIzPXA+iHHvjho+wvAF6qYS5I0MfxNZUkSYCFIkgoLQZIEWAiSpMJCkCQBFoIkqbAQJEmAhSBJKiwESRJgIUiSCgtBkgRYCJKkwkKQJAEWgiSpsBAkSYCFIEkqLARJEmAhSJIKC0GSBFgIkqTCQpAkARaCJKmwECRJgIUgSSosBEkSYCFIkoo3RSG88go0GpBZdxLp/2+ZSeO5BsdfO153FI1DJYUQEVdExM6I2BMRNw9z/9SI+Ga5/9GIWNjunAcOwOrVsGIFzJoF3/42RLT7qJLaERHct/s+Zv7xTFbcs4LVj6/mwA8P1B1LLepr9wEiYjJwG/BRYB+wKSLWZOb2QcM+A7yUmf8qIq4FbgX+7ZnMkwlPPAFr18K6dfD446/f95a3wOc/3+6fRFIVfvf9v8uqTatYt2sd63atA+B9c97HiiUr+MSST3DxnIsJf3rrSpFtnmeJiMuA38/Mny/7XwDIzD8cNOb+MuZ7EdEHfB+YnaNMfs455+SyZct56SU4dKh5+9GPRs4xeXJbf4xxW7jwCM89N72eyc+AOavx1pMvczyfZtLZk3jt/Negy7+vLZy2kOf+5bmOzzuQAzDCv+4pfVOYefZMZp4zkxnTZjApJnHkyBGmT5/e0YxnqhcyAjzyyCOPZ+ay8Xxu288QgLnA3kH7+4BLRhqTmSci4igwE3hx8KCIWAmsBDjrrLP4wQ+O8NprcPbZMG9eBUknwJQpAyxYcKTuGGMyZzWC5MCBPiJgwdkL6o4zpimTprBgWhfmHIDjPzzOif97gil9Uzg5cJIjR47UnWpUAwMDXZ+xXVUUQmUyczWwGmDp0qW5Y8cWBgbge99rnipauxZ27Hjj5517Llx/fYfDFsuXN3jssf56Jj8D5qzOt9Z+gLe87TAfufUjdUcZ0/ITy3ms77GOz3v31rt5+dWX33D8PbPew4olK1ixdAWXzbuMyZOaT+0bjQb9/f0dTnlmeiEj0NbpuCoKYT8wf9D+vHJsuDH7yimj84BDrTz45MnwwQ82b7feCs8803wNYe1aeOQROHECXn4Zfu3X4JKhz0s6oNGA667r/LxnypzV2bbtLI4cmcqfXPkndUcZU6PR4Lr+zi7oxn0bWbVpFQB9k/q4fMHlp18/uPDtF3Y0i85MFYWwCVgcERfQ/MZ/LfArQ8asAW4Avgd8Enh4tNcPRnPhhfC5zzVvR4/C/fc3y2HVqnoKQdKPu23TbVz309exYskKPnbhxzhv2nl1R1KL2i6E8prATcD9wGTgjsx8OiK+BGzOzDXA14E/i4g9wGGapdG2886DX/7l5m1goPlOJN+8INUnM7nz6jtPnwpSb6nkNYTMXA+sH3Lsi4O2/wX4VBVzjaSudxlJel1EMDn8x9ir3hS/qSxJap+FIEkCLARJUmEhSJIAC0GSVFgIkiTAQpAkFRaCJAmwECRJhYUgSQIsBElSYSFIkgALQZJUWAiSJMBCkCQVFoIkCbAQJEmFhSBJAiwESVJhIUiSAAtBklRYCJIkwEKQJBUWgiQJsBAkSYWFIEkCLARJUtFWIUTE2yPigYjYXT7OGGHcQERsKbc17cwpSZoY7T5DuBl4KDMXAw+V/eEcz8x/XW5XtTmnJGkCtFsIVwN3le27gGvafDxJUk3aLYTzM/Ng2f4+cP4I46ZFxOaI2BgR17Q5pyRpAvSNNSAiHgTeMcxdtwzeycyMiBzhYRZk5v6IWAQ8HBHbMvOZYeZaCawEmD17No1GY6x4tTt27Jg5K9QLOY8cOcLAwEDX54TeWE/ojZy9kLFtmTnuG7ATmFO25wA7W/icO4FPjjVuyZIl2Qs2bNhQd4SWmLM6l19+eb73ve+tO0ZLemE9M3sjZy9kzMwENuc4v6e3e8poDXBD2b4B+NbQARExIyKmlu1ZwAeA7W3OK0mqWLuF8EfARyNiN/CRsk9ELIuIr5Ux7wE2R8STwAbgjzLTQpCkLjPmawijycxDwIeHOb4Z+GzZ/l/AT7UzjyRp4vmbypIkwEKQJBUWgiQJsBAkSYWFIEkCLARJUmEhSJIAC0GSVFgIkiTAQpAkFRaCJAmwECRJhYUgSQIsBElSYSFIkgALQZJUWAiSJMBCkCQVFoIkCbAQJEmFhSBJAiwESVJhIUiSAAtBklRYCJIkwEKQJBUWgiQJsBAkSUVbhRARn4qIpyPiZEQsG2XcFRGxMyL2RMTN7cwpSZoY7T5DeAr4N8B3RhoQEZOB24CPAxcBn46Ii9qcV5JUsb52PjkzdwBExGjDlgN7MvPZMvYvgKuB7e3MLUmqVluF0KK5wN5B+/uAS4YbGBErgZVl99WIeGqCs1VhFvBi3SFaYM5qzYqInshJj6wn3Z+zFzICLB3vJ45ZCBHxIPCOYe66JTO/Nd6Jh5OZq4HVZd7NmTni6xLdwpzVMme1zFmdXsgIzZzj/dwxCyEzPzLeBy/2A/MH7c8rxyRJXaQTbzvdBCyOiAsiYgpwLbCmA/NKks5Au287/cWI2AdcBtwbEfeX4++MiPUAmXkCuAm4H9gB/GVmPt3Cw69uJ1sHmbNa5qyWOavTCxmhjZyRmVUGkST1KH9TWZIEWAiSpKJrCiEi/ntE/FNEbI2Iv42I6SOMq/UyGGdwuY7nImJbRGxp521g49UrlxWJiLdHxAMRsbt8nDHCuIGyllsiomNvShhrfSJiakR8s9z/aEQs7FS2M8h4Y0T8YND6fbbTGUuOOyLihZF+vyiavlL+HFsj4uJOZyw5xsrZHxFHB63nF2vIOD8iNkTE9vLv/HPDjDnz9czMrrgBHwP6yvatwK3DjJkMPAMsAqYATwIXdTjne2j+4kcDWDbKuOeAWTWu55g5u2Q9/xi4uWzfPNzfe7nvWA1rOOb6AP8BuL1sXwt8swsz3gis6vT6DZP154CLgadGuP9K4D4ggEuBR7s0Zz+wrua1nANcXLbfBuwa5u/9jNeza54hZObfZ/MdSQAbaf6+wlCnL4ORmT8CTl0Go2Myc0dm7uzknOPRYs7a17PMd1fZvgu4psPzj6aV9Rmc/6+AD8cY13KpIWNXyMzvAIdHGXI1cHc2bQSmR8SczqR7XQs5a5eZBzPzibL9Q5rv4Jw7ZNgZr2fXFMIQ/45msw013GUwhi5Ct0jg7yPi8XJJjm7UDet5fmYeLNvfB84fYdy0iNgcERsj4prORGtpfU6PKT/QHAVmdiTdkPmLkf4Of6mcNviriJg/zP3doBu+Hlt1WUQ8GRH3RcRP1hmknKb8GeDRIXed8Xp24lpGp7VyGYyIuAU4AXyjk9kGq+hyHR/MzP0R8RPAAxHxT+Unj8p08rIi7Rgt5+CdzMyIGOl90AvKei4CHo6IbZn5TNVZ36TWAvdk5qsR8Zs0n9F8qOZMvewJml+PxyLiSuDvgMV1BImItwJ/DfxOZr7c7uN1tBByjMtgRMSNwCeAD2c5CTZERy6DMVbOFh9jf/n4QkT8Lc2n9pUWQgU5a1/PiPjniJiTmQfL09kXRniMU+v5bEQ0aP5ENNGF0Mr6nBqzLyL6gPOAQxOca7j5T3lDxswcnOdrNF+36UY9cZmbwd94M3N9RPxpRMzKzI5e+C4izqJZBt/IzL8ZZsgZr2fXnDKKiCuA/wxclZmvjDCsJy6DERFviYi3ndqm+YJ5N165tRvWcw1wQ9m+AXjDM5uImBERU8v2LOADdOby6a2sz+D8nwQeHuGHmdoyDjlvfBXN883daA1wfXl3zKXA0UGnE7tGRLzj1OtEEbGc5vfRTv4QQJn/68COzPzyCMPOfD3rfKV8yCvie2ie79pSbqfeufFOYP2QV8530fzp8JYacv4izXNxrwL/DNw/NCfNd3w8WW5Pd2vOLlnPmcBDwG7gQeDt5fgy4Gtl+/3AtrKe24DPdDDfG9YH+BLNH1wApgH/o3z9PgYsqmENx8r4h+Xr8ElgA/DuTmcsOe4BDgKvla/NzwC/BfxWuT9o/mdaz5S/5xHfxVdzzpsGredG4P01ZPwgzdcptw76nnllu+vppSskSUAXnTKSJNXLQpAkARaCJKmwECRJgIUgSSosBEkSYCFIkor/BxtP8t5PxJz2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graficar_vectores([v1_B, v2_B, v1, v2], ['red','blue','purple','green'], 1)\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el signo negativo del determinante **está haciendo rotar a nuestro espacio**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPiv9zPYkOv/TkQILiye/UB",
   "collapsed_sections": [],
   "name": "Fundamentos_Algebra_Lineal_con_Python.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de contenidos 💜",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "439.667px",
    "left": "49px",
    "top": "162.567px",
    "width": "306px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
