{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Tabla de Contenidos 💜",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Python_para_Data_Scientist_Avanzado.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "kvzP1zUemWHl"
      },
      "source": [
        "<h1>Tabla de Contenidos 💜<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Python-para-data-scientist-avanzado\" data-toc-modified-id=\"Python-para-data-scientist-avanzado-1\">Python para data scientist avanzado</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Machine-Learning:-Modelación-avanzada\" data-toc-modified-id=\"1.-Machine-Learning:-Modelación-avanzada-1.1\">1. Machine Learning: Modelación avanzada</a></span><ul class=\"toc-item\"><li><span><a href=\"#Validación-interna-y-externa\" data-toc-modified-id=\"Validación-interna-y-externa-1.1.1\">Validación interna y externa</a></span></li><li><span><a href=\"#Validación-Externa-en-Python\" data-toc-modified-id=\"Validación-Externa-en-Python-1.1.2\">Validación Externa en Python</a></span></li><li><span><a href=\"#¿Qué-es-y-cómo-actúa-el-K-Fold?\" data-toc-modified-id=\"¿Qué-es-y-cómo-actúa-el-K-Fold?-1.1.3\">¿Qué es y cómo actúa el K-Fold?</a></span></li><li><span><a href=\"#Leave-One-Out\" data-toc-modified-id=\"Leave-One-Out-1.1.4\">Leave One Out</a></span></li><li><span><a href=\"#Redes-neuronales\" data-toc-modified-id=\"Redes-neuronales-1.1.5\">Redes neuronales</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conceptos\" data-toc-modified-id=\"Conceptos-1.1.5.1\">Conceptos</a></span></li><li><span><a href=\"#Ventajas\" data-toc-modified-id=\"Ventajas-1.1.5.2\">Ventajas</a></span></li><li><span><a href=\"#Desventajas\" data-toc-modified-id=\"Desventajas-1.1.5.3\">Desventajas</a></span></li></ul></li><li><span><a href=\"#Redes-neuronales-en-código\" data-toc-modified-id=\"Redes-neuronales-en-código-1.1.6\">Redes neuronales en código</a></span></li><li><span><a href=\"#XGboost-y-los-árboles-de-decisión\" data-toc-modified-id=\"XGboost-y-los-árboles-de-decisión-1.1.7\">XGboost y los árboles de decisión</a></span></li></ul></li></ul></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtpkHaJnmWHm"
      },
      "source": [
        "# Python para data scientist avanzado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQFEZMRfmWHn"
      },
      "source": [
        "## 1. Machine Learning: Modelación avanzada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3XBINu6mWHn"
      },
      "source": [
        "### Validación interna y externa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k97CBSzamWHo"
      },
      "source": [
        "Primero, hablemos sobre la validación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyLAx5wemWHo"
      },
      "source": [
        "* **Uso inteligente de los datos disponibles:** Es decir, no utilizar todos los datos de golpe y en lugar de ello, pensar en para qué los queremos utilizar y cómo podríamos interpretarlos en dicho caso también teniendo en cuenta el modelo que vamos a utilizar. Cuando utilizamos todos los datos para entrenar y evaluar al modelo estaremos en el caso de **validación interna** mientras que por el otro lado, cuando utilizamos sólo unos cuántos datos para entrenar y unos cuántos para evaluar entonces estamos en el caso de **validación externa**.\n",
        "\n",
        "* **Más allá de $R^2$ y el overfittin:** Es muy típico simplemente, querer maximizar el $R^2$ (coeficiente de determinación) de nuestros modelos utilizando todos nuestros datos. En casos particulares cómo en las *ciencias sociales* sí que nos interesaría encontrar el modelo con el $R^2$ más alto posible, olvidandonos totalmente del posible **overfitting**, pero en otro tipo de casos donde queremos *generalizar* el aprendizaje deberíamos de tener más cuidado con ello.\n",
        "\n",
        "* **Train / Test:** Es muy común partir nuestro conjunto de *datos en datos de entrenamiento* y *datos de pruebas*, normalmente los primeros ocupan un 80% de nuestro conjunto total y utilizamos el 20% restante para validar que tan bueno es nuestro modelo al realizar predicciones.\n",
        "\n",
        "* **Tiempo y potencial computacional:** Hay que tener en cuenta que esto suele llevar más tiempo y recursos, ya que podríamos requerir de varios procesos de entrenamientos a la vez que requeriríamos ir evaluando."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXcGqTLYmWHo"
      },
      "source": [
        "Hagamos una comparativa entre *validación interna* y *validación externa*:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kq89jZ6mWHp"
      },
      "source": [
        "![](https://i.imgur.com/DCE8egK.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrrjx63XmWHp"
      },
      "source": [
        "Normalmente, cuando nos referimos a la validación externa también hablamos de **validación cruzada**. Es decir, partir de una serie de bloque en donde entrenamos nuestro modelo y utilizamos el último para evaluarlo, para obtener un valor de $R^2$ y \"retroalimentar\" o volver a empezar.\n",
        "\n",
        "Pongamos un ejemplo para que sea más claro, supongamos que tenemos datos divididos en los siguientes 4 bloques:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvt90n8mmWHp"
      },
      "source": [
        "![](https://i.imgur.com/XP7Bcw9.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGN-QlU_mWHq"
      },
      "source": [
        "Podríamos comenzar por ejemplo, utilizando los bloques 1,2 y 3 para entrenar nuestro modelo y después testear con el bloque 4, recolectamos nuestro $R^2$ volvemos a empezar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tTQHwN-mWHq"
      },
      "source": [
        "![](https://i.imgur.com/fm5mF8O.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgpRFRmPmWHq"
      },
      "source": [
        "Ahora, partiendo de nuestro valor obtenido $R^2$ repetimos el proceso, pero cambiando de bloques. Digamos que ahora utilizaremos los bloques 1,2,4 para entrenar y el bloque 3 para testeo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktpJn5iSmWHr"
      },
      "source": [
        "![](https://i.imgur.com/ufenaR5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A10yZd4mWHr"
      },
      "source": [
        "y así podríamos continuar las veces que consideremos necesarias o hasta que utilicemos todas las combinaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu-5clfkmWHr"
      },
      "source": [
        "Entre los tipos de validación más utilizados en ML tenemos las siguientes:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnRvnANSmWHr"
      },
      "source": [
        "* **Interna:** Utilizar **todos los datos** para todo.\n",
        "\n",
        "* **Externa aleatoria:** Partir la base de datos en *train/test* **al azar** y posteriormente, evaluar nuestro modelo.\n",
        "\n",
        "* **Externa k-fold:** Partir la base de datos en *train/test* al azar y posteriormente, evaluar nuestro modelo. Esto realizado **múltiples veces** (cómo en las imágenes de arriba).\n",
        "\n",
        "* **Leave One Out:** Similar a k-fold, pero aquí **dejamos \"fuera\" del proceso a uno de nuestros puntos o bloques**. Y hacemos esto para todos los puntos de la base de datos. Esto es muy costoso, pero nos permite obtener una estimación muy precisa de que tan bien funciona nuestro modelo.\n",
        "\n",
        "* **Bootstrap:** Nos permite **obtener estimadores**. Llendo un poco más allá de los test clásicos, basándonos en un **re-muestreo con reemplazamiento**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpC9NdL6mWHr"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6KfZGjmmWHs"
      },
      "source": [
        "### Validación Externa en Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmfkt4vomWHs"
      },
      "source": [
        "Siempre que empezamos un proyecto de ML basado en la modelización de datos una de las primeras cosas en las que tenemos que pensar es en **cómo validar nuestros datos**. Para realizar esto utilizaremos la función `train_test_split` incluida en ScikitLearn. Ya conocemos esta funcionalidad en el notebook de [Fundamentos Prácticos de ML](https://github.com/abdielgv162/Data-Science-Machine-Learning-Notes/blob/master/Fundamentos_Practicos_de_Machine_Learning/Fundamentos_Practicos_de_Machine_Learning.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTFn_3_tmWHs"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M4ifDawmWHs"
      },
      "source": [
        "Vamos a cargar nuestros datos que descargamos de [Kaggle](https://www.kaggle.com/vikalpdongre/us-flights-data-2008?select=2008.csv)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vZweSYZmWHt"
      },
      "source": [
        "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuMKF62XmWHt"
      },
      "source": [
        "Vamos a visualizar nuestros datos con un DF:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF5eYulemWHt"
      },
      "source": [
        "DF = pd.DataFrame(data)\n",
        "DF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84-xNNvVmWHt"
      },
      "source": [
        "keys = DF.keys()\n",
        "print(sorted(keys))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-k6ONN6mWHt"
      },
      "source": [
        "utilizamos `dropna` para eliminar los valores faltantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIfQu4qRmWHt"
      },
      "source": [
        "# Esta será nuestra \"variable respuesta\"\n",
        "df = data.dropna(subset=[\"ArrDelay\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtoZdHvrmWHu"
      },
      "source": [
        "vamos a quedarnos solamente con 1000 filas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV5wsmsSmWHu"
      },
      "source": [
        "df = df.sample(frac=1).head(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsFKelVEmWHu"
      },
      "source": [
        "Vamos a escoger 3 \"variables regresoras\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3kMhVsvmWHu"
      },
      "source": [
        "X = df[['AirTime', 'Distance', 'DepDelay']]\n",
        "print(X.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKznxLBgmWHu"
      },
      "source": [
        "y nuestra variable respuesta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiX0H6Z5mWHu"
      },
      "source": [
        "Y = df['ArrDelay']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAT4PzPBmWHv"
      },
      "source": [
        "Ahora, vamos a dividir nuestros datos en **datos de entrenamiento** y **datos de pruebas**. Para ello utilizaremos la instrucción ` train_test_split()` y cómo argumentos le pasaremos a nuestras variables `X`, `Y` de arriba y la porción de los datos destinada al testeo, en este caso el 20%. El argumento `random_state` controlamos la selección aleatoria de los datos antes de la partición :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5pfeK7_mWHv"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYPHqo4imWHv"
      },
      "source": [
        "> Se suele utilizar mayúscula en la $X$ ya que son valores que permanecen fijos (constante) y minúscula en la $y$ ya que es nuestra variable a predecir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuWx2bK0mWHv"
      },
      "source": [
        "Vamos a crear 2 modelos de regresión lineal para estudiar un tipo de validación Interno y otro Externo. Hagamos primero la Interna:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1DQ0MOJmWHv"
      },
      "source": [
        "regrInterna = linear_model.LinearRegression() # Establecemos el modelo a usar\n",
        "regrInterna.fit(X, Y) # Entrenamos utilizando TODOS los datos\n",
        "prediccionesInterna = regrInterna.predict(X) # Devuelve las predicciones según todo X\n",
        "print(\"R2:\", r2_score(Y, prediccionesInterna)) # Devuelve R2 comparando los valores con la predicción"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL63yLI0mWHw"
      },
      "source": [
        "Ahora hagamos la Externa:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWPx8MpemWHw"
      },
      "source": [
        "regrExterna = linear_model.LinearRegression() \n",
        "regrExterna.fit(X_train, y_train) # Esntrenamos con los DATOS DE ENTRENAMIENTO\n",
        "prediccionesExterna = regrExterna.predict(X_test) # Realiza predicciones de los valores de testing\n",
        "print(\"R2: \", r2_score(y_test, prediccionesExterna)) # Devuelve R2 según las predicciones del test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7BD1CBZmWHw"
      },
      "source": [
        "Podemos ver que si bien, tenemos un \"mejor resultado\" en la **validación interna** también tenemos un overfitting más alto, ya que estamos prediciendo los datos con los que lo entrenamos. Mientras que en el caso de la **validación externa** tenemos un valor de $R^2$ más pequeño, pero a la vez tenemos una \"generalización\" más versátil de nuestros datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71WXLNo0mWHx"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruqdcxU6mWHx"
      },
      "source": [
        "### ¿Qué es y cómo actúa el K-Fold?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nwo14f-mWHx"
      },
      "source": [
        "En general, la validación externa es una buena manera de evaluar que tan bueno es nuestro modelo, pero en muchos casos es dependiente de qué selección concreta hayamos hecho en el conjunto `X_train` y `X_test`. Esto implica que, dependiendo que datos \"caigan\" en un grupo u otro; por lo que no siempre estaremos tan seguros de que tan buena haya sido la selección.\n",
        "\n",
        "Aquí propondremos utilizar **K-Fold**, el cuál prácticamente realizará el mismo procedimiento de ` train_test_split` **múltiples veces**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIdD1o7wmWHy"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I72JNl5FmWHy"
      },
      "source": [
        "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVRhc5-wmWHz"
      },
      "source": [
        "df = data.dropna(subset=[\"ArrDelay\"])\n",
        "df = df.sample(frac=1).head(5000)\n",
        "\n",
        "# Es importante resetear el índice de los datos cuando hacemos\n",
        "# selecciones aleatorias\n",
        "df = df.reset_index()\n",
        "\n",
        "X = df[['AirTime', 'Distance', 'DepDelay']]\n",
        "y = df['ArrDelay']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud18GdjFmWHz"
      },
      "source": [
        "La sintaxis es muy similar a la que utilizamos en el caso anterior. KFold nos permite elegir cuántas particiones queremos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWHzBu2YmWHz"
      },
      "source": [
        "# Aquí se vuelve importante tener los indices reseteados\n",
        "kf = KFold(n_splits=10, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFe33oQNmWHz"
      },
      "source": [
        "Obtenemos las particiones de nuestras variables X:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbZfMZ_NmWHz"
      },
      "source": [
        "kf.get_n_splits(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zj8Zh-7mWH0"
      },
      "source": [
        "Aplicamos una regresión lineal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhpEXZk0mWH0"
      },
      "source": [
        "reg = linear_model.LinearRegression()\n",
        "\n",
        "\n",
        "results = []\n",
        "\n",
        "# Por cada vez que repitamos la partición\n",
        "for train_index, test_index in kf.split(X):\n",
        "    \n",
        "    # Localizamos los datos que vamos a colocar en cada partición\n",
        "    X_train, X_test = X.loc[train_index], X.iloc[test_index,]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    \n",
        "    #Entrenamos\n",
        "    reg.fit(X_train, y_train)\n",
        "    # Testeamos\n",
        "    predictions = reg.predict(X_test)\n",
        "    print(\"R2: \", r2_score(y_test, predictions))\n",
        "    \n",
        "    # Guardamos\n",
        "    results.append(r2_score(y_test, predictions))\n",
        "    \n",
        "print(\"R2 promedio\", np.mean(results))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVQfYA8FmWH0"
      },
      "source": [
        "Aquí es más claro visualizar cómo dependiendo de la selección de nuestros datos de entrenamiento tendremos mejores o peores predicciones. En este caso con KFold tenemos el promedio de todos estos, manteniendo un valor de $R^2$ más alto que con el split anterior. \n",
        "\n",
        "Utilizar el promedio nos ayuda a compensar la dependencia de datos concretos, este es un tipo de validación más representativa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXby9o4rmWH0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7O_x91JmWH0"
      },
      "source": [
        "### Leave One Out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QC13nYDmWH1"
      },
      "source": [
        "Ahora vamos a hablar de otra forma de validación que si bien es más costosa computacionalmente (y en tiempo), es un tanto divertida e interesante. Lo que haremos será entrenar al modelo con todos los datos excepto 1, es decir, en nuestra línea de código `test_size` tendríamos $\\frac{1}{n}$. La particularidad de este proceso es que lo repetimos $n$ veces, de ahí la razón por la que sea tan costoso, pero es muy buena opción en caso de tener muestras muy pequeñas de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_RQhVGGmWH1"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn import linear_model\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO_0rgtBmWH1"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z19ZXYD9mWH1"
      },
      "source": [
        "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUuZLu40mWH1"
      },
      "source": [
        "df = data.dropna(subset = [\"ArrDelay\"])\n",
        "df = df.sample(frac=1).head(5000)\n",
        "\n",
        "df = df.reset_index()\n",
        "\n",
        "X = df[['AirTime', 'Distance', 'DepDelay']]\n",
        "y = df['ArrDelay']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NMYPcILmWH1"
      },
      "source": [
        "loo = LeaveOneOut()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lttSn9yUmWH2"
      },
      "source": [
        "reg = linear_model.LinearRegression()\n",
        "error_vector = []\n",
        "for train_index, test_index in loo.split(X):\n",
        "    \n",
        "    X_train, X_test = X.loc[train_index,], X.loc[test_index,]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    reg.fit(X_train, y_train)\n",
        "    predictions = reg.predict(X_test)\n",
        "    \n",
        "    error_vector.append( int((y_test - predictions[0])**2 ) ) \n",
        "    print('Error Cuadratico: ', ( (y_test - predictions[0])**2 ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_GWeYhamWH2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFYg_fnMmWH2"
      },
      "source": [
        "### Redes neuronales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9fCTXZDmWH2"
      },
      "source": [
        "Las redes neuronales son uno de los modelos más populares hoy en día, su funcionamiento se basa en tratar de replicar los procesos cognitivos de un cerebro humano; partiendo desde conceptos como neuronas artificiales, funciones de activación hasta tener redes súper complejas cada vez más profundas. Son muy costosas computacionalmente, pero también son muy buenas al aproximar todo tipo de estructuras internas dentro de nuestros datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJlvdhxumWH3"
      },
      "source": [
        "![](https://i.imgur.com/p6d6Fjw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hcFZUEymWH3"
      },
      "source": [
        "En la imagen de arriba cada bolita representa una neurona y tenemos dividido al modelo en distintas capas. En nuestra primera capa tenemos nuestros inputs (datos), o variables regresoras. Después, tenemos capas ocultas que representan ***combinaciones lineales** o pesos de los inputs y de otras capas oculats. Finalmente, tenemos nuestros valores de salida o outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rW8nr0YmWH3"
      },
      "source": [
        "#### Conceptos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCKw6BfDmWH3"
      },
      "source": [
        "* **Neuronas:** Son cada uno de los elementos individuales informativos que generamos al intentar relacionar y explicar nuestros outputs a través de nuestros inputs.\n",
        "* **Enlaces:** Son las combinaciones lineales entre los elementos de la red.\n",
        "* **Función de pérdida:** Función matemática que relaciona un evento o tarea con un número que representa el coste de realizarla.\n",
        "* **Aprendizaje automático:** Cuando desarrollamos algoritmos y modelos que pueden \"aprender\" a realizar una tarea sin necesidad de ser implícitamente programados para ello. En general, se basan en iterar distintos procesos hasta minimizar una función de pérdida.\n",
        "* **Función de activación:** Función matemática que describe cómo se \"encienden\" o activan nuestras neuronas o elementos de nuestra red.\n",
        "* **Tipo de aprendizaje:** Supervisado, no supervisado o reforzado.\n",
        "* **Coste:** Coste computacional en función de la cantidad de datos y la profundidad o cantidad de capas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t1QJP3PmWH3"
      },
      "source": [
        "#### Ventajas         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWYufFgemWH3"
      },
      "source": [
        "* **Adaptativas:** Funcionan para todo tipo de distribución de datos, lineales o no lineales.\n",
        "* **Paralelizables:** Podemos distribuir el cálculo en distintos computadores o servidores.\n",
        "* **Tolerancia a fallos**: Si alguna parte del modelo falla o pierde algo de información, podemos repararlo sin haber perdido todo lo que hemos hecho.\n",
        "* **Potencial predictivo:** Son muy buenas generalizando los patrones en los, siempre y cuando estén bien calibradas y construidas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AgDShkemWH4"
      },
      "source": [
        "#### Desventajas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5P-dDXgmWH4"
      },
      "source": [
        "* **Coste computacional**: Por lo mismo de la profundidad a la que pueden llegar, requieren de gran poder de cómputo.\n",
        "* **Cajas negras:** En realidad no sabemos exactamente que es lo que pasa dentro del modelo, solo podemos entenderlo al nivel de sus capas más simples, el resto es gracias a la conexión y trabajo conjunto de ellas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9zBMnJvmWH4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnAkD0-VmWH4"
      },
      "source": [
        "### Redes neuronales en código"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYgLg-mkmWH4"
      },
      "source": [
        "Vamos a utilizar ScikitLearn para ver cómo podríamos ajustar redes neuronales. Utilizamos `MLPClassifier` al trabajar con datos categóricos y `MLPRegressor` con datos numéricos; después importamos a `StandardScaler` escalar nuestros datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FAjE62BmWH4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split # Validación externa\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTHGXPnLmWH4"
      },
      "source": [
        "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yNf5L2UmWH5"
      },
      "source": [
        "df = data.dropna(subset = ['AirTime','Distance','TaxiIn', 'TaxiOut', 'DepDelay'])\n",
        "df = df.sample(frac=1).head(1000)\n",
        "\n",
        "\n",
        "X = df[['AirTime','Distance','TaxiIn', 'TaxiOut', 'DepDelay']]\n",
        "Y = df['ArrDelay']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nSzTd77mWH5"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TreL7aSKmWH5"
      },
      "source": [
        "Vamos a dividir los datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwL9KSFZmWH5"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reA7MF8KmWH5"
      },
      "source": [
        "Recordemos que tenemos datos que miden cosas distintas, algunas columnas miden tiempo, otras distancia, etc. Así que vamos a estandarizar nuestros valores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIcIK6crmWH5"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh4yAT_VmWH6"
      },
      "source": [
        "Lo que hace es estandarizar las características eliminando la media y escalando a la varianza de la unidad. La puntuación estándar de una muestra $x$ se calcula cómo:\n",
        "\n",
        "$$ z = \\frac{(x-u)}{s}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBcjuOnGmWH6"
      },
      "source": [
        "donde $u$ es la media de nuestras muestras, $s$ es la desviación estándar de las muestras y $x$ nuestras muestras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiGOqoBTmWH6"
      },
      "source": [
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGpJJOxqmWH6"
      },
      "source": [
        "Ahora, vamos a ajustar a la red neuronal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X8XzIzKmWH6"
      },
      "source": [
        "clf = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, ))\n",
        "\n",
        "model = clf.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print('R2: ', r2_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN8zLgLbmWH6"
      },
      "source": [
        "Podemos ver que tenemos un $R^2$ muy alto, pero recordemos que tenemos la variable ` 'DepDelay'` tanto en $X$ cómo en $Y$, por lo que esperaríamos que estén muy correlacionados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdRiDolgmWH7"
      },
      "source": [
        "Hay algunos parámetros que podemos modificar para adaptar este tipo de modelos:\n",
        "\n",
        "* **`solver`:** Indica a nuestra función cómo resolver el problema de optimización.\n",
        "    * `lbfgs`: es un optimizador de la familia de métodos cuasi-Newton.\n",
        "    * `sgd`: se refiere a un descenso del gradiente estocástico.\n",
        "    * `adam`:  se refiere a un optimizador estocástico basado en gradientes propuesto por Kingma, Diederik y Jimmy Ba.\n",
        "\n",
        "\n",
        "* **`alpha`:** Penalización a la complejidad del modelo, nos ayuda a controlar el **overfitting**.\n",
        "\n",
        "\n",
        "* **`hidden_layer_sizes`:** Número de capas ocultas en las que trabajamos, esto depende muchísimo de los datos que estemos utilizando. NO siempre es mejor tener más capas.\n",
        "    * Primero recibe el número de capas.\n",
        "    * Después de la coma recibe el número de neuronas (generalmente se mantiene vacío).\n",
        "\n",
        "\n",
        "* **`activation`:** Indica cuál es la función de activación que utilizaremos.\n",
        "    * `identity`: activación sin operación, útil para implementar cuellos de botella lineales, devuelve $f(x) = x$.\n",
        "\n",
        "    * `logistic`: la función sigmoidea logística, devuelve $f (x) =\\frac{1}{ (1 + exp (-x))}$.\n",
        "\n",
        "    * `tanh`:  la función tan hiperbólica, devuelve $f (x) = tanh (x)$.\n",
        "\n",
        "    * `relu`: la función de unidad lineal rectificada, devuelve $f (x) = max (0, x)$.\n",
        "    \n",
        "    \n",
        "* **`learning_rate`**: Velocidad de aprendizaje de nuestra red. \n",
        "    * `constant`: es una tasa de aprendizaje constante dada por `learning_rate_init`. Este es el valor predeterminado.\n",
        "    * `invscaling`: disminuye gradualmente la tasa de aprendizaje `learning_rate_` en cada paso de tiempo $t$ utilizando un exponente de escala inversa de `power_t` . `effective_learning_rate = learning_rate_init / pow(t, power_t)`.\n",
        "    * `adaptive`: mantiene la tasa de aprendizaje constante en `learning_rate_init` siempre que la pérdida de entrenamiento siga disminuyendo.\n",
        "    \n",
        "\n",
        "* `max_iter`: Número máximo de iteraciones.\n",
        "\n",
        "\n",
        "* `warm_start`: El modelo comienza desde la solución de la última vez que la hemos ejecutado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz6QgufLmWH7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ53XbmcmWH7"
      },
      "source": [
        "### XGboost y los árboles de decisión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dUxGQuzmWH7"
      },
      "source": [
        "XGboost es una \"evolución\" de los árboles de clasificación. Se podría decir que estamos mezclando varios árboles y evaluando que tan bueno es el modelo. \n",
        "\n",
        "El elemento clave de esto es nuestra función de pérdida, comúnmente utilizando la media de los errores al cuadrado junto con una **penalización de complejidad**, es decir, vamos a penalizar los modelos que sean muy complejos; esto último es lo que nos permite evitar el **overfitting**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr-DB39TmWH7"
      },
      "source": [
        "![](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/cart.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-6_pnLzmWH7"
      },
      "source": [
        "a diferencia de los árboles normales, en este caso asigna **valores reales** a nuestros posibles eventos, de manera que podríamos generar una métrica que vamos a poder añadir a nuevos árboles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6JGThzhmWH8"
      },
      "source": [
        "![](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/twocart.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw__LVsJmWH8"
      },
      "source": [
        "de forma que la predicción de nuestros eventos estará en función de los distintos árboles que utilicemos. De forma que al final obtenemos una estructura como la siguiente:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5rnlabGmWH8"
      },
      "source": [
        "![](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/struct_score.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AU98xOYmWH8"
      },
      "source": [
        "estaríamos **acumulando los valores** de nuestros eventos o en este caso, de nuestros individuos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyc5vywSmWH8"
      },
      "source": [
        "[Documentación de XGboost ](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq5SahpvmWH8"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa58cEcbnU83"
      },
      "source": [
        "Ya que el paquete XGboost suele dar problemas, de aquí en adelante estaré utilizando colab para no instalarlo; por lo que las llamadas de los archivos se veran distintas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB7yvoGtmWH9"
      },
      "source": [
        "### KGboost en Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23Dw7lnDm0hj"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WISf0eUm2rK"
      },
      "source": [
        "from xgboost import XGBRegressor #pip install xgboost\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOMUujSonKJ3"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/DataSets/2008.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6bU5SA7nR5u"
      },
      "source": [
        "df = data.dropna(subset=['ArrDelay'])\n",
        "df = df.sample(frac=1).head(10000)\n",
        "\n",
        "X = df[[\"AirTime\", \"Distance\", \"TaxiIn\", \"TaxiOut\", \"DepDelay\"]]\n",
        "Y = df[\"ArrDelay\"]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx6YsJVWnwTi"
      },
      "source": [
        "podríamos utilizar variables categóricas y convertirlas en dummies de la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfqMmRTeoLGe"
      },
      "source": [
        "#df['Month'] = df['Month'].apply(str)\n",
        "#df['DayofMonth'] = df['DayofMonth'].apply(str)\n",
        "#df['DayOfWeek'] = df['DayOfWeek'].apply(str)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj9iIwQAoXRX"
      },
      "source": [
        "#dummies = pd.get_dummies(data= df[['Month', 'DayofMonth', 'DayOfWeek', 'Origin', 'Dest']])\n",
        "#X = dummies.add(X, fill_value=0)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxi29534ozUd"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyMXMuIGpF83"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg_17vSPpQa-"
      },
      "source": [
        "Ahora, vamos a llamar al modelo XGboost:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhlxb_fZpjhI"
      },
      "source": [
        "model = XGBRegressor(n_jobs=-1, learning_rate=.5, max_depth=2,\n",
        "                     colsample_bytree=1, verbosity=2, subsample=1, n_stimators=500)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq4_bqzyqSsz"
      },
      "source": [
        "* `n_jobs`: Nos permite paralelizar el procedimiento. En este caso asignamos todos los procesadores excepto 1.\n",
        "* `learning_rate`: Velocidad a la que aprende el modelo.\n",
        "* `max_depth`: Profundidad máxima de los árboles.\n",
        "* `colsample_bytree`: Qué porcentaje de columnas queremos utilizar para lso árboles. En este caso, usamos todos.\n",
        "* `verbosity`: Aquí le decimos si queremos que nos muestre los resultados, dependiendo el valor nos da cierta información extra.\n",
        "* `subsample`: Cuántas filas tomamos para los árboles.\n",
        "* `n_stimators`: Número de árboles que queremos.\n",
        "\n",
        "Aún hay más parámetros que podríamos modificar, para más detalles tenemos la documentación oficial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDR_GTlzp2DD"
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HT9JHLep4rx",
        "outputId": "2e3d4945-9cfa-4479-88e6-7844d650a313"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "print('R2: ', r2_score(y_test, predictions))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2:  0.9371116163116314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J16T5BJrlMx"
      },
      "source": [
        "Como vemos es un modelo con el que podemos obtener muy buenos resultados, el único inconveniente es que tendremos que moficiar muchos parámetros hasta dar con la versión más óptima para nuestros datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMhfBPUFqMih"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcbEmUUdrjNM"
      },
      "source": [
        "## 2. Funciones clave en Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWPYrNxNtT5r"
      },
      "source": [
        "### Seleccionar variables en Machine Learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkq2uGTktZNZ"
      },
      "source": [
        "Cuando estamos creando modelos para bases de datos con muchas columnas (variables), puede que queramos omitir cierta cantidad de ellas dependiendo del problema que estemos haciendo, ya que algunas de ellas no serían relevantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQGz8li9trI_"
      },
      "source": [
        "from sklearn import linear_model\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-M1WpwWtw0H"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/DataSets/2008.csv')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPMWERSnt-VG",
        "outputId": "f5dddf56-266d-453b-f166-8fec385a9444"
      },
      "source": [
        "print(sorted(data.keys()))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ActualElapsedTime', 'AirTime', 'ArrDelay', 'ArrTime', 'CRSArrTime', 'CRSDepTime', 'CRSElapsedTime', 'CancellationCode', 'Cancelled', 'CarrierDelay', 'DayOfWeek', 'DayofMonth', 'DepDelay', 'DepTime', 'Dest', 'Distance', 'Diverted', 'FlightNum', 'LateAircraftDelay', 'Month', 'NASDelay', 'Origin', 'SecurityDelay', 'TailNum', 'TaxiIn', 'TaxiOut', 'UniqueCarrier', 'WeatherDelay', 'Year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09xFW1wmt5kY"
      },
      "source": [
        "df = data.dropna(subset = ['AirTime', 'Distance', 'TaxiIn', 'TaxiOut', 'DayOfWeek', 'DayofMonth', 'Month', 'DepDelay', 'WeatherDelay'])\n",
        "df = df.sample(frac = 1).head(1000)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvE0gmcFudEt"
      },
      "source": [
        "X = df[ ['AirTime', 'Distance', 'TaxiIn', 'TaxiOut', 'DayOfWeek', 'DayofMonth', 'Month', 'DepDelay', 'WeatherDelay']]\n",
        "Y = df['ArrDelay']"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rg8TZF-u4UA"
      },
      "source": [
        "Usemos un modelo de regresión lineal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eurf9IvXutEH"
      },
      "source": [
        "regression = linear_model.LinearRegression()\n",
        "regression.fit(X,Y)\n",
        "predictions = regression.predict(X)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTREIYrow6bh",
        "outputId": "69f8479d-c1e7-4e88-b445-9661e64f9ec8"
      },
      "source": [
        "print('R2: ', r2_score(Y, predictions))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2:  0.9694363013700205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXuRv2UCu2Fz"
      },
      "source": [
        "Para saber cuales de estas variables realmente son representativas (teóricamente) haremos un análisis estadístico. Utilizaremos las siguientes instrucciones para hacer que Python nos muestre datos similares a los que esperaríamos al utilizar R. Esto lo lograremos con el paquete `statsmodels.api`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBuFfhBevNrO",
        "outputId": "2fd136a4-77cc-4b57-cb85-34afbbf25d7f"
      },
      "source": [
        "# Test estadistico\n",
        "X2 = sm.add_constant(X)\n",
        "est = sm.OLS(Y, X2)\n",
        "est2 = est.fit()\n",
        "print(est2.summary())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:               ArrDelay   R-squared:                       0.969\n",
            "Model:                            OLS   Adj. R-squared:                  0.969\n",
            "Method:                 Least Squares   F-statistic:                     3489.\n",
            "Date:                Fri, 02 Jul 2021   Prob (F-statistic):               0.00\n",
            "Time:                        01:03:31   Log-Likelihood:                -3719.5\n",
            "No. Observations:                1000   AIC:                             7459.\n",
            "Df Residuals:                     990   BIC:                             7508.\n",
            "Df Model:                           9                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "================================================================================\n",
            "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "const          -21.6959      1.326    -16.362      0.000     -24.298     -19.094\n",
            "AirTime          0.4308      0.021     20.521      0.000       0.390       0.472\n",
            "Distance        -0.0521      0.003    -19.957      0.000      -0.057      -0.047\n",
            "TaxiIn           0.7445      0.048     15.492      0.000       0.650       0.839\n",
            "TaxiOut          0.8153      0.015     54.168      0.000       0.786       0.845\n",
            "DayOfWeek       -0.0134      0.159     -0.084      0.933      -0.326       0.299\n",
            "DayofMonth      -0.0278      0.037     -0.760      0.447      -0.100       0.044\n",
            "Month           -0.0958      0.090     -1.069      0.285      -0.272       0.080\n",
            "DepDelay         0.9556      0.006    167.401      0.000       0.944       0.967\n",
            "WeatherDelay     0.0354      0.016      2.163      0.031       0.003       0.068\n",
            "==============================================================================\n",
            "Omnibus:                       59.658   Durbin-Watson:                   1.934\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              229.226\n",
            "Skew:                           0.063   Prob(JB):                     1.68e-50\n",
            "Kurtosis:                       5.342   Cond. No.                     4.14e+03\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 4.14e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e6TDYENvkIE"
      },
      "source": [
        "Particularmente nos interesa la columna ` P>|t|`, aquí tenemos la probabilidad de que cada una de las variables sea relevante o no en nuestro modelo. Es decir, que tan relevante podría ser al generar cambios significativos en nuestros resultados. \n",
        "\n",
        "En este caso decimos que es significativo cuando el valor es próximo a 0, diríamos que `DayOfWeek` es la menos relevante. Si el valor está por encima de $0.5$ decimos que no es relevante para el modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkk7wfMwv980"
      },
      "source": [
        "Vamos a probar nuestro modelo omitiendo las variables que no son tan relevantes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqzCw2cdxGZ2"
      },
      "source": [
        "df = data.dropna(subset = ['AirTime', 'Distance', 'TaxiIn', 'TaxiOut', 'DayofMonth', 'Month', 'DepDelay', 'WeatherDelay'])\n",
        "df = df.sample(frac = 1).head(1000)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilr9l3FVxJmD"
      },
      "source": [
        "X = df[ ['AirTime', 'Distance', 'TaxiIn', 'TaxiOut', 'DayofMonth', 'Month', 'DepDelay', 'WeatherDelay']]\n",
        "Y = df['ArrDelay']"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYNnGw0QxMRY"
      },
      "source": [
        "regression = linear_model.LinearRegression()\n",
        "regression.fit(X,Y)\n",
        "predictions = regression.predict(X)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUXsDQ0YxObf",
        "outputId": "ef95485b-8025-4105-a4c9-1585c382f4e0"
      },
      "source": [
        "print('R2: ', r2_score(Y, predictions))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2:  0.9538875382623997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMAOP4w7xQRy"
      },
      "source": [
        "Podríamos obtener un score menor, pero al trabajar con menos variables el modelo es menos costoso computacionalmente, nos ahorra tiempo y realmente no tendríamos un cambio tan significativo.\n",
        "\n",
        "Podríamos repetir el procedimiento varías veces para quitarnos de encima las variables que no son necesarias y ahorrarnos costes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k1GwYE7xa55",
        "outputId": "2ef80d7d-e047-4180-8e19-f39799d9b7cc"
      },
      "source": [
        "# Test estadistico\n",
        "X2 = sm.add_constant(X)\n",
        "est = sm.OLS(Y, X2)\n",
        "est2 = est.fit()\n",
        "print(est2.summary())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:               ArrDelay   R-squared:                       0.954\n",
            "Model:                            OLS   Adj. R-squared:                  0.954\n",
            "Method:                 Least Squares   F-statistic:                     2562.\n",
            "Date:                Fri, 02 Jul 2021   Prob (F-statistic):               0.00\n",
            "Time:                        01:12:49   Log-Likelihood:                -3800.0\n",
            "No. Observations:                1000   AIC:                             7618.\n",
            "Df Residuals:                     991   BIC:                             7662.\n",
            "Df Model:                           8                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "================================================================================\n",
            "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "const          -23.4468      1.293    -18.131      0.000     -25.984     -20.909\n",
            "AirTime          0.4791      0.023     21.158      0.000       0.435       0.523\n",
            "Distance        -0.0585      0.003    -20.846      0.000      -0.064      -0.053\n",
            "TaxiIn           0.8351      0.050     16.568      0.000       0.736       0.934\n",
            "TaxiOut          0.7655      0.021     36.836      0.000       0.725       0.806\n",
            "DayofMonth      -0.0112      0.039     -0.289      0.772      -0.087       0.065\n",
            "Month            0.1094      0.097      1.124      0.261      -0.082       0.300\n",
            "DepDelay         0.9574      0.007    131.517      0.000       0.943       0.972\n",
            "WeatherDelay     0.0271      0.016      1.649      0.100      -0.005       0.059\n",
            "==============================================================================\n",
            "Omnibus:                       86.675   Durbin-Watson:                   1.932\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              412.812\n",
            "Skew:                          -0.224   Prob(JB):                     2.29e-90\n",
            "Kurtosis:                       6.115   Cond. No.                     3.73e+03\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 3.73e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQGsr2kjxsc5"
      },
      "source": [
        "Por ejemplo, ahora podríamos extraer la variable `DayofMonth`. Aunque es importante aclarar que aquí esta marcandonos estas variables como **menos significativas** dado que no las estamos tratando adecuadamente, las estamos utilizando de fomra numérica cuando tendríamos que trabajarla más de en forma de `dummies` (como factores).\n",
        "\n",
        "¿Podríamos automatizar este proceso?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgvdGy7qxx1V"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky9Hu1_37dPn"
      },
      "source": [
        "### Selección automatizada de variables en ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gImgjOPj7g0e"
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn import linear_model\n",
        "import pandas as pd"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnVkNB0M7nSN"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/DataSets/2008.csv')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZhk9C947rOw"
      },
      "source": [
        "Para realizar nuestra selección automatizada de variables utilizaremos `.feature_selection.RFE` (eliminación de características recursivas) el cual tiene el objetivo de seleccionar las características considerando recursivamente conjuntos de características cada vez más pequeños. \n",
        "\n",
        "Primero, el estimador se entrena en el conjunto inicial de características y la importancia de cada una se obtiene a través de cualquier atributo específico o invocable. Luego, las características menos importantes se eliminan del conjunto actual. Repetimos ese proceso recursivamente hasta que se obtiene el número deseado de características para seleccionar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwL_XBTA9XX4"
      },
      "source": [
        "Vamos a partir de las siguientes variables elegidas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zty_AtGX8V0O"
      },
      "source": [
        "df = data.dropna(subset = ['AirTime', 'Distance', 'TaxiIn', 'TaxiOut', 'DayOfWeek', 'DayofMonth', 'Month','DepDelay', 'WeatherDelay'])\n",
        "df = df.sample(frac = 1).head(1000)\n",
        "\n",
        "X = df[ ['AirTime', 'Distance', 'TaxiIn', 'TaxiOut', 'DayOfWeek', 'DayofMonth', 'Month','DepDelay', 'WeatherDelay']]\n",
        "Y = df['ArrDelay']\n",
        "\n",
        "regression = linear_model.LinearRegression()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDHqqAZR-md2"
      },
      "source": [
        "Llamamos al RFE, pasandole nuestra regresión y diciendole que queremos 4 variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUZ30SYL9UVL",
        "outputId": "2c76a48f-4166-4b95-afd6-e24cd7fc5eaa"
      },
      "source": [
        "selector = RFE(estimator=regression, n_features_to_select=4)\n",
        "selector.fit(X, Y)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
              "                               normalize=False),\n",
              "    n_features_to_select=4, step=1, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXipaOcK-0bF"
      },
      "source": [
        "Vamos a ver con que variables nos hemos quedado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkIaFzsO-iZW",
        "outputId": "692f3b6d-31ac-45dd-999b-251b669994e3"
      },
      "source": [
        "print(selector.ranking_)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 5 1 1 1 6 2 1 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZF_q0f8-zFq"
      },
      "source": [
        "Si sabemos a priori cuál o cuales son las variables más corelacionadas podríamos verificar si esto funcionó correctamente. En este caso, si o si, tendríamos que quedarnos con `DepDelay` ya que es la que está más relatcionada con `ArrDelay` (retraso de salida con retraso de llegada)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10vBSx6S_Lem",
        "outputId": "fc6ac747-f75f-4f6e-de2f-7c487c1280e2"
      },
      "source": [
        "X.columns[selector.support_]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TaxiIn', 'TaxiOut', 'DayOfWeek', 'DepDelay'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkUIk2O5_bx_"
      },
      "source": [
        "Haciendo la prueba con 1 sola variable tendríamos que obtener `DepDelay`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je42z_bX_snO",
        "outputId": "5fa74369-f4ba-4110-d30a-a18d58f8e0fa"
      },
      "source": [
        "selector = RFE(estimator=regression, n_features_to_select=1)\n",
        "selector.fit(X, Y)\n",
        "print(selector.ranking_)\n",
        "X.columns[selector.support_]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 8 3 2 4 9 5 1 6]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['DepDelay'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZEXScp0_zGT"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5luk2l1VB-WN"
      },
      "source": [
        "### Selección de parámetros en ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trgVn876CB86"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "import pandas as pd"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpE7Imy2CSWT"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/DataSets/2008.csv')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpXnu-HjCbah"
      },
      "source": [
        "Ahora, vamos a crear un modelo para seleccionar nuestros parámetros que sea aplicable a cualquier modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBdYUw-gCjxQ"
      },
      "source": [
        "df = data.dropna(subset=['AirTime', 'Distance','TaxiIn', 'TaxiOut', 'DepDelay'])\n",
        "df = df.sample(frac=1).head(1000)\n",
        "X = df[ ['AirTime', 'Distance','TaxiIn', 'TaxiOut', 'DepDelay'] ]\n",
        "Y = df['ArrDelay']\n",
        "\n",
        "# Separando datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = .2, random_state = 1)\n",
        "\n",
        "# Estandarizamos\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train) # Notemos que siempre utilizamos el train, NO introducir X o habría overfitting\n",
        "\n",
        "# Reasginamos a los valores de entrenamiento y test\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4lBfm0WE3FD"
      },
      "source": [
        "Vamos a generar 3 listas de 3 parámetros que queremos estudiar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHov86e4C4DO"
      },
      "source": [
        "alphas = [0.000001, 0.0001, 0.01, 0.1] # Penalización de complejidad\n",
        "layers = [2, 5, 10, 50, 100] # Núm de capas ocultas\n",
        "solvers = ['lbfgs', 'adam'] # Optimizadores"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfzzhI3RFf9f"
      },
      "source": [
        "Vamos a ver cuántas combinaciones tendríamos con las selecciones de esos 3 parámetros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vba0EFBYE14H",
        "outputId": "152362cc-d077-4e8f-da1e-e8bfa75c7734"
      },
      "source": [
        "print(len(alphas)*len(layers)*len(solvers), 'Combinaciones posibles')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40 Combinaciones posibles\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZKxQPb3Fxbb"
      },
      "source": [
        "Esto nos da una idea de cuánto podríamos tardar en evaluar cada caso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "376-1w-bF2zv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}