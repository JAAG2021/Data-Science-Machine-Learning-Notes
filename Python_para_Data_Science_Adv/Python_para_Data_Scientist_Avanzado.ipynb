{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos 💜<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Python-para-data-scientist-avanzado\" data-toc-modified-id=\"Python-para-data-scientist-avanzado-1\">Python para data scientist avanzado</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Machine-Learning:-Modelación-avanzada\" data-toc-modified-id=\"1.-Machine-Learning:-Modelación-avanzada-1.1\">1. Machine Learning: Modelación avanzada</a></span><ul class=\"toc-item\"><li><span><a href=\"#Validación-interna-y-externa\" data-toc-modified-id=\"Validación-interna-y-externa-1.1.1\">Validación interna y externa</a></span></li><li><span><a href=\"#Validación-Externa-en-Python\" data-toc-modified-id=\"Validación-Externa-en-Python-1.1.2\">Validación Externa en Python</a></span></li><li><span><a href=\"#¿Qué-es-y-cómo-actúa-el-K-Fold?\" data-toc-modified-id=\"¿Qué-es-y-cómo-actúa-el-K-Fold?-1.1.3\">¿Qué es y cómo actúa el K-Fold?</a></span></li><li><span><a href=\"#Leave-One-Out\" data-toc-modified-id=\"Leave-One-Out-1.1.4\">Leave One Out</a></span></li><li><span><a href=\"#Redes-neuronales\" data-toc-modified-id=\"Redes-neuronales-1.1.5\">Redes neuronales</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conceptos\" data-toc-modified-id=\"Conceptos-1.1.5.1\">Conceptos</a></span></li><li><span><a href=\"#Ventajas\" data-toc-modified-id=\"Ventajas-1.1.5.2\">Ventajas</a></span></li><li><span><a href=\"#Desventajas\" data-toc-modified-id=\"Desventajas-1.1.5.3\">Desventajas</a></span></li></ul></li><li><span><a href=\"#Redes-neuronales-en-código\" data-toc-modified-id=\"Redes-neuronales-en-código-1.1.6\">Redes neuronales en código</a></span></li><li><span><a href=\"#XGboost-y-los-árboles-de-decisión\" data-toc-modified-id=\"XGboost-y-los-árboles-de-decisión-1.1.7\">XGboost y los árboles de decisión</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python para data scientist avanzado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Machine Learning: Modelación avanzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación interna y externa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, hablemos sobre la validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Uso inteligente de los datos disponibles:** Es decir, no utilizar todos los datos de golpe y en lugar de ello, pensar en para qué los queremos utilizar y cómo podríamos interpretarlos en dicho caso también teniendo en cuenta el modelo que vamos a utilizar. Cuando utilizamos todos los datos para entrenar y evaluar al modelo estaremos en el caso de **validación interna** mientras que por el otro lado, cuando utilizamos sólo unos cuántos datos para entrenar y unos cuántos para evaluar entonces estamos en el caso de **validación externa**.\n",
    "\n",
    "* **Más allá de $R^2$ y el overfittin:** Es muy típico simplemente, querer maximizar el $R^2$ (coeficiente de determinación) de nuestros modelos utilizando todos nuestros datos. En casos particulares cómo en las *ciencias sociales* sí que nos interesaría encontrar el modelo con el $R^2$ más alto posible, olvidandonos totalmente del posible **overfitting**, pero en otro tipo de casos donde queremos *generalizar* el aprendizaje deberíamos de tener más cuidado con ello.\n",
    "\n",
    "* **Train / Test:** Es muy común partir nuestro conjunto de *datos en datos de entrenamiento* y *datos de pruebas*, normalmente los primeros ocupan un 80% de nuestro conjunto total y utilizamos el 20% restante para validar que tan bueno es nuestro modelo al realizar predicciones.\n",
    "\n",
    "* **Tiempo y potencial computacional:** Hay que tener en cuenta que esto suele llevar más tiempo y recursos, ya que podríamos requerir de varios procesos de entrenamientos a la vez que requeriríamos ir evaluando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos una comparativa entre *validación interna* y *validación externa*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/DCE8egK.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente, cuando nos referimos a la validación externa también hablamos de **validación cruzada**. Es decir, partir de una serie de bloque en donde entrenamos nuestro modelo y utilizamos el último para evaluarlo, para obtener un valor de $R^2$ y \"retroalimentar\" o volver a empezar.\n",
    "\n",
    "Pongamos un ejemplo para que sea más claro, supongamos que tenemos datos divididos en los siguientes 4 bloques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/XP7Bcw9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podríamos comenzar por ejemplo, utilizando los bloques 1,2 y 3 para entrenar nuestro modelo y después testear con el bloque 4, recolectamos nuestro $R^2$ volvemos a empezar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/fm5mF8O.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, partiendo de nuestro valor obtenido $R^2$ repetimos el proceso, pero cambiando de bloques. Digamos que ahora utilizaremos los bloques 1,2,4 para entrenar y el bloque 3 para testeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/ufenaR5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y así podríamos continuar las veces que consideremos necesarias o hasta que utilicemos todas las combinaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre los tipos de validación más utilizados en ML tenemos las siguientes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Interna:** Utilizar **todos los datos** para todo.\n",
    "\n",
    "* **Externa aleatoria:** Partir la base de datos en *train/test* **al azar** y posteriormente, evaluar nuestro modelo.\n",
    "\n",
    "* **Externa k-fold:** Partir la base de datos en *train/test* al azar y posteriormente, evaluar nuestro modelo. Esto realizado **múltiples veces** (cómo en las imágenes de arriba).\n",
    "\n",
    "* **Leave One Out:** Similar a k-fold, pero aquí **dejamos \"fuera\" del proceso a uno de nuestros puntos o bloques**. Y hacemos esto para todos los puntos de la base de datos. Esto es muy costoso, pero nos permite obtener una estimación muy precisa de que tan bien funciona nuestro modelo.\n",
    "\n",
    "* **Bootstrap:** Nos permite **obtener estimadores**. Llendo un poco más allá de los test clásicos, basándonos en un **re-muestreo con reemplazamiento**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Externa en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre que empezamos un proyecto de ML basado en la modelización de datos una de las primeras cosas en las que tenemos que pensar es en **cómo validar nuestros datos**. Para realizar esto utilizaremos la función `train_test_split` incluida en ScikitLearn. Ya conocemos esta funcionalidad en el notebook de [Fundamentos Prácticos de ML](https://github.com/abdielgv162/Data-Science-Machine-Learning-Notes/blob/master/Fundamentos_Practicos_de_Machine_Learning/Fundamentos_Practicos_de_Machine_Learning.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a cargar nuestros datos que descargamos de [Kaggle](https://www.kaggle.com/vikalpdongre/us-flights-data-2008?select=2008.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a visualizar nuestros datos con un DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.DataFrame(data)\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = DF.keys()\n",
    "print(sorted(keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilizamos `dropna` para eliminar los valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta será nuestra \"variable respuesta\"\n",
    "df = data.dropna(subset=[\"ArrDelay\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos a quedarnos solamente con 1000 filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a escoger 3 \"variables regresoras\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['AirTime', 'Distance', 'DepDelay']]\n",
    "print(X.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y nuestra variable respuesta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['ArrDelay']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a dividir nuestros datos en **datos de entrenamiento** y **datos de pruebas**. Para ello utilizaremos la instrucción ` train_test_split()` y cómo argumentos le pasaremos a nuestras variables `X`, `Y` de arriba y la porción de los datos destinada al testeo, en este caso el 20%. El argumento `random_state` controlamos la selección aleatoria de los datos antes de la partición :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se suele utilizar mayúscula en la $X$ ya que son valores que permanecen fijos (constante) y minúscula en la $y$ ya que es nuestra variable a predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear 2 modelos de regresión lineal para estudiar un tipo de validación Interno y otro Externo. Hagamos primero la Interna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrInterna = linear_model.LinearRegression() # Establecemos el modelo a usar\n",
    "regrInterna.fit(X, Y) # Entrenamos utilizando TODOS los datos\n",
    "prediccionesInterna = regrInterna.predict(X) # Devuelve las predicciones según todo X\n",
    "print(\"R2:\", r2_score(Y, prediccionesInterna)) # Devuelve R2 comparando los valores con la predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hagamos la Externa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrExterna = linear_model.LinearRegression() \n",
    "regrExterna.fit(X_train, y_train) # Esntrenamos con los DATOS DE ENTRENAMIENTO\n",
    "prediccionesExterna = regrExterna.predict(X_test) # Realiza predicciones de los valores de testing\n",
    "print(\"R2: \", r2_score(y_test, prediccionesExterna)) # Devuelve R2 según las predicciones del test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que si bien, tenemos un \"mejor resultado\" en la **validación interna** también tenemos un overfitting más alto, ya que estamos prediciendo los datos con los que lo entrenamos. Mientras que en el caso de la **validación externa** tenemos un valor de $R^2$ más pequeño, pero a la vez tenemos una \"generalización\" más versátil de nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué es y cómo actúa el K-Fold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, la validación externa es una buena manera de evaluar que tan bueno es nuestro modelo, pero en muchos casos es dependiente de qué selección concreta hayamos hecho en el conjunto `X_train` y `X_test`. Esto implica que, dependiendo que datos \"caigan\" en un grupo u otro; por lo que no siempre estaremos tan seguros de que tan buena haya sido la selección.\n",
    "\n",
    "Aquí propondremos utilizar **K-Fold**, el cuál prácticamente realizará el mismo procedimiento de ` train_test_split` **múltiples veces**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.dropna(subset=[\"ArrDelay\"])\n",
    "df = df.sample(frac=1).head(5000)\n",
    "\n",
    "# Es importante resetear el índice de los datos cuando hacemos\n",
    "# selecciones aleatorias\n",
    "df = df.reset_index()\n",
    "\n",
    "X = df[['AirTime', 'Distance', 'DepDelay']]\n",
    "y = df['ArrDelay']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sintaxis es muy similar a la que utilizamos en el caso anterior. KFold nos permite elegir cuántas particiones queremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí se vuelve importante tener los indices reseteados\n",
    "kf = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las particiones de nuestras variables X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos una regresión lineal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "# Por cada vez que repitamos la partición\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    # Localizamos los datos que vamos a colocar en cada partición\n",
    "    X_train, X_test = X.loc[train_index], X.iloc[test_index,]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    #Entrenamos\n",
    "    reg.fit(X_train, y_train)\n",
    "    # Testeamos\n",
    "    predictions = reg.predict(X_test)\n",
    "    print(\"R2: \", r2_score(y_test, predictions))\n",
    "    \n",
    "    # Guardamos\n",
    "    results.append(r2_score(y_test, predictions))\n",
    "    \n",
    "print(\"R2 promedio\", np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí es más claro visualizar cómo dependiendo de la selección de nuestros datos de entrenamiento tendremos mejores o peores predicciones. En este caso con KFold tenemos el promedio de todos estos, manteniendo un valor de $R^2$ más alto que con el split anterior. \n",
    "\n",
    "Utilizar el promedio nos ayuda a compensar la dependencia de datos concretos, este es un tipo de validación más representativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave One Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a hablar de otra forma de validación que si bien es más costosa computacionalmente (y en tiempo), es un tanto divertida e interesante. Lo que haremos será entrenar al modelo con todos los datos excepto 1, es decir, en nuestra línea de código `test_size` tendríamos $\\frac{1}{n}$. La particularidad de este proceso es que lo repetimos $n$ veces, de ahí la razón por la que sea tan costoso, pero es muy buena opción en caso de tener muestras muy pequeñas de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import linear_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.dropna(subset = [\"ArrDelay\"])\n",
    "df = df.sample(frac=1).head(5000)\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "X = df[['AirTime', 'Distance', 'DepDelay']]\n",
    "y = df['ArrDelay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "error_vector = []\n",
    "for train_index, test_index in loo.split(X):\n",
    "    \n",
    "    X_train, X_test = X.loc[train_index,], X.loc[test_index,]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    reg.fit(X_train, y_train)\n",
    "    predictions = reg.predict(X_test)\n",
    "    \n",
    "    error_vector.append( int((y_test - predictions[0])**2 ) ) \n",
    "    print('Error Cuadratico: ', ( (y_test - predictions[0])**2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales son uno de los modelos más populares hoy en día, su funcionamiento se basa en tratar de replicar los procesos cognitivos de un cerebro humano; partiendo desde conceptos como neuronas artificiales, funciones de activación hasta tener redes súper complejas cada vez más profundas. Son muy costosas computacionalmente, pero también son muy buenas al aproximar todo tipo de estructuras internas dentro de nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/p6d6Fjw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la imagen de arriba cada bolita representa una neurona y tenemos dividido al modelo en distintas capas. En nuestra primera capa tenemos nuestros inputs (datos), o variables regresoras. Después, tenemos capas ocultas que representan ***combinaciones lineales** o pesos de los inputs y de otras capas oculats. Finalmente, tenemos nuestros valores de salida o outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conceptos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Neuronas:** Son cada uno de los elementos individuales informativos que generamos al intentar relacionar y explicar nuestros outputs a través de nuestros inputs.\n",
    "* **Enlaces:** Son las combinaciones lineales entre los elementos de la red.\n",
    "* **Función de pérdida:** Función matemática que relaciona un evento o tarea con un número que representa el coste de realizarla.\n",
    "* **Aprendizaje automático:** Cuando desarrollamos algoritmos y modelos que pueden \"aprender\" a realizar una tarea sin necesidad de ser implícitamente programados para ello. En general, se basan en iterar distintos procesos hasta minimizar una función de pérdida.\n",
    "* **Función de activación:** Función matemática que describe cómo se \"encienden\" o activan nuestras neuronas o elementos de nuestra red.\n",
    "* **Tipo de aprendizaje:** Supervisado, no supervisado o reforzado.\n",
    "* **Coste:** Coste computacional en función de la cantidad de datos y la profundidad o cantidad de capas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ventajas         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Adaptativas:** Funcionan para todo tipo de distribución de datos, lineales o no lineales.\n",
    "* **Paralelizables:** Podemos distribuir el cálculo en distintos computadores o servidores.\n",
    "* **Tolerancia a fallos**: Si alguna parte del modelo falla o pierde algo de información, podemos repararlo sin haber perdido todo lo que hemos hecho.\n",
    "* **Potencial predictivo:** Son muy buenas generalizando los patrones en los, siempre y cuando estén bien calibradas y construidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Coste computacional**: Por lo mismo de la profundidad a la que pueden llegar, requieren de gran poder de cómputo.\n",
    "* **Cajas negras:** En realidad no sabemos exactamente que es lo que pasa dentro del modelo, solo podemos entenderlo al nivel de sus capas más simples, el resto es gracias a la conexión y trabajo conjunto de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes neuronales en código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar ScikitLearn para ver cómo podríamos ajustar redes neuronales. Utilizamos `MLPClassifier` al trabajar con datos categóricos y `MLPRegressor` con datos numéricos; después importamos a `StandardScaler` escalar nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Validación externa\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Python_para_Data_Science_Adv/Data/2008.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.dropna(subset = ['AirTime','Distance','TaxiIn', 'TaxiOut', 'DepDelay'])\n",
    "df = df.sample(frac=1).head(1000)\n",
    "\n",
    "\n",
    "X = df[['AirTime','Distance','TaxiIn', 'TaxiOut', 'DepDelay']]\n",
    "Y = df['ArrDelay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a dividir los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que tenemos datos que miden cosas distintas, algunas columnas miden tiempo, otras distancia, etc. Así que vamos a estandarizar nuestros valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hace es estandarizar las características eliminando la media y escalando a la varianza de la unidad. La puntuación estándar de una muestra $x$ se calcula cómo:\n",
    "\n",
    "$$ z = \\frac{(x-u)}{s}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $u$ es la media de nuestras muestras, $s$ es la desviación estándar de las muestras y $x$ nuestras muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a ajustar a la red neuronal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, ))\n",
    "\n",
    "model = clf.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print('R2: ', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que tenemos un $R^2$ muy alto, pero recordemos que tenemos la variable ` 'DepDelay'` tanto en $X$ cómo en $Y$, por lo que esperaríamos que estén muy correlacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay algunos parámetros que podemos modificar para adaptar este tipo de modelos:\n",
    "\n",
    "* **`solver`:** Indica a nuestra función cómo resolver el problema de optimización.\n",
    "    * `lbfgs`: es un optimizador de la familia de métodos cuasi-Newton.\n",
    "    * `sgd`: se refiere a un descenso del gradiente estocástico.\n",
    "    * `adam`:  se refiere a un optimizador estocástico basado en gradientes propuesto por Kingma, Diederik y Jimmy Ba.\n",
    "\n",
    "\n",
    "* **`alpha`:** Penalización a la complejidad del modelo, nos ayuda a controlar el **overfitting**.\n",
    "\n",
    "\n",
    "* **`hidden_layer_sizes`:** Número de capas ocultas en las que trabajamos, esto depende muchísimo de los datos que estemos utilizando. NO siempre es mejor tener más capas.\n",
    "    * Primero recibe el número de capas.\n",
    "    * Después de la coma recibe el número de neuronas (generalmente se mantiene vacío).\n",
    "\n",
    "\n",
    "* **`activation`:** Indica cuál es la función de activación que utilizaremos.\n",
    "    * `identity`: activación sin operación, útil para implementar cuellos de botella lineales, devuelve $f(x) = x$.\n",
    "\n",
    "    * `logistic`: la función sigmoidea logística, devuelve $f (x) =\\frac{1}{ (1 + exp (-x))}$.\n",
    "\n",
    "    * `tanh`:  la función tan hiperbólica, devuelve $f (x) = tanh (x)$.\n",
    "\n",
    "    * `relu`: la función de unidad lineal rectificada, devuelve $f (x) = max (0, x)$.\n",
    "    \n",
    "    \n",
    "* **`learning_rate`**: Velocidad de aprendizaje de nuestra red. \n",
    "    * `constant`: es una tasa de aprendizaje constante dada por `learning_rate_init`. Este es el valor predeterminado.\n",
    "    * `invscaling`: disminuye gradualmente la tasa de aprendizaje `learning_rate_` en cada paso de tiempo $t$ utilizando un exponente de escala inversa de `power_t` . `effective_learning_rate = learning_rate_init / pow(t, power_t)`.\n",
    "    * `adaptive`: mantiene la tasa de aprendizaje constante en `learning_rate_init` siempre que la pérdida de entrenamiento siga disminuyendo.\n",
    "    \n",
    "\n",
    "* `max_iter`: Número máximo de iteraciones.\n",
    "\n",
    "\n",
    "* `warm_start`: El modelo comienza desde la solución de la última vez que la hemos ejecutado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost y los árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGboost es una \"evolución\" de los árboles de clasificación. Se podría decir que estamos mezclando varios árboles y evaluando que tan bueno es el modelo. \n",
    "\n",
    "El elemento clave de esto es nuestra función de pérdida, comúnmente utilizando la media de los errores al cuadrado junto con una **penalización de complejidad**, es decir, vamos a penalizar los modelos que sean muy complejos; esto último es lo que nos permite evitar el **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/cart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a diferencia de los árboles normales, en este caso asigna **valores reales** a nuestros posibles eventos, de manera que podríamos generar una métrica que vamos a poder añadir a nuevos árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/twocart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "de forma que la predicción de nuestros eventos estará en función de los distintos árboles que utilicemos. De forma que al final obtenemos una estructura como la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/struct_score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estaríamos **acumulando los valores** de nuestros eventos o en este caso, de nuestros individuos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Documentación de XGboost ](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de Contenidos 💜",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
