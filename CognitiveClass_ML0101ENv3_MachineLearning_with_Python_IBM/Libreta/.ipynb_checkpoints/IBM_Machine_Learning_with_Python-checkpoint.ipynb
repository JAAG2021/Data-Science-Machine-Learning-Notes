{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Cognitive-Class:-ML0101ENv3-Machine-Learning-with-Python\" data-toc-modified-id=\"Cognitive-Class:-ML0101ENv3-Machine-Learning-with-Python-0\">Cognitive Class: ML0101ENv3 Machine Learning with Python</a></span><ul class=\"toc-item\"><li><span><a href=\"#Objetivos:\" data-toc-modified-id=\"Objetivos:-0.1\">Objetivos:</a></span></li><li><span><a href=\"#Introducción-al-Machine-Learning:\" data-toc-modified-id=\"Introducción-al-Machine-Learning:-0.2\">Introducción al Machine Learning:</a></span><ul class=\"toc-item\"><li><span><a href=\"#¿Qué-es-el-Machine-Learning?:\" data-toc-modified-id=\"¿Qué-es-el-Machine-Learning?:-0.2.1\">¿Qué es el Machine Learning?:</a></span></li><li><span><a href=\"#Ejemplos-de-Machine-Learning-en-la-vida-cotidiana:\" data-toc-modified-id=\"Ejemplos-de-Machine-Learning-en-la-vida-cotidiana:-0.2.2\">Ejemplos de Machine Learning en la vida cotidiana:</a></span></li><li><span><a href=\"#Técnicas-más-populares:\" data-toc-modified-id=\"Técnicas-más-populares:-0.2.3\">Técnicas más populares:</a></span></li><li><span><a href=\"#Diferencias-entre-inteligencia-artificial,-machine-learning-y-deep-learning:\" data-toc-modified-id=\"Diferencias-entre-inteligencia-artificial,-machine-learning-y-deep-learning:-0.2.4\">Diferencias entre inteligencia artificial, machine learning y deep learning:</a></span></li></ul></li><li><span><a href=\"#Python-para-Machine-Learning:\" data-toc-modified-id=\"Python-para-Machine-Learning:-0.3\">Python para Machine Learning:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Más-sobre-scikit-learn\" data-toc-modified-id=\"Más-sobre-scikit-learn-0.3.1\">Más sobre scikit-learn</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cognitive Class: ML0101ENv3 Machine Learning with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Entender como se relacionan los modelos estadísticos con el aprendizaje automático (Machine Learning).\n",
    "\n",
    "* Conocer aplicaciones de Machine Learning en la vida real y cómo afecta a la sociedad de formas que previamente no habíamos cuestionado o imaginado.\n",
    "\n",
    "* Aprender a usar librerías de Python para Machine Learning, por ejemplo, scikit-learn.\n",
    "\n",
    "**Explorar algoritmos y modelos**\n",
    "\n",
    "* Algoritmos populares como: Regresión, clasificación y Agrupamiento.\n",
    "\n",
    "* Sistemas de recomendación: Filtrado colaborativo y basado en contenido.\n",
    "\n",
    "* Modelos populares: División de entrenamiento/test ( Train/Test Split), Descenso de gradiente y Error medio cuadrático (Mean Squared Error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción al Machine Learning: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aplicaciones del Machine Learning\n",
    "\n",
    "* Librerías de Python para Machine Learning\n",
    "\n",
    "* Aprendizaje supervisado vs no supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos que tenemos una muestra de una célula humana que se le ha extraído a un paciente. Y dividimos las características de dicha célula en parámetros como:\n",
    "\n",
    "* su espesor de grupo (clump thickness)\n",
    "\n",
    "* uniformidad del tamaño de la celda (uniformity of cell size)\n",
    "\n",
    "* Adhesión marginal (Marginal Adhesion)\n",
    "\n",
    "entre otras característica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/synIkER.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y a partir de los números asignados a cada uno de los parámetros nos hacemos la siguiente pregunta. ¿Esta es una célula benigna o maligna?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En contraste con un tumor \"benigno\" respecto a un tumor \"maligno\", el *maligno* puede invadir el tejido de sus alrededores o cercano a el o esparcirse por todo el cuerpo. Y diagnosticar a tiempo un tumor maligno es una pieza clase para la supervivencia de nuestro paciente. \n",
    "\n",
    "Podríamos pensar que solo un doctor con los suficientes años de experiencia y familiaridad con ese tipo de enfermedades podría ser lo suficientemente capaz de detectar a tiempo este tipo de tumores malignos o cáncer, pero aún así no tendríamos una certeza del 100% además de que no todos los pacientes de la población podrían permitirse acceder a un médico de tan alto calibre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bueno, imaginemos que disponemos de un amplio dataset con información de las células extraídas a miles de pacientes quienes creían tener riesgo de desarrollar cáncer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/RkuvsyE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando el dataset podemos ver que las características o parámetros varían significativamente dependiendo de pacientes con celular malignas y benignas.\n",
    "\n",
    "Podemos basarnos en otras muestras de pacientes con características muy similares para tratar de predecir si una nueva célula extraída es o no maligna. Para lograr esto, debemos de \"limpiar\" nuestros datos, elegir un algoritmo adecuado para crear nuestro modelo de predicciones y entrenar a nuestro modelo para que aprenda a encontrar los patrones subyacentes en nuestro dataset. Este entrenamiento lo realiza \"estudiando\" los datos de forma iterativa, se parte de una función matemática que será más compleja dependiendo la aplicación y en cada iteración se irá modificando esta función hasta que se \"acomode\" a un modelo predictivo como el que esperamos, es decir, el aprendizaje no es más que un modelamiento matemático realizado por la computadora de forma no necesariamente explícita por el programador.\n",
    "\n",
    "Una vez que hemos creado y entrenado a nuestro modelo, podemos usarlo para probar con nuevos inputs, es decir, con nuevas células extraídas que no estaban dentro del dataset original. Una vez que evaluamos esa célula obtenemos un resultado con cierto porcentaje de certeza (accuracy) que nos permite obtener un diagnostico con mucha más certidumbre.\n",
    "\n",
    "Así es como funciona el Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/idFKMZp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Está es solo una de las tantas formas en las que el Machine Learning ha incursionado en campos tan diversos, entre ellos, la medicina. Permitiendo a los doctores obtener diagnosticos mucho más certeros e incluso más rápidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos una definición más formal de Machine Learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué es el Machine Learning?:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El Machine Learning es el campo de las ciencias de la computación que le permite a las computadoras \"la habilidad de aprender sin ser explícitamente programadas para realizar dicha tarea\".**\n",
    "\n",
    "> Artur Samuel: Americano pionero en el campo de los juegos automatizados y de la inteligencia artificial, quien acuñó el término \"Machine Learning\" en 1959 mientras trabajaba en IBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿A que nos referimos con que algo no sea \"explícitamente programado\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a asumir que tenemos un dataset de imágenes de animalitos, por ejemplo, perros y gatos. Y queremos crear un software o una aplicación que sepa reconocerlos y diferenciarlos.\n",
    "\n",
    "Lo primero que tendríamos que hacer para lograrlo sería interpretar nuestras imágenes como un **conjunto de conjuntos de características**. Por ejemplo, podríamos empezar por tratar de diferenciar entre los ojos de un perro y un gato, sus tamaños, orejas, colas, etc. \n",
    "\n",
    "Previo a la era del Machine Learning se tenían que transformar *cada una de las imágenes* en un **vector de características**. Después, teníamos que escribir *explícitamente* un código que indicara como teníamos que trabajar con dichos vectores de características de forma que pudieramos aproximarnos a una clasificación de las imágenes, pero los resultados para nada eran lo suficientemente buenos siguiendo ese paradigma de programación. ¿Por qué no era una buena opción para realizar esa tarea? Bueno, tendríamos que escribir un montón de código para separar cada uno de los rasgos que consideramos importantes a la hora de determinar que es lo que hay en una imagen, además de que estas reglas siempre serían muy dependientes de nuestras imágenes del dataset cosa que se hace cada vez más complicada al tratar de generalizar para un dataset de imagenes distintas. En conclusión, era un lío abordar el problema desde ese paradigma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La \"arquitectura\" a muy grandes rasgos de como se tenía que trabajar previo al Machine Learning era la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/aenrHol.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Ahora, como sería el modelo aplicando Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta nueva técnica podemos construir modelos que nos permiten crear un modelo que analiza todos los conjuntos de características y su correspondiente tipo de animales, y aprende aprende el patrón de cada animal. De esta forma tenemos un programa que sabe diferenciar los animales de las fotos sin que estén programadas explícitamente las instrucciones para hacer esa tarea en específico.\n",
    "\n",
    "Prácticamente, el Machine Learning usa el mismo método de diferenciación que haría un niño pequeño que sería, entender las partes que conforman a cada animal y aprender a diferenciarlos entre sí dado un previo dataset de \"entrenamiento\". De hecho el Machine Learning está enfocado en aprender a replicar los procesos de aprendizaje de los seres humanos, o al menos tratar de hacerlos de una forma muy parecida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/zRmDi2P.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos de Machine Learning en la vida cotidiana:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Algoritmos de recomendación usados por Netflix o Amazon:** Estos algoritmos usan Machine Learning para calcular cual de las películas o series de su catálogo tienen mayor probabilidad de interesarte de acuerdo a tus búsquedas previas.\n",
    "\n",
    "\n",
    "* **Aprobación de solicitudes de prestamos bancarios:** Algunos bancos utilizan técnicas de Machine Learning para calcular la probabilidad que los solicitantes resulten en algún fraude crediticio y a partir de los resultados deciden si aceptar o rechazar sus solicitudes.\n",
    "\n",
    "\n",
    "* **Telecomunicaciones:** Utilizan los datos demográficos de sus clientes para predecir si en el siguiente periodo es posible que sus clientes abandonen el servicio, anticipandose con alguna campaña de marketing, ofertas especiales, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/jt4rU8Z.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Técnicas más populares:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Regresión/Estimación:** Se utiliza para predecir valores continuos, por ejemplo, predecir cosas como el precio de una casa basandose en sus características, o para estimar la cantidad de $C0_2$ emitida por un auto.\n",
    "\n",
    "\n",
    "* **Clasificación:** Se utiliza para predecir a que categoría o clase pertenece cierto dato en particular, por ejemplo, si una célula es benigna o maligno, o para clasificar a nuestros clientes en ciertas categorías ya creadas.\n",
    "\n",
    "\n",
    "* **Agrupamiento:** Se utiliza para encontrar una estructura subyacente en los datos, a partir de un set de datos similares trata de crear grupos en los cuales puede dividir esos datos. Por ejemplo, al querer descubrir en que grupos podemos dividir a nuestros clientes según ciertos patrones de conducta.\n",
    "\n",
    "\n",
    "* **Asociación:** Asocia eventos que suelen estar correlacionados. Las reglas que el algoritmo identifica pueden utilizarse para predecir las probables compras de un cliente en el futuro, basándose en los elementos existentes en la cesta de compra actual del cliente.\n",
    "\n",
    "\n",
    "* **Detección de anomalías:** Detecta casos anormales o inusuales. En este principio se basa el algoritmo de detección de fraudes crediticios.\n",
    "\n",
    "\n",
    "* **Minería de secuencias:** Predice eventos futuros; click-stream (Markov Model, HMM). También se puede aplicar dentro de un sitio web para predecir el comportamiento del usuario.\n",
    "\n",
    "\n",
    "* **Reducción de dimensiones:** Reduce el tamaño de nuestros datos (PCA).\n",
    "\n",
    "\n",
    "* **Sistemas de recomendación:** Recomienda items basado en comportamientos previos, como en el caso de Netflix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferencias entre inteligencia artificial, machine learning y deep learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El campo de la inteligencia artificial se encarga de hacer a las computadoras \"inteligentes\" refiriendonos a que queremos replicar las funciones cognitivas del ser humano para imitar su aprendizaje y lo que llamamos \"comportamiento inteligente \".\n",
    "\n",
    "Componentes de\n",
    "\n",
    "**Inteligencia artificial:**\n",
    "\n",
    "* Enfoque computacional (computer vision)\n",
    "* Procesamiento del lenguaje\n",
    "* Creatividad\n",
    "\n",
    "**Machine learning o aprendizaje automatizado:**\n",
    "*Es una rama de la inteligencia artificial* que cubre la parte estadística de la inteligencia artificial, aquí es donde enseñamos a la computadora a resolver problemas a partir de mostrarle datasets enormes de miles y miles de datos, de forma que aprenda a detectar los \"patrones\" subyacentes en ellos. Una vez que tiene el entrenamiento o experiencia suficiente al estudiar esos datos de ejemplo, se ingresan nuevos valores para resolver nuevos problemas.\n",
    "\n",
    "* Clasificación\n",
    "* Agrupamiento\n",
    "* Redes neuronales\n",
    "\n",
    "**Deep learning o aprendizaje profundo:**\n",
    "*Es una rama del Machine Learning* donde las computadoras ya pueden aprender y tomar decisiones inteligentes por su propia cuenta. Aquí englobamos un aprendizaje a un nivel más profundo en comparación con el nivel de aprendizaje de los modelos de machine learning ya que se concentra en encontrar patrones aun más complejos para realizar tareas más complejas. Un ejemplo de deep learning sería su aplicación en coches autónomos, reconocimiento de vídeos, reconocimiento de audio, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python para Machine Learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que Python es un lenguaje bastante poderoso y con una gran cantidad de herramientas desarrolladas para distintos propósitos, entre ellos, uno de los usos más populares que se le da es para ciencia de datos y machine learning.\n",
    "\n",
    "Tenemos algunos módulos y librerías que son de utilidad y casi indispensables para trabajar en este campo, entre ellas tenemos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Numpy:** Es una librería de matemáticas que nos ayuda a trabajar con arrays de n-dimensiones, esto nos permite realizar ciertos cómputos de forma más eficaz y efectiva. Nos permite extender muchísimo nuestros alcances con el lenguaje, por ejemplo, agiliza mucho el proceso al trabajar con arrays, diccionarios, funciones, estructuras de datos y al trabajar con imágenes.\n",
    "\n",
    "* **SciPy:** Es una colección de algoritmos numéricos y herramientas de dominio específico (domain-specific toolboxes), incluyendo el procesamiento de señales, optimización, estadística y más. Es una buena librería para científicos y para computación de alto rendimiento.\n",
    "\n",
    "* **matplotlib:** Es un paquete muy famoso para graficar en 2D y 3D.\n",
    "\n",
    "* **pandas:** es una librería de Python de alto nivel que nos proporciona cómputos de alto rendimiento al trabajar con estructuras de datos, cuenta con muchas funciones para importar datos, manipularlos y analizarlos. En particular ofrece estructuras de datos y operaciones para manipular tablas numéricas y series temporales (time series).\n",
    "\n",
    "* **scikit-learn:** Es una colección de algoritmos y herramientas para machine learning.\n",
    "\n",
    "![](https://i.imgur.com/VYyhoWp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Más sobre scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué es tan popular?\n",
    "\n",
    "* Es una librería gratuita para trabajar en machine learning.\n",
    "* Contiene la mayor parte de herramientas para trabajar con algoritmos de clasificación, regresión y agrupamiento.\n",
    "* Está diseñado para trabajar con NumPy and SciPy.\n",
    "* Tiene una muy buena documentación.\n",
    "* Es muy fácil de implementar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchas de las tareas que nos interesa realizar en machine learning ya están implementadas dentro de scikit learn, incluyendo pre-procesado de datos, selección de features(características de interés), extracción de features, train/test splitting, definición de algoritmos, modelos de ajuste, parámetros de ajuste, predicciones, evaluación y exportación de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/CYjPCMH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver un pequeño ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de machine learning se benefician de la estandarización de los data set. Si hay algunos valores atípicos, o campos a diferentes escalas en nuestro data set, tenemos que arreglarlos.\n",
    "\n",
    "El paquete `preprocessing` de `scikit learn` nos provee algunas funciones de utilidad que son comunes de usar y clases `transformer` para cambiar nuestros vectores de características sin tener que procesar en una representación que sea más adecuada para los estimadores posteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que dividir nuestro conjunto de datos en **conjunto de prueba** y **conjunto de entrenamiento** para proceder a entrenar el modelo, luego probar la precisión del modelo por separado.\n",
    "\n",
    "Scikit learn puede dividir matrices o arrays en conjuntos aleatorios de pruebas y probar los subconjuntos por nosotros:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, ya podemos configurar nuestro algoritmo. Por ejemplo, podemos crear un clasificador utilizando un algoritmo de clasificación de vectores de soporte:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma = 0.001, C=100.)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamamos a nuestra instancia de estimación/estimador `clf` e inicializamos sus parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos entrenar nuestro modelo con nuestro set de entrenamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "clf.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasando nuestro conjunto de entrenamiento al método de ajuste, el modelo `clf` aprenderá a clasificar casos desconocidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, podemos usar nuestro set de testeo para realizar algunas predicciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "clf.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y el resultado nos dice cuál es la clase de cada valor desconocido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, podemos utilizar diferentes métricas para evaluar la precisión del modelo, por ejemplo, utilizando una matriz de confusión (confusion matrix) para mostrar los resultados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "form sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, yhat, labels=[1,0]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y finalmente, guardamos nuestro modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "import pickle\n",
    "s = pickle.dumps(clf)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más adelante indagará con más detalle en cada uno de los conceptos e instrucciones utilizadas. Por ahora, mantengamos el punto más importante de todo eso y es que, el proceso entero de una tarea realizada con Machine Learning puede hacerse de una manera muy simple en unas pocas líneas de código utilizando `scikit learn`.\n",
    "\n",
    "Esto sería posible desarrollarlo utilizando Numpy o Scipy, pero no sería una tarea igual de sencilla. De hecho, acomplejaríamos mucho más el proceso solo por hacerlo de una forma más \"artesanal\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
